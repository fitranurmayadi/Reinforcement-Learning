{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29.1\n",
      "2.5.1+cu118\n",
      "3.2.4\n",
      "2.3.2\n",
      "2.38.0\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import torch as th\n",
    "import mujoco\n",
    "import stable_baselines3 as sb\n",
    "import ray\n",
    "\n",
    "print(gym.__version__)\n",
    "print(th.__version__)\n",
    "print(mujoco.__version__)\n",
    "print(sb.__version__)\n",
    "print(ray.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Converting from sequence to b2Vec2, expected int/float arguments index 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m action \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39msample()\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# step (transition) through the environment with the action\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# receiving the next observation, reward and if the episode has terminated or truncated\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# If the episode has ended then we can reset to start a new episode\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated:\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\robot_sim\\lib\\site-packages\\gymnasium\\wrappers\\time_limit.py:57\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m     47\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m \n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\robot_sim\\lib\\site-packages\\gymnasium\\wrappers\\order_enforcing.py:56\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\robot_sim\\lib\\site-packages\\gymnasium\\wrappers\\env_checker.py:49\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_step:\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43menv_step_passive_checker\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\robot_sim\\lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:208\u001b[0m, in \u001b[0;36menv_step_passive_checker\u001b[1;34m(env, action)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"A passive check for the environment step, investigating the returning data then returning the data unchanged.\"\"\"\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;66;03m# We don't check the action as for some environments then out-of-bounds values can be given\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    210\u001b[0m     result, \u001b[38;5;28mtuple\u001b[39m\n\u001b[0;32m    211\u001b[0m ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpects step result to be a tuple, actual type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(result)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\robot_sim\\lib\\site-packages\\gymnasium\\envs\\box2d\\lunar_lander.py:570\u001b[0m, in \u001b[0;36mLunarLander.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    563\u001b[0m         \u001b[38;5;66;03m# particles are just a decoration, with no impact on the physics, so don't add them when not rendering\u001b[39;00m\n\u001b[0;32m    564\u001b[0m         p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_particle(\n\u001b[0;32m    565\u001b[0m             \u001b[38;5;241m3.5\u001b[39m,  \u001b[38;5;66;03m# 3.5 is here to make particle speed adequate\u001b[39;00m\n\u001b[0;32m    566\u001b[0m             impulse_pos[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    567\u001b[0m             impulse_pos[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m    568\u001b[0m             m_power,\n\u001b[0;32m    569\u001b[0m         )\n\u001b[1;32m--> 570\u001b[0m         \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mApplyLinearImpulse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m                \u001b[49m\u001b[43mox\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mMAIN_ENGINE_POWER\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mm_power\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m                \u001b[49m\u001b[43moy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mMAIN_ENGINE_POWER\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mm_power\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[43m            \u001b[49m\u001b[43mimpulse_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    576\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    577\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlander\u001b[38;5;241m.\u001b[39mApplyLinearImpulse(\n\u001b[0;32m    579\u001b[0m         (\u001b[38;5;241m-\u001b[39mox \u001b[38;5;241m*\u001b[39m MAIN_ENGINE_POWER \u001b[38;5;241m*\u001b[39m m_power, \u001b[38;5;241m-\u001b[39moy \u001b[38;5;241m*\u001b[39m MAIN_ENGINE_POWER \u001b[38;5;241m*\u001b[39m m_power),\n\u001b[0;32m    580\u001b[0m         impulse_pos,\n\u001b[0;32m    581\u001b[0m         \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    582\u001b[0m     )\n\u001b[0;32m    584\u001b[0m s_power \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: Converting from sequence to b2Vec2, expected int/float arguments index 0"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "# Initialise the environment\n",
    "env = gym.make(\"LunarLander-v2\", continuous=True, render_mode=\"human\")\n",
    "\n",
    "# Reset the environment to generate the first observation\n",
    "observation, info = env.reset(seed=42)\n",
    "for _ in range(1000):\n",
    "    # this is where you would insert your policy\n",
    "    action = env.action_space.sample()\n",
    "\n",
    "    # step (transition) through the environment with the action\n",
    "    # receiving the next observation, reward and if the episode has terminated or truncated\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    # If the episode has ended then we can reset to start a new episode\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Creating environment from the given name 'Pendulum-v1'\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.35e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 370       |\n",
      "|    iterations         | 100       |\n",
      "|    time_elapsed       | 1         |\n",
      "|    total_timesteps    | 500       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.44     |\n",
      "|    explained_variance | 0.8979026 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 99        |\n",
      "|    policy_loss        | -17       |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 62.9      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 200         |\n",
      "|    ep_rew_mean        | -1.36e+03   |\n",
      "| time/                 |             |\n",
      "|    fps                | 434         |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 2           |\n",
      "|    total_timesteps    | 1000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.44       |\n",
      "|    explained_variance | -0.17413008 |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 199         |\n",
      "|    policy_loss        | -42.1       |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 887         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 200         |\n",
      "|    ep_rew_mean        | -1.36e+03   |\n",
      "| time/                 |             |\n",
      "|    fps                | 465         |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 3           |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.44       |\n",
      "|    explained_variance | -0.95142376 |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 299         |\n",
      "|    policy_loss        | -34.7       |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 922         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.37e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 481        |\n",
      "|    iterations         | 400        |\n",
      "|    time_elapsed       | 4          |\n",
      "|    total_timesteps    | 2000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.44      |\n",
      "|    explained_variance | 0.60967755 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 399        |\n",
      "|    policy_loss        | -18.9      |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 187        |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 200          |\n",
      "|    ep_rew_mean        | -1.41e+03    |\n",
      "| time/                 |              |\n",
      "|    fps                | 492          |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 5            |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.44        |\n",
      "|    explained_variance | 0.0026640892 |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 499          |\n",
      "|    policy_loss        | -23.9        |\n",
      "|    std                | 1.02         |\n",
      "|    value_loss         | 714          |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.47e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 500        |\n",
      "|    iterations         | 600        |\n",
      "|    time_elapsed       | 5          |\n",
      "|    total_timesteps    | 3000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.44      |\n",
      "|    explained_variance | -0.3744948 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 599        |\n",
      "|    policy_loss        | -43.4      |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 657        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.5e+03   |\n",
      "| time/                 |            |\n",
      "|    fps                | 506        |\n",
      "|    iterations         | 700        |\n",
      "|    time_elapsed       | 6          |\n",
      "|    total_timesteps    | 3500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.44      |\n",
      "|    explained_variance | -1.1372986 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 699        |\n",
      "|    policy_loss        | -21.6      |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 539        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.53e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 511        |\n",
      "|    iterations         | 800        |\n",
      "|    time_elapsed       | 7          |\n",
      "|    total_timesteps    | 4000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.45      |\n",
      "|    explained_variance | 0.09796393 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 799        |\n",
      "|    policy_loss        | -11.4      |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 168        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.53e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 515       |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.44     |\n",
      "|    explained_variance | 0.6326253 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | -4.49     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 19.2      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 200         |\n",
      "|    ep_rew_mean        | -1.55e+03   |\n",
      "| time/                 |             |\n",
      "|    fps                | 517         |\n",
      "|    iterations         | 1000        |\n",
      "|    time_elapsed       | 9           |\n",
      "|    total_timesteps    | 5000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.44       |\n",
      "|    explained_variance | -0.65183187 |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 999         |\n",
      "|    policy_loss        | -3.38       |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 7.52        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.57e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 520       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 10        |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.45     |\n",
      "|    explained_variance | -9.008474 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | -0.938    |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.667     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.59e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 522        |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 11         |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.43      |\n",
      "|    explained_variance | -13.430685 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1199       |\n",
      "|    policy_loss        | 10.7       |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 54.7       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.6e+03   |\n",
      "| time/                 |            |\n",
      "|    fps                | 524        |\n",
      "|    iterations         | 1300       |\n",
      "|    time_elapsed       | 12         |\n",
      "|    total_timesteps    | 6500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.44      |\n",
      "|    explained_variance | -0.8703195 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1299       |\n",
      "|    policy_loss        | 5.35       |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 22.4       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.59e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 525        |\n",
      "|    iterations         | 1400       |\n",
      "|    time_elapsed       | 13         |\n",
      "|    total_timesteps    | 7000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.43      |\n",
      "|    explained_variance | -23.949614 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1399       |\n",
      "|    policy_loss        | -8.92      |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 87.8       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 200      |\n",
      "|    ep_rew_mean        | -1.6e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 520      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.43    |\n",
      "|    explained_variance | -54.8238 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 6.83     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 56.6     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.6e+03   |\n",
      "| time/                 |            |\n",
      "|    fps                | 515        |\n",
      "|    iterations         | 1600       |\n",
      "|    time_elapsed       | 15         |\n",
      "|    total_timesteps    | 8000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.43      |\n",
      "|    explained_variance | -174.15506 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1599       |\n",
      "|    policy_loss        | 11.2       |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 113        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.61e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 509       |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 16        |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.41     |\n",
      "|    explained_variance | -6.089242 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | -20.4     |\n",
      "|    std                | 0.993     |\n",
      "|    value_loss         | 307       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.61e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 500        |\n",
      "|    iterations         | 1800       |\n",
      "|    time_elapsed       | 17         |\n",
      "|    total_timesteps    | 9000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.4       |\n",
      "|    explained_variance | -51.819725 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1799       |\n",
      "|    policy_loss        | 16.8       |\n",
      "|    std                | 0.984      |\n",
      "|    value_loss         | 252        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.61e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 495        |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 19         |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.4       |\n",
      "|    explained_variance | -1599.6655 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1899       |\n",
      "|    policy_loss        | 363        |\n",
      "|    std                | 0.982      |\n",
      "|    value_loss         | 1.38e+05   |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 200      |\n",
      "|    ep_rew_mean        | -1.6e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 491      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.39    |\n",
      "|    explained_variance | -24.7452 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 16.8     |\n",
      "|    std                | 0.974    |\n",
      "|    value_loss         | 140      |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.59e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 484        |\n",
      "|    iterations         | 2100       |\n",
      "|    time_elapsed       | 21         |\n",
      "|    total_timesteps    | 10500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.38      |\n",
      "|    explained_variance | -1870.2108 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2099       |\n",
      "|    policy_loss        | 110        |\n",
      "|    std                | 0.964      |\n",
      "|    value_loss         | 1.47e+04   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.59e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 482        |\n",
      "|    iterations         | 2200       |\n",
      "|    time_elapsed       | 22         |\n",
      "|    total_timesteps    | 11000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.37      |\n",
      "|    explained_variance | -38.031803 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2199       |\n",
      "|    policy_loss        | 15.1       |\n",
      "|    std                | 0.954      |\n",
      "|    value_loss         | 210        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.58e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 479        |\n",
      "|    iterations         | 2300       |\n",
      "|    time_elapsed       | 23         |\n",
      "|    total_timesteps    | 11500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.38      |\n",
      "|    explained_variance | -189.89075 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2299       |\n",
      "|    policy_loss        | -20.3      |\n",
      "|    std                | 0.958      |\n",
      "|    value_loss         | 2.33e+03   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.57e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 472       |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 25        |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.38     |\n",
      "|    explained_variance | -42.27545 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | -124      |\n",
      "|    std                | 0.966     |\n",
      "|    value_loss         | 9.05e+03  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.56e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 470        |\n",
      "|    iterations         | 2500       |\n",
      "|    time_elapsed       | 26         |\n",
      "|    total_timesteps    | 12500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.39      |\n",
      "|    explained_variance | -5535.4414 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2499       |\n",
      "|    policy_loss        | 228        |\n",
      "|    std                | 0.972      |\n",
      "|    value_loss         | 3.27e+04   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.55e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 468       |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 27        |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.39     |\n",
      "|    explained_variance | -3.726892 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | -38.5     |\n",
      "|    std                | 0.967     |\n",
      "|    value_loss         | 729       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.54e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 463        |\n",
      "|    iterations         | 2700       |\n",
      "|    time_elapsed       | 29         |\n",
      "|    total_timesteps    | 13500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.38      |\n",
      "|    explained_variance | -168.99423 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2699       |\n",
      "|    policy_loss        | 12.2       |\n",
      "|    std                | 0.967      |\n",
      "|    value_loss         | 2.03e+03   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.55e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 462        |\n",
      "|    iterations         | 2800       |\n",
      "|    time_elapsed       | 30         |\n",
      "|    total_timesteps    | 14000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.39      |\n",
      "|    explained_variance | -51.791336 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2799       |\n",
      "|    policy_loss        | -290       |\n",
      "|    std                | 0.973      |\n",
      "|    value_loss         | 5.2e+04    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.54e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 463        |\n",
      "|    iterations         | 2900       |\n",
      "|    time_elapsed       | 31         |\n",
      "|    total_timesteps    | 14500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.39      |\n",
      "|    explained_variance | -336.92758 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2899       |\n",
      "|    policy_loss        | -86.9      |\n",
      "|    std                | 0.971      |\n",
      "|    value_loss         | 1.17e+04   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.54e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 460        |\n",
      "|    iterations         | 3000       |\n",
      "|    time_elapsed       | 32         |\n",
      "|    total_timesteps    | 15000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.39      |\n",
      "|    explained_variance | -203.67915 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2999       |\n",
      "|    policy_loss        | 29.5       |\n",
      "|    std                | 0.97       |\n",
      "|    value_loss         | 2.59e+03   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.54e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 461        |\n",
      "|    iterations         | 3100       |\n",
      "|    time_elapsed       | 33         |\n",
      "|    total_timesteps    | 15500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.39      |\n",
      "|    explained_variance | -8.5385475 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3099       |\n",
      "|    policy_loss        | -78.8      |\n",
      "|    std                | 0.968      |\n",
      "|    value_loss         | 4.65e+03   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.53e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 462       |\n",
      "|    iterations         | 3200      |\n",
      "|    time_elapsed       | 34        |\n",
      "|    total_timesteps    | 16000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.39     |\n",
      "|    explained_variance | -210.4883 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3199      |\n",
      "|    policy_loss        | -168      |\n",
      "|    std                | 0.973     |\n",
      "|    value_loss         | 2.65e+04  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.52e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 463        |\n",
      "|    iterations         | 3300       |\n",
      "|    time_elapsed       | 35         |\n",
      "|    total_timesteps    | 16500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.39      |\n",
      "|    explained_variance | -12.508872 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3299       |\n",
      "|    policy_loss        | -115       |\n",
      "|    std                | 0.973      |\n",
      "|    value_loss         | 6.35e+03   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.52e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 464       |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 36        |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.38     |\n",
      "|    explained_variance | 0.9106893 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | 4.55      |\n",
      "|    std                | 0.964     |\n",
      "|    value_loss         | 11.2      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.52e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 462        |\n",
      "|    iterations         | 3500       |\n",
      "|    time_elapsed       | 37         |\n",
      "|    total_timesteps    | 17500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.37      |\n",
      "|    explained_variance | -58.289642 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3499       |\n",
      "|    policy_loss        | -21.5      |\n",
      "|    std                | 0.954      |\n",
      "|    value_loss         | 103        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.51e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 462       |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 38        |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.36     |\n",
      "|    explained_variance | -13.29893 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | 49.3      |\n",
      "|    std                | 0.945     |\n",
      "|    value_loss         | 2.19e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.51e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 461       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 40        |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.35     |\n",
      "|    explained_variance | -43.71214 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | 33.3      |\n",
      "|    std                | 0.938     |\n",
      "|    value_loss         | 870       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.5e+03   |\n",
      "| time/                 |            |\n",
      "|    fps                | 459        |\n",
      "|    iterations         | 3800       |\n",
      "|    time_elapsed       | 41         |\n",
      "|    total_timesteps    | 19000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.35      |\n",
      "|    explained_variance | -34.834187 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3799       |\n",
      "|    policy_loss        | -66.1      |\n",
      "|    std                | 0.937      |\n",
      "|    value_loss         | 4.2e+03    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.5e+03   |\n",
      "| time/                 |            |\n",
      "|    fps                | 458        |\n",
      "|    iterations         | 3900       |\n",
      "|    time_elapsed       | 42         |\n",
      "|    total_timesteps    | 19500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.35      |\n",
      "|    explained_variance | -75.004875 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3899       |\n",
      "|    policy_loss        | -353       |\n",
      "|    std                | 0.935      |\n",
      "|    value_loss         | 5.31e+04   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.5e+03   |\n",
      "| time/                 |            |\n",
      "|    fps                | 457        |\n",
      "|    iterations         | 4000       |\n",
      "|    time_elapsed       | 43         |\n",
      "|    total_timesteps    | 20000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.34      |\n",
      "|    explained_variance | -26.516308 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3999       |\n",
      "|    policy_loss        | -62.1      |\n",
      "|    std                | 0.921      |\n",
      "|    value_loss         | 1.91e+03   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.5e+03   |\n",
      "| time/                 |            |\n",
      "|    fps                | 457        |\n",
      "|    iterations         | 4100       |\n",
      "|    time_elapsed       | 44         |\n",
      "|    total_timesteps    | 20500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.34      |\n",
      "|    explained_variance | -48.950165 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4099       |\n",
      "|    policy_loss        | -49.3      |\n",
      "|    std                | 0.925      |\n",
      "|    value_loss         | 776        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.5e+03   |\n",
      "| time/                 |            |\n",
      "|    fps                | 455        |\n",
      "|    iterations         | 4200       |\n",
      "|    time_elapsed       | 46         |\n",
      "|    total_timesteps    | 21000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.34      |\n",
      "|    explained_variance | -24.133488 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4199       |\n",
      "|    policy_loss        | -17.7      |\n",
      "|    std                | 0.922      |\n",
      "|    value_loss         | 347        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.5e+03   |\n",
      "| time/                 |            |\n",
      "|    fps                | 455        |\n",
      "|    iterations         | 4300       |\n",
      "|    time_elapsed       | 47         |\n",
      "|    total_timesteps    | 21500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.34      |\n",
      "|    explained_variance | -2082.7903 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4299       |\n",
      "|    policy_loss        | -32.4      |\n",
      "|    std                | 0.924      |\n",
      "|    value_loss         | 1.35e+03   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.51e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 457       |\n",
      "|    iterations         | 4400      |\n",
      "|    time_elapsed       | 48        |\n",
      "|    total_timesteps    | 22000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.35     |\n",
      "|    explained_variance | -9.585895 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4399      |\n",
      "|    policy_loss        | -5.78     |\n",
      "|    std                | 0.935     |\n",
      "|    value_loss         | 34.9      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.51e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 459        |\n",
      "|    iterations         | 4500       |\n",
      "|    time_elapsed       | 48         |\n",
      "|    total_timesteps    | 22500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.36      |\n",
      "|    explained_variance | -24.638805 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4499       |\n",
      "|    policy_loss        | -66.5      |\n",
      "|    std                | 0.944      |\n",
      "|    value_loss         | 1.93e+03   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.5e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 461       |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 49        |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.36     |\n",
      "|    explained_variance | -42.70274 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | -279      |\n",
      "|    std                | 0.945     |\n",
      "|    value_loss         | 2.9e+04   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.5e+03   |\n",
      "| time/                 |            |\n",
      "|    fps                | 463        |\n",
      "|    iterations         | 4700       |\n",
      "|    time_elapsed       | 50         |\n",
      "|    total_timesteps    | 23500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.36      |\n",
      "|    explained_variance | -50.909187 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4699       |\n",
      "|    policy_loss        | -182       |\n",
      "|    std                | 0.939      |\n",
      "|    value_loss         | 2.74e+04   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.49e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 463       |\n",
      "|    iterations         | 4800      |\n",
      "|    time_elapsed       | 51        |\n",
      "|    total_timesteps    | 24000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.36     |\n",
      "|    explained_variance | -90.15137 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4799      |\n",
      "|    policy_loss        | -73.5     |\n",
      "|    std                | 0.945     |\n",
      "|    value_loss         | 1.24e+04  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.49e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 463        |\n",
      "|    iterations         | 4900       |\n",
      "|    time_elapsed       | 52         |\n",
      "|    total_timesteps    | 24500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.36      |\n",
      "|    explained_variance | -24.000517 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4899       |\n",
      "|    policy_loss        | -159       |\n",
      "|    std                | 0.945      |\n",
      "|    value_loss         | 1.04e+04   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.48e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 464       |\n",
      "|    iterations         | 5000      |\n",
      "|    time_elapsed       | 53        |\n",
      "|    total_timesteps    | 25000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.36     |\n",
      "|    explained_variance | -20.84853 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4999      |\n",
      "|    policy_loss        | -164      |\n",
      "|    std                | 0.947     |\n",
      "|    value_loss         | 1.54e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.48e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 464       |\n",
      "|    iterations         | 5100      |\n",
      "|    time_elapsed       | 54        |\n",
      "|    total_timesteps    | 25500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.36     |\n",
      "|    explained_variance | -1.858304 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5099      |\n",
      "|    policy_loss        | 20.1      |\n",
      "|    std                | 0.948     |\n",
      "|    value_loss         | 236       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.47e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 465        |\n",
      "|    iterations         | 5200       |\n",
      "|    time_elapsed       | 55         |\n",
      "|    total_timesteps    | 26000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.37      |\n",
      "|    explained_variance | 0.07982975 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5199       |\n",
      "|    policy_loss        | -9.19      |\n",
      "|    std                | 0.95       |\n",
      "|    value_loss         | 34.1       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.46e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 464        |\n",
      "|    iterations         | 5300       |\n",
      "|    time_elapsed       | 57         |\n",
      "|    total_timesteps    | 26500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.36      |\n",
      "|    explained_variance | -1636.3575 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5299       |\n",
      "|    policy_loss        | 214        |\n",
      "|    std                | 0.94       |\n",
      "|    value_loss         | 2.44e+04   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 200         |\n",
      "|    ep_rew_mean        | -1.46e+03   |\n",
      "| time/                 |             |\n",
      "|    fps                | 463         |\n",
      "|    iterations         | 5400        |\n",
      "|    time_elapsed       | 58          |\n",
      "|    total_timesteps    | 27000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.36       |\n",
      "|    explained_variance | -0.74414337 |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5399        |\n",
      "|    policy_loss        | -10.7       |\n",
      "|    std                | 0.943       |\n",
      "|    value_loss         | 122         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.46e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 463        |\n",
      "|    iterations         | 5500       |\n",
      "|    time_elapsed       | 59         |\n",
      "|    total_timesteps    | 27500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.36      |\n",
      "|    explained_variance | -26.321012 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5499       |\n",
      "|    policy_loss        | 19.3       |\n",
      "|    std                | 0.945      |\n",
      "|    value_loss         | 758        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.44e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 463       |\n",
      "|    iterations         | 5600      |\n",
      "|    time_elapsed       | 60        |\n",
      "|    total_timesteps    | 28000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.36     |\n",
      "|    explained_variance | 0.9481976 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5599      |\n",
      "|    policy_loss        | -15.4     |\n",
      "|    std                | 0.942     |\n",
      "|    value_loss         | 93.6      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.43e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 464        |\n",
      "|    iterations         | 5700       |\n",
      "|    time_elapsed       | 61         |\n",
      "|    total_timesteps    | 28500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.35      |\n",
      "|    explained_variance | 0.82830966 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5699       |\n",
      "|    policy_loss        | 7.19       |\n",
      "|    std                | 0.935      |\n",
      "|    value_loss         | 41.3       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.42e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 465       |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 62        |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.34     |\n",
      "|    explained_variance | -30.68928 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | -103      |\n",
      "|    std                | 0.926     |\n",
      "|    value_loss         | 7.92e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.42e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 464       |\n",
      "|    iterations         | 5900      |\n",
      "|    time_elapsed       | 63        |\n",
      "|    total_timesteps    | 29500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.35     |\n",
      "|    explained_variance | 0.54487   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5899      |\n",
      "|    policy_loss        | -1.74     |\n",
      "|    std                | 0.927     |\n",
      "|    value_loss         | 1.35      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.42e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 464        |\n",
      "|    iterations         | 6000       |\n",
      "|    time_elapsed       | 64         |\n",
      "|    total_timesteps    | 30000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.34      |\n",
      "|    explained_variance | 0.26640832 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5999       |\n",
      "|    policy_loss        | -3.61      |\n",
      "|    std                | 0.926      |\n",
      "|    value_loss         | 22.4       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.42e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 466        |\n",
      "|    iterations         | 6100       |\n",
      "|    time_elapsed       | 65         |\n",
      "|    total_timesteps    | 30500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.34      |\n",
      "|    explained_variance | -36.503616 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6099       |\n",
      "|    policy_loss        | -81.2      |\n",
      "|    std                | 0.926      |\n",
      "|    value_loss         | 4.5e+03    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.42e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 467       |\n",
      "|    iterations         | 6200      |\n",
      "|    time_elapsed       | 66        |\n",
      "|    total_timesteps    | 31000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.35     |\n",
      "|    explained_variance | 0.9336818 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6199      |\n",
      "|    policy_loss        | 3.96      |\n",
      "|    std                | 0.935     |\n",
      "|    value_loss         | 6.85      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.42e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 469        |\n",
      "|    iterations         | 6300       |\n",
      "|    time_elapsed       | 67         |\n",
      "|    total_timesteps    | 31500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.36      |\n",
      "|    explained_variance | -1052.0653 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6299       |\n",
      "|    policy_loss        | 119        |\n",
      "|    std                | 0.941      |\n",
      "|    value_loss         | 1.21e+04   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.42e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 471       |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 67        |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.37     |\n",
      "|    explained_variance | -2.655083 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | 7.48      |\n",
      "|    std                | 0.951     |\n",
      "|    value_loss         | 41.4      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.42e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 471        |\n",
      "|    iterations         | 6500       |\n",
      "|    time_elapsed       | 68         |\n",
      "|    total_timesteps    | 32500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.38      |\n",
      "|    explained_variance | -45.708076 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6499       |\n",
      "|    policy_loss        | 28.5       |\n",
      "|    std                | 0.963      |\n",
      "|    value_loss         | 777        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.42e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 472        |\n",
      "|    iterations         | 6600       |\n",
      "|    time_elapsed       | 69         |\n",
      "|    total_timesteps    | 33000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.38      |\n",
      "|    explained_variance | 0.97589386 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6599       |\n",
      "|    policy_loss        | 2.86       |\n",
      "|    std                | 0.957      |\n",
      "|    value_loss         | 5.39       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.41e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 473        |\n",
      "|    iterations         | 6700       |\n",
      "|    time_elapsed       | 70         |\n",
      "|    total_timesteps    | 33500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.36      |\n",
      "|    explained_variance | -1.4420705 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6699       |\n",
      "|    policy_loss        | 0.828      |\n",
      "|    std                | 0.938      |\n",
      "|    value_loss         | 19.5       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.4e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 474       |\n",
      "|    iterations         | 6800      |\n",
      "|    time_elapsed       | 71        |\n",
      "|    total_timesteps    | 34000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.35     |\n",
      "|    explained_variance | 0.9478162 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6799      |\n",
      "|    policy_loss        | -1.58     |\n",
      "|    std                | 0.938     |\n",
      "|    value_loss         | 4.19      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 200      |\n",
      "|    ep_rew_mean        | -1.4e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 476      |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.36    |\n",
      "|    explained_variance | 0.955784 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | -0.341   |\n",
      "|    std                | 0.94     |\n",
      "|    value_loss         | 1.32     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.39e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 7000      |\n",
      "|    time_elapsed       | 73        |\n",
      "|    total_timesteps    | 35000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.36     |\n",
      "|    explained_variance | -1.199312 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6999      |\n",
      "|    policy_loss        | 0.328     |\n",
      "|    std                | 0.946     |\n",
      "|    value_loss         | 2.1       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.39e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 480        |\n",
      "|    iterations         | 7100       |\n",
      "|    time_elapsed       | 73         |\n",
      "|    total_timesteps    | 35500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.36      |\n",
      "|    explained_variance | -5.5528474 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7099       |\n",
      "|    policy_loss        | 22.6       |\n",
      "|    std                | 0.941      |\n",
      "|    value_loss         | 337        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 200         |\n",
      "|    ep_rew_mean        | -1.38e+03   |\n",
      "| time/                 |             |\n",
      "|    fps                | 481         |\n",
      "|    iterations         | 7200        |\n",
      "|    time_elapsed       | 74          |\n",
      "|    total_timesteps    | 36000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.36       |\n",
      "|    explained_variance | -0.33951938 |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7199        |\n",
      "|    policy_loss        | 10.5        |\n",
      "|    std                | 0.941       |\n",
      "|    value_loss         | 93.5        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.38e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 481       |\n",
      "|    iterations         | 7300      |\n",
      "|    time_elapsed       | 75        |\n",
      "|    total_timesteps    | 36500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.37     |\n",
      "|    explained_variance | 0.3814094 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7299      |\n",
      "|    policy_loss        | 1.04      |\n",
      "|    std                | 0.951     |\n",
      "|    value_loss         | 1.22      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.38e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 482       |\n",
      "|    iterations         | 7400      |\n",
      "|    time_elapsed       | 76        |\n",
      "|    total_timesteps    | 37000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.37     |\n",
      "|    explained_variance | 0.861108  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7399      |\n",
      "|    policy_loss        | 0.85      |\n",
      "|    std                | 0.952     |\n",
      "|    value_loss         | 0.921     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.38e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 482       |\n",
      "|    iterations         | 7500      |\n",
      "|    time_elapsed       | 77        |\n",
      "|    total_timesteps    | 37500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.37     |\n",
      "|    explained_variance | 0.7900983 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7499      |\n",
      "|    policy_loss        | 2.82      |\n",
      "|    std                | 0.956     |\n",
      "|    value_loss         | 7.33      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 200         |\n",
      "|    ep_rew_mean        | -1.38e+03   |\n",
      "| time/                 |             |\n",
      "|    fps                | 482         |\n",
      "|    iterations         | 7600        |\n",
      "|    time_elapsed       | 78          |\n",
      "|    total_timesteps    | 38000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.38       |\n",
      "|    explained_variance | -0.68884456 |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7599        |\n",
      "|    policy_loss        | 3.71        |\n",
      "|    std                | 0.958       |\n",
      "|    value_loss         | 18.3        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.39e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 483       |\n",
      "|    iterations         | 7700      |\n",
      "|    time_elapsed       | 79        |\n",
      "|    total_timesteps    | 38500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.38     |\n",
      "|    explained_variance | 0.9551649 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7699      |\n",
      "|    policy_loss        | 1.76      |\n",
      "|    std                | 0.963     |\n",
      "|    value_loss         | 2.5       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.39e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 483        |\n",
      "|    iterations         | 7800       |\n",
      "|    time_elapsed       | 80         |\n",
      "|    total_timesteps    | 39000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.38      |\n",
      "|    explained_variance | -0.2943275 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7799       |\n",
      "|    policy_loss        | 1.58       |\n",
      "|    std                | 0.964      |\n",
      "|    value_loss         | 4.08       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.39e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 482        |\n",
      "|    iterations         | 7900       |\n",
      "|    time_elapsed       | 81         |\n",
      "|    total_timesteps    | 39500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.39      |\n",
      "|    explained_variance | 0.98508763 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7899       |\n",
      "|    policy_loss        | -4.25      |\n",
      "|    std                | 0.969      |\n",
      "|    value_loss         | 10.7       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.39e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 482       |\n",
      "|    iterations         | 8000      |\n",
      "|    time_elapsed       | 82        |\n",
      "|    total_timesteps    | 40000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.38     |\n",
      "|    explained_variance | 0.9216459 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7999      |\n",
      "|    policy_loss        | -0.544    |\n",
      "|    std                | 0.962     |\n",
      "|    value_loss         | 1.5       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.39e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 482        |\n",
      "|    iterations         | 8100       |\n",
      "|    time_elapsed       | 83         |\n",
      "|    total_timesteps    | 40500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.38      |\n",
      "|    explained_variance | 0.35279328 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8099       |\n",
      "|    policy_loss        | -1.66      |\n",
      "|    std                | 0.963      |\n",
      "|    value_loss         | 9.16       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.39e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 483       |\n",
      "|    iterations         | 8200      |\n",
      "|    time_elapsed       | 84        |\n",
      "|    total_timesteps    | 41000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.38     |\n",
      "|    explained_variance | 0.9254193 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8199      |\n",
      "|    policy_loss        | -3.09     |\n",
      "|    std                | 0.959     |\n",
      "|    value_loss         | 7.83      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.38e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 482        |\n",
      "|    iterations         | 8300       |\n",
      "|    time_elapsed       | 85         |\n",
      "|    total_timesteps    | 41500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.37      |\n",
      "|    explained_variance | 0.47362232 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8299       |\n",
      "|    policy_loss        | 1.7        |\n",
      "|    std                | 0.953      |\n",
      "|    value_loss         | 3.85       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.38e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 482       |\n",
      "|    iterations         | 8400      |\n",
      "|    time_elapsed       | 87        |\n",
      "|    total_timesteps    | 42000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.37     |\n",
      "|    explained_variance | 0.9374447 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8399      |\n",
      "|    policy_loss        | -4.01     |\n",
      "|    std                | 0.95      |\n",
      "|    value_loss         | 8.19      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.37e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 482        |\n",
      "|    iterations         | 8500       |\n",
      "|    time_elapsed       | 88         |\n",
      "|    total_timesteps    | 42500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.37      |\n",
      "|    explained_variance | -1.8336594 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8499       |\n",
      "|    policy_loss        | -0.738     |\n",
      "|    std                | 0.952      |\n",
      "|    value_loss         | 2.85       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.35e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 482       |\n",
      "|    iterations         | 8600      |\n",
      "|    time_elapsed       | 89        |\n",
      "|    total_timesteps    | 43000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.36     |\n",
      "|    explained_variance | 0.9821483 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8599      |\n",
      "|    policy_loss        | 6.16      |\n",
      "|    std                | 0.942     |\n",
      "|    value_loss         | 13.7      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.35e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 482        |\n",
      "|    iterations         | 8700       |\n",
      "|    time_elapsed       | 90         |\n",
      "|    total_timesteps    | 43500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.36      |\n",
      "|    explained_variance | 0.98154896 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8699       |\n",
      "|    policy_loss        | 2.6        |\n",
      "|    std                | 0.947      |\n",
      "|    value_loss         | 7.51       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.34e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 482       |\n",
      "|    iterations         | 8800      |\n",
      "|    time_elapsed       | 91        |\n",
      "|    total_timesteps    | 44000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.37     |\n",
      "|    explained_variance | 0.5250764 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8799      |\n",
      "|    policy_loss        | 6.84      |\n",
      "|    std                | 0.95      |\n",
      "|    value_loss         | 22.9      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.34e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 482        |\n",
      "|    iterations         | 8900       |\n",
      "|    time_elapsed       | 92         |\n",
      "|    total_timesteps    | 44500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.36      |\n",
      "|    explained_variance | -3.2520127 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8899       |\n",
      "|    policy_loss        | 9.74       |\n",
      "|    std                | 0.946      |\n",
      "|    value_loss         | 34.3       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.33e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 482       |\n",
      "|    iterations         | 9000      |\n",
      "|    time_elapsed       | 93        |\n",
      "|    total_timesteps    | 45000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.36     |\n",
      "|    explained_variance | 0.9710156 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8999      |\n",
      "|    policy_loss        | -6.38     |\n",
      "|    std                | 0.947     |\n",
      "|    value_loss         | 33.2      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 200         |\n",
      "|    ep_rew_mean        | -1.32e+03   |\n",
      "| time/                 |             |\n",
      "|    fps                | 481         |\n",
      "|    iterations         | 9100        |\n",
      "|    time_elapsed       | 94          |\n",
      "|    total_timesteps    | 45500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.36       |\n",
      "|    explained_variance | -0.25292134 |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9099        |\n",
      "|    policy_loss        | 1.34        |\n",
      "|    std                | 0.944       |\n",
      "|    value_loss         | 16.5        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.31e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 482       |\n",
      "|    iterations         | 9200      |\n",
      "|    time_elapsed       | 95        |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.36     |\n",
      "|    explained_variance | 0.9032755 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9199      |\n",
      "|    policy_loss        | -4.19     |\n",
      "|    std                | 0.947     |\n",
      "|    value_loss         | 27.1      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.31e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 481        |\n",
      "|    iterations         | 9300       |\n",
      "|    time_elapsed       | 96         |\n",
      "|    total_timesteps    | 46500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.37      |\n",
      "|    explained_variance | 0.94108135 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9299       |\n",
      "|    policy_loss        | -14.9      |\n",
      "|    std                | 0.954      |\n",
      "|    value_loss         | 61         |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.31e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 480        |\n",
      "|    iterations         | 9400       |\n",
      "|    time_elapsed       | 97         |\n",
      "|    total_timesteps    | 47000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.37      |\n",
      "|    explained_variance | 0.62417305 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9399       |\n",
      "|    policy_loss        | 2.93       |\n",
      "|    std                | 0.952      |\n",
      "|    value_loss         | 7.5        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.3e+03   |\n",
      "| time/                 |            |\n",
      "|    fps                | 481        |\n",
      "|    iterations         | 9500       |\n",
      "|    time_elapsed       | 98         |\n",
      "|    total_timesteps    | 47500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.37      |\n",
      "|    explained_variance | -16.440948 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9499       |\n",
      "|    policy_loss        | -2.33      |\n",
      "|    std                | 0.954      |\n",
      "|    value_loss         | 13.7       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.31e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 482        |\n",
      "|    iterations         | 9600       |\n",
      "|    time_elapsed       | 99         |\n",
      "|    total_timesteps    | 48000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.36      |\n",
      "|    explained_variance | 0.76084423 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9599       |\n",
      "|    policy_loss        | 4.23       |\n",
      "|    std                | 0.946      |\n",
      "|    value_loss         | 14.2       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.31e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 483       |\n",
      "|    iterations         | 9700      |\n",
      "|    time_elapsed       | 100       |\n",
      "|    total_timesteps    | 48500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.36     |\n",
      "|    explained_variance | 0.5322062 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9699      |\n",
      "|    policy_loss        | 8.45      |\n",
      "|    std                | 0.943     |\n",
      "|    value_loss         | 52.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.31e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 483       |\n",
      "|    iterations         | 9800      |\n",
      "|    time_elapsed       | 101       |\n",
      "|    total_timesteps    | 49000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.35     |\n",
      "|    explained_variance | 0.863413  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9799      |\n",
      "|    policy_loss        | -3.25     |\n",
      "|    std                | 0.934     |\n",
      "|    value_loss         | 4.57      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 200      |\n",
      "|    ep_rew_mean        | -1.3e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 484      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.35    |\n",
      "|    explained_variance | 0.867651 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | 13.6     |\n",
      "|    std                | 0.937    |\n",
      "|    value_loss         | 132      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.3e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 483       |\n",
      "|    iterations         | 10000     |\n",
      "|    time_elapsed       | 103       |\n",
      "|    total_timesteps    | 50000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.37     |\n",
      "|    explained_variance | 0.4959417 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9999      |\n",
      "|    policy_loss        | -21.8     |\n",
      "|    std                | 0.948     |\n",
      "|    value_loss         | 258       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.29e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 483       |\n",
      "|    iterations         | 10100     |\n",
      "|    time_elapsed       | 104       |\n",
      "|    total_timesteps    | 50500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.35     |\n",
      "|    explained_variance | 0.8309884 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10099     |\n",
      "|    policy_loss        | -12.9     |\n",
      "|    std                | 0.934     |\n",
      "|    value_loss         | 138       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.27e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 482       |\n",
      "|    iterations         | 10200     |\n",
      "|    time_elapsed       | 105       |\n",
      "|    total_timesteps    | 51000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.35     |\n",
      "|    explained_variance | -5.757651 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10199     |\n",
      "|    policy_loss        | 9.4       |\n",
      "|    std                | 0.933     |\n",
      "|    value_loss         | 84.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.26e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 482       |\n",
      "|    iterations         | 10300     |\n",
      "|    time_elapsed       | 106       |\n",
      "|    total_timesteps    | 51500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.35     |\n",
      "|    explained_variance | -2.958517 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10299     |\n",
      "|    policy_loss        | 19.3      |\n",
      "|    std                | 0.931     |\n",
      "|    value_loss         | 228       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.24e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 480        |\n",
      "|    iterations         | 10400      |\n",
      "|    time_elapsed       | 108        |\n",
      "|    total_timesteps    | 52000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.33      |\n",
      "|    explained_variance | 0.15248114 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 10399      |\n",
      "|    policy_loss        | 2.67       |\n",
      "|    std                | 0.919      |\n",
      "|    value_loss         | 5.94       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 200         |\n",
      "|    ep_rew_mean        | -1.23e+03   |\n",
      "| time/                 |             |\n",
      "|    fps                | 480         |\n",
      "|    iterations         | 10500       |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 52500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.33       |\n",
      "|    explained_variance | -0.82001865 |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10499       |\n",
      "|    policy_loss        | 43.1        |\n",
      "|    std                | 0.915       |\n",
      "|    value_loss         | 356         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.22e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 479        |\n",
      "|    iterations         | 10600      |\n",
      "|    time_elapsed       | 110        |\n",
      "|    total_timesteps    | 53000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.33      |\n",
      "|    explained_variance | 0.91796386 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 10599      |\n",
      "|    policy_loss        | 0.999      |\n",
      "|    std                | 0.916      |\n",
      "|    value_loss         | 0.956      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.22e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 479        |\n",
      "|    iterations         | 10700      |\n",
      "|    time_elapsed       | 111        |\n",
      "|    total_timesteps    | 53500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.33      |\n",
      "|    explained_variance | -35.829807 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 10699      |\n",
      "|    policy_loss        | 56.3       |\n",
      "|    std                | 0.916      |\n",
      "|    value_loss         | 2.46e+03   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.22e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 477        |\n",
      "|    iterations         | 10800      |\n",
      "|    time_elapsed       | 113        |\n",
      "|    total_timesteps    | 54000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.33      |\n",
      "|    explained_variance | -5.8722515 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 10799      |\n",
      "|    policy_loss        | -33.6      |\n",
      "|    std                | 0.913      |\n",
      "|    value_loss         | 1.31e+03   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.21e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 476        |\n",
      "|    iterations         | 10900      |\n",
      "|    time_elapsed       | 114        |\n",
      "|    total_timesteps    | 54500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.33      |\n",
      "|    explained_variance | -26.755503 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 10899      |\n",
      "|    policy_loss        | 30.9       |\n",
      "|    std                | 0.91       |\n",
      "|    value_loss         | 992        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.22e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 475        |\n",
      "|    iterations         | 11000      |\n",
      "|    time_elapsed       | 115        |\n",
      "|    total_timesteps    | 55000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.33      |\n",
      "|    explained_variance | 0.88186455 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 10999      |\n",
      "|    policy_loss        | 7.2        |\n",
      "|    std                | 0.918      |\n",
      "|    value_loss         | 22.7       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.2e+03   |\n",
      "| time/                 |            |\n",
      "|    fps                | 474        |\n",
      "|    iterations         | 11100      |\n",
      "|    time_elapsed       | 116        |\n",
      "|    total_timesteps    | 55500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.33      |\n",
      "|    explained_variance | -50.689816 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 11099      |\n",
      "|    policy_loss        | 93.8       |\n",
      "|    std                | 0.916      |\n",
      "|    value_loss         | 3.93e+03   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.21e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 472        |\n",
      "|    iterations         | 11200      |\n",
      "|    time_elapsed       | 118        |\n",
      "|    total_timesteps    | 56000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.34      |\n",
      "|    explained_variance | -13.157668 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 11199      |\n",
      "|    policy_loss        | -15.6      |\n",
      "|    std                | 0.923      |\n",
      "|    value_loss         | 200        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 200         |\n",
      "|    ep_rew_mean        | -1.21e+03   |\n",
      "| time/                 |             |\n",
      "|    fps                | 472         |\n",
      "|    iterations         | 11300       |\n",
      "|    time_elapsed       | 119         |\n",
      "|    total_timesteps    | 56500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.34       |\n",
      "|    explained_variance | -0.02885437 |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11299       |\n",
      "|    policy_loss        | -17.4       |\n",
      "|    std                | 0.926       |\n",
      "|    value_loss         | 264         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.2e+03   |\n",
      "| time/                 |            |\n",
      "|    fps                | 472        |\n",
      "|    iterations         | 11400      |\n",
      "|    time_elapsed       | 120        |\n",
      "|    total_timesteps    | 57000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.35      |\n",
      "|    explained_variance | -158.45609 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 11399      |\n",
      "|    policy_loss        | 12.2       |\n",
      "|    std                | 0.931      |\n",
      "|    value_loss         | 321        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.21e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 471        |\n",
      "|    iterations         | 11500      |\n",
      "|    time_elapsed       | 121        |\n",
      "|    total_timesteps    | 57500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.34      |\n",
      "|    explained_variance | -11.910566 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 11499      |\n",
      "|    policy_loss        | 48.7       |\n",
      "|    std                | 0.926      |\n",
      "|    value_loss         | 623        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.19e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 470        |\n",
      "|    iterations         | 11600      |\n",
      "|    time_elapsed       | 123        |\n",
      "|    total_timesteps    | 58000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.33      |\n",
      "|    explained_variance | -480.06537 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 11599      |\n",
      "|    policy_loss        | 57.4       |\n",
      "|    std                | 0.913      |\n",
      "|    value_loss         | 3.19e+03   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.18e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 470       |\n",
      "|    iterations         | 11700     |\n",
      "|    time_elapsed       | 124       |\n",
      "|    total_timesteps    | 58500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.34     |\n",
      "|    explained_variance | -4.349347 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11699     |\n",
      "|    policy_loss        | -58.9     |\n",
      "|    std                | 0.923     |\n",
      "|    value_loss         | 2.59e+03  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.17e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 467        |\n",
      "|    iterations         | 11800      |\n",
      "|    time_elapsed       | 126        |\n",
      "|    total_timesteps    | 59000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.34      |\n",
      "|    explained_variance | -25.075285 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 11799      |\n",
      "|    policy_loss        | 80.5       |\n",
      "|    std                | 0.923      |\n",
      "|    value_loss         | 5.31e+03   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.16e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 467       |\n",
      "|    iterations         | 11900     |\n",
      "|    time_elapsed       | 127       |\n",
      "|    total_timesteps    | 59500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.34     |\n",
      "|    explained_variance | -636.8742 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11899     |\n",
      "|    policy_loss        | 77.9      |\n",
      "|    std                | 0.921     |\n",
      "|    value_loss         | 4.23e+03  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.15e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 466        |\n",
      "|    iterations         | 12000      |\n",
      "|    time_elapsed       | 128        |\n",
      "|    total_timesteps    | 60000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.32      |\n",
      "|    explained_variance | -5.3198376 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 11999      |\n",
      "|    policy_loss        | 63.8       |\n",
      "|    std                | 0.906      |\n",
      "|    value_loss         | 3.7e+03    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.14e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 466        |\n",
      "|    iterations         | 12100      |\n",
      "|    time_elapsed       | 129        |\n",
      "|    total_timesteps    | 60500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.31      |\n",
      "|    explained_variance | 0.46825182 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 12099      |\n",
      "|    policy_loss        | 12         |\n",
      "|    std                | 0.896      |\n",
      "|    value_loss         | 151        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.13e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 466        |\n",
      "|    iterations         | 12200      |\n",
      "|    time_elapsed       | 130        |\n",
      "|    total_timesteps    | 61000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.3       |\n",
      "|    explained_variance | -6.9102855 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 12199      |\n",
      "|    policy_loss        | 25.3       |\n",
      "|    std                | 0.886      |\n",
      "|    value_loss         | 645        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.11e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 465        |\n",
      "|    iterations         | 12300      |\n",
      "|    time_elapsed       | 132        |\n",
      "|    total_timesteps    | 61500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.28      |\n",
      "|    explained_variance | 0.76467824 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 12299      |\n",
      "|    policy_loss        | 8.8        |\n",
      "|    std                | 0.874      |\n",
      "|    value_loss         | 47.4       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.09e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 465       |\n",
      "|    iterations         | 12400     |\n",
      "|    time_elapsed       | 133       |\n",
      "|    total_timesteps    | 62000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.28     |\n",
      "|    explained_variance | -4.179808 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12399     |\n",
      "|    policy_loss        | 39.1      |\n",
      "|    std                | 0.869     |\n",
      "|    value_loss         | 956       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.08e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 464        |\n",
      "|    iterations         | 12500      |\n",
      "|    time_elapsed       | 134        |\n",
      "|    total_timesteps    | 62500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.28      |\n",
      "|    explained_variance | -97.003944 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 12499      |\n",
      "|    policy_loss        | 36.4       |\n",
      "|    std                | 0.874      |\n",
      "|    value_loss         | 845        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.07e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 464        |\n",
      "|    iterations         | 12600      |\n",
      "|    time_elapsed       | 135        |\n",
      "|    total_timesteps    | 63000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.27      |\n",
      "|    explained_variance | 0.16882086 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 12599      |\n",
      "|    policy_loss        | 15.1       |\n",
      "|    std                | 0.867      |\n",
      "|    value_loss         | 97.2       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.08e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 464        |\n",
      "|    iterations         | 12700      |\n",
      "|    time_elapsed       | 136        |\n",
      "|    total_timesteps    | 63500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.27      |\n",
      "|    explained_variance | -7.1080265 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 12699      |\n",
      "|    policy_loss        | -36.1      |\n",
      "|    std                | 0.865      |\n",
      "|    value_loss         | 617        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.08e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 462        |\n",
      "|    iterations         | 12800      |\n",
      "|    time_elapsed       | 138        |\n",
      "|    total_timesteps    | 64000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.28      |\n",
      "|    explained_variance | -1.7058299 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 12799      |\n",
      "|    policy_loss        | -4.4       |\n",
      "|    std                | 0.868      |\n",
      "|    value_loss         | 33         |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.08e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 463        |\n",
      "|    iterations         | 12900      |\n",
      "|    time_elapsed       | 139        |\n",
      "|    total_timesteps    | 64500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.27      |\n",
      "|    explained_variance | 0.46241772 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 12899      |\n",
      "|    policy_loss        | 1.71       |\n",
      "|    std                | 0.86       |\n",
      "|    value_loss         | 3.38       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.09e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 462       |\n",
      "|    iterations         | 13000     |\n",
      "|    time_elapsed       | 140       |\n",
      "|    total_timesteps    | 65000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.26     |\n",
      "|    explained_variance | -0.594918 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12999     |\n",
      "|    policy_loss        | -3.25     |\n",
      "|    std                | 0.857     |\n",
      "|    value_loss         | 58.7      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.1e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 462       |\n",
      "|    iterations         | 13100     |\n",
      "|    time_elapsed       | 141       |\n",
      "|    total_timesteps    | 65500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.26     |\n",
      "|    explained_variance | 0.8520913 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13099     |\n",
      "|    policy_loss        | 5.22      |\n",
      "|    std                | 0.85      |\n",
      "|    value_loss         | 23.5      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.1e+03   |\n",
      "| time/                 |            |\n",
      "|    fps                | 461        |\n",
      "|    iterations         | 13200      |\n",
      "|    time_elapsed       | 142        |\n",
      "|    total_timesteps    | 66000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.24      |\n",
      "|    explained_variance | 0.79278886 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 13199      |\n",
      "|    policy_loss        | 0.0975     |\n",
      "|    std                | 0.84       |\n",
      "|    value_loss         | 1.29       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 200          |\n",
      "|    ep_rew_mean        | -1.1e+03     |\n",
      "| time/                 |              |\n",
      "|    fps                | 460          |\n",
      "|    iterations         | 13300        |\n",
      "|    time_elapsed       | 144          |\n",
      "|    total_timesteps    | 66500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.23        |\n",
      "|    explained_variance | -0.039749026 |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 13299        |\n",
      "|    policy_loss        | -8.71        |\n",
      "|    std                | 0.829        |\n",
      "|    value_loss         | 133          |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 200         |\n",
      "|    ep_rew_mean        | -1.1e+03    |\n",
      "| time/                 |             |\n",
      "|    fps                | 460         |\n",
      "|    iterations         | 13400       |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 67000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.23       |\n",
      "|    explained_variance | -0.10912132 |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13399       |\n",
      "|    policy_loss        | 1.31        |\n",
      "|    std                | 0.828       |\n",
      "|    value_loss         | 19.3        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.09e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 460        |\n",
      "|    iterations         | 13500      |\n",
      "|    time_elapsed       | 146        |\n",
      "|    total_timesteps    | 67500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.22      |\n",
      "|    explained_variance | 0.86238116 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 13499      |\n",
      "|    policy_loss        | -1.5       |\n",
      "|    std                | 0.82       |\n",
      "|    value_loss         | 2.69       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.09e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 460       |\n",
      "|    iterations         | 13600     |\n",
      "|    time_elapsed       | 147       |\n",
      "|    total_timesteps    | 68000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.21     |\n",
      "|    explained_variance | 0.7591566 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13599     |\n",
      "|    policy_loss        | 7.59      |\n",
      "|    std                | 0.812     |\n",
      "|    value_loss         | 30        |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.09e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 458        |\n",
      "|    iterations         | 13700      |\n",
      "|    time_elapsed       | 149        |\n",
      "|    total_timesteps    | 68500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.21      |\n",
      "|    explained_variance | -10.354326 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 13699      |\n",
      "|    policy_loss        | 21.4       |\n",
      "|    std                | 0.809      |\n",
      "|    value_loss         | 696        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.09e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 458       |\n",
      "|    iterations         | 13800     |\n",
      "|    time_elapsed       | 150       |\n",
      "|    total_timesteps    | 69000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.19     |\n",
      "|    explained_variance | 0.5901553 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13799     |\n",
      "|    policy_loss        | -14.3     |\n",
      "|    std                | 0.798     |\n",
      "|    value_loss         | 120       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.08e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 458       |\n",
      "|    iterations         | 13900     |\n",
      "|    time_elapsed       | 151       |\n",
      "|    total_timesteps    | 69500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.2      |\n",
      "|    explained_variance | -77.26259 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13899     |\n",
      "|    policy_loss        | 28.9      |\n",
      "|    std                | 0.8       |\n",
      "|    value_loss         | 896       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.09e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 457        |\n",
      "|    iterations         | 14000      |\n",
      "|    time_elapsed       | 152        |\n",
      "|    total_timesteps    | 70000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.19      |\n",
      "|    explained_variance | -1.3042421 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 13999      |\n",
      "|    policy_loss        | -1.67      |\n",
      "|    std                | 0.797      |\n",
      "|    value_loss         | 1.37       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 200         |\n",
      "|    ep_rew_mean        | -1.09e+03   |\n",
      "| time/                 |             |\n",
      "|    fps                | 457         |\n",
      "|    iterations         | 14100       |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 70500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.19       |\n",
      "|    explained_variance | -0.12006223 |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14099       |\n",
      "|    policy_loss        | -17.1       |\n",
      "|    std                | 0.798       |\n",
      "|    value_loss         | 147         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 200         |\n",
      "|    ep_rew_mean        | -1.1e+03    |\n",
      "| time/                 |             |\n",
      "|    fps                | 456         |\n",
      "|    iterations         | 14200       |\n",
      "|    time_elapsed       | 155         |\n",
      "|    total_timesteps    | 71000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.2        |\n",
      "|    explained_variance | -0.15506017 |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14199       |\n",
      "|    policy_loss        | -15.5       |\n",
      "|    std                | 0.803       |\n",
      "|    value_loss         | 295         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.11e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 456        |\n",
      "|    iterations         | 14300      |\n",
      "|    time_elapsed       | 156        |\n",
      "|    total_timesteps    | 71500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.2       |\n",
      "|    explained_variance | 0.15739775 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 14299      |\n",
      "|    policy_loss        | -2.82      |\n",
      "|    std                | 0.801      |\n",
      "|    value_loss         | 12.5       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.12e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 455       |\n",
      "|    iterations         | 14400     |\n",
      "|    time_elapsed       | 158       |\n",
      "|    total_timesteps    | 72000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.2      |\n",
      "|    explained_variance | 0.7025137 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 14399     |\n",
      "|    policy_loss        | 4.08      |\n",
      "|    std                | 0.8       |\n",
      "|    value_loss         | 15.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.13e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 454       |\n",
      "|    iterations         | 14500     |\n",
      "|    time_elapsed       | 159       |\n",
      "|    total_timesteps    | 72500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.2      |\n",
      "|    explained_variance | -78.69622 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 14499     |\n",
      "|    policy_loss        | 4.93      |\n",
      "|    std                | 0.803     |\n",
      "|    value_loss         | 31.6      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.14e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 454        |\n",
      "|    iterations         | 14600      |\n",
      "|    time_elapsed       | 160        |\n",
      "|    total_timesteps    | 73000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.2       |\n",
      "|    explained_variance | -3.4565787 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 14599      |\n",
      "|    policy_loss        | -4.15      |\n",
      "|    std                | 0.802      |\n",
      "|    value_loss         | 111        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.14e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 453       |\n",
      "|    iterations         | 14700     |\n",
      "|    time_elapsed       | 162       |\n",
      "|    total_timesteps    | 73500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.21     |\n",
      "|    explained_variance | -7.821206 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 14699     |\n",
      "|    policy_loss        | 36.1      |\n",
      "|    std                | 0.808     |\n",
      "|    value_loss         | 668       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.15e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 453        |\n",
      "|    iterations         | 14800      |\n",
      "|    time_elapsed       | 163        |\n",
      "|    total_timesteps    | 74000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.21      |\n",
      "|    explained_variance | 0.55077684 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 14799      |\n",
      "|    policy_loss        | 7.88       |\n",
      "|    std                | 0.811      |\n",
      "|    value_loss         | 75.1       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.15e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 453       |\n",
      "|    iterations         | 14900     |\n",
      "|    time_elapsed       | 164       |\n",
      "|    total_timesteps    | 74500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.2      |\n",
      "|    explained_variance | -22.07081 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 14899     |\n",
      "|    policy_loss        | -36.9     |\n",
      "|    std                | 0.802     |\n",
      "|    value_loss         | 855       |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 200         |\n",
      "|    ep_rew_mean        | -1.15e+03   |\n",
      "| time/                 |             |\n",
      "|    fps                | 451         |\n",
      "|    iterations         | 15000       |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 75000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -1.19       |\n",
      "|    explained_variance | -0.72769415 |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14999       |\n",
      "|    policy_loss        | 9.82        |\n",
      "|    std                | 0.797       |\n",
      "|    value_loss         | 67.6        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.15e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 451       |\n",
      "|    iterations         | 15100     |\n",
      "|    time_elapsed       | 167       |\n",
      "|    total_timesteps    | 75500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.18     |\n",
      "|    explained_variance | -9.418714 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 15099     |\n",
      "|    policy_loss        | -54.1     |\n",
      "|    std                | 0.788     |\n",
      "|    value_loss         | 2e+03     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.14e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 450       |\n",
      "|    iterations         | 15200     |\n",
      "|    time_elapsed       | 168       |\n",
      "|    total_timesteps    | 76000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.19     |\n",
      "|    explained_variance | 0.7971531 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 15199     |\n",
      "|    policy_loss        | 2.55      |\n",
      "|    std                | 0.793     |\n",
      "|    value_loss         | 4.8       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.13e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 450        |\n",
      "|    iterations         | 15300      |\n",
      "|    time_elapsed       | 169        |\n",
      "|    total_timesteps    | 76500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.19      |\n",
      "|    explained_variance | 0.87863636 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 15299      |\n",
      "|    policy_loss        | -2.97      |\n",
      "|    std                | 0.793      |\n",
      "|    value_loss         | 16.5       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.13e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 450        |\n",
      "|    iterations         | 15400      |\n",
      "|    time_elapsed       | 170        |\n",
      "|    total_timesteps    | 77000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.19      |\n",
      "|    explained_variance | -3.3965468 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 15399      |\n",
      "|    policy_loss        | -35.2      |\n",
      "|    std                | 0.794      |\n",
      "|    value_loss         | 1.73e+03   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.12e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 450        |\n",
      "|    iterations         | 15500      |\n",
      "|    time_elapsed       | 172        |\n",
      "|    total_timesteps    | 77500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.18      |\n",
      "|    explained_variance | -2.8279672 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 15499      |\n",
      "|    policy_loss        | 18.4       |\n",
      "|    std                | 0.791      |\n",
      "|    value_loss         | 133        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.12e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 449       |\n",
      "|    iterations         | 15600     |\n",
      "|    time_elapsed       | 173       |\n",
      "|    total_timesteps    | 78000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.18     |\n",
      "|    explained_variance | -4.699931 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 15599     |\n",
      "|    policy_loss        | 16.5      |\n",
      "|    std                | 0.784     |\n",
      "|    value_loss         | 472       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.11e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 448        |\n",
      "|    iterations         | 15700      |\n",
      "|    time_elapsed       | 174        |\n",
      "|    total_timesteps    | 78500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.16      |\n",
      "|    explained_variance | 0.38708818 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 15699      |\n",
      "|    policy_loss        | 3.92       |\n",
      "|    std                | 0.773      |\n",
      "|    value_loss         | 26.2       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.12e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 448        |\n",
      "|    iterations         | 15800      |\n",
      "|    time_elapsed       | 176        |\n",
      "|    total_timesteps    | 79000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.15      |\n",
      "|    explained_variance | -1.6497011 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 15799      |\n",
      "|    policy_loss        | -3.9       |\n",
      "|    std                | 0.767      |\n",
      "|    value_loss         | 34.4       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.1e+03   |\n",
      "| time/                 |            |\n",
      "|    fps                | 447        |\n",
      "|    iterations         | 15900      |\n",
      "|    time_elapsed       | 177        |\n",
      "|    total_timesteps    | 79500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.14      |\n",
      "|    explained_variance | 0.53080636 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 15899      |\n",
      "|    policy_loss        | 1.55       |\n",
      "|    std                | 0.759      |\n",
      "|    value_loss         | 4.34       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.1e+03   |\n",
      "| time/                 |            |\n",
      "|    fps                | 447        |\n",
      "|    iterations         | 16000      |\n",
      "|    time_elapsed       | 178        |\n",
      "|    total_timesteps    | 80000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.13      |\n",
      "|    explained_variance | -5.6258535 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 15999      |\n",
      "|    policy_loss        | -54        |\n",
      "|    std                | 0.753      |\n",
      "|    value_loss         | 1.41e+03   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.11e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 447       |\n",
      "|    iterations         | 16100     |\n",
      "|    time_elapsed       | 180       |\n",
      "|    total_timesteps    | 80500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.13     |\n",
      "|    explained_variance | -36.51694 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 16099     |\n",
      "|    policy_loss        | 16        |\n",
      "|    std                | 0.753     |\n",
      "|    value_loss         | 826       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.12e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 446        |\n",
      "|    iterations         | 16200      |\n",
      "|    time_elapsed       | 181        |\n",
      "|    total_timesteps    | 81000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.13      |\n",
      "|    explained_variance | -3.4215713 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 16199      |\n",
      "|    policy_loss        | 3.35       |\n",
      "|    std                | 0.748      |\n",
      "|    value_loss         | 10.1       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.13e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 446       |\n",
      "|    iterations         | 16300     |\n",
      "|    time_elapsed       | 182       |\n",
      "|    total_timesteps    | 81500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.11     |\n",
      "|    explained_variance | -662.1909 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 16299     |\n",
      "|    policy_loss        | 30.1      |\n",
      "|    std                | 0.734     |\n",
      "|    value_loss         | 1.65e+03  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.14e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 446        |\n",
      "|    iterations         | 16400      |\n",
      "|    time_elapsed       | 183        |\n",
      "|    total_timesteps    | 82000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.11      |\n",
      "|    explained_variance | -105.54049 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 16399      |\n",
      "|    policy_loss        | 7.4        |\n",
      "|    std                | 0.734      |\n",
      "|    value_loss         | 560        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.13e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 446       |\n",
      "|    iterations         | 16500     |\n",
      "|    time_elapsed       | 184       |\n",
      "|    total_timesteps    | 82500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.09     |\n",
      "|    explained_variance | -44.00785 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 16499     |\n",
      "|    policy_loss        | 2.74      |\n",
      "|    std                | 0.721     |\n",
      "|    value_loss         | 30.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.14e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 446       |\n",
      "|    iterations         | 16600     |\n",
      "|    time_elapsed       | 186       |\n",
      "|    total_timesteps    | 83000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.08     |\n",
      "|    explained_variance | 0.357449  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 16599     |\n",
      "|    policy_loss        | -13.7     |\n",
      "|    std                | 0.712     |\n",
      "|    value_loss         | 104       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.13e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 445       |\n",
      "|    iterations         | 16700     |\n",
      "|    time_elapsed       | 187       |\n",
      "|    total_timesteps    | 83500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.07     |\n",
      "|    explained_variance | -6.281517 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 16699     |\n",
      "|    policy_loss        | 1.19      |\n",
      "|    std                | 0.707     |\n",
      "|    value_loss         | 2.47      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.11e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 445       |\n",
      "|    iterations         | 16800     |\n",
      "|    time_elapsed       | 188       |\n",
      "|    total_timesteps    | 84000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.07     |\n",
      "|    explained_variance | -4.689498 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 16799     |\n",
      "|    policy_loss        | 0.303     |\n",
      "|    std                | 0.702     |\n",
      "|    value_loss         | 0.481     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.1e+03   |\n",
      "| time/                 |            |\n",
      "|    fps                | 444        |\n",
      "|    iterations         | 16900      |\n",
      "|    time_elapsed       | 190        |\n",
      "|    total_timesteps    | 84500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.06      |\n",
      "|    explained_variance | -27.662453 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 16899      |\n",
      "|    policy_loss        | -50.6      |\n",
      "|    std                | 0.7        |\n",
      "|    value_loss         | 3.84e+03   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.08e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 444        |\n",
      "|    iterations         | 17000      |\n",
      "|    time_elapsed       | 191        |\n",
      "|    total_timesteps    | 85000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.05      |\n",
      "|    explained_variance | -2.0265477 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 16999      |\n",
      "|    policy_loss        | 7.86       |\n",
      "|    std                | 0.691      |\n",
      "|    value_loss         | 45.7       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 200          |\n",
      "|    ep_rew_mean        | -1.07e+03    |\n",
      "| time/                 |              |\n",
      "|    fps                | 444          |\n",
      "|    iterations         | 17100        |\n",
      "|    time_elapsed       | 192          |\n",
      "|    total_timesteps    | 85500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -1.02        |\n",
      "|    explained_variance | -0.094239235 |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 17099        |\n",
      "|    policy_loss        | -0.00611     |\n",
      "|    std                | 0.674        |\n",
      "|    value_loss         | 0.000102     |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.06e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 444       |\n",
      "|    iterations         | 17200     |\n",
      "|    time_elapsed       | 193       |\n",
      "|    total_timesteps    | 86000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.02     |\n",
      "|    explained_variance | -2.527805 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 17199     |\n",
      "|    policy_loss        | -8.29     |\n",
      "|    std                | 0.674     |\n",
      "|    value_loss         | 24        |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.04e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 444        |\n",
      "|    iterations         | 17300      |\n",
      "|    time_elapsed       | 194        |\n",
      "|    total_timesteps    | 86500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.02      |\n",
      "|    explained_variance | -703.06213 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 17299      |\n",
      "|    policy_loss        | -0.0136    |\n",
      "|    std                | 0.674      |\n",
      "|    value_loss         | 0.000452   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.03e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 443       |\n",
      "|    iterations         | 17400     |\n",
      "|    time_elapsed       | 196       |\n",
      "|    total_timesteps    | 87000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.02     |\n",
      "|    explained_variance | 0.8971411 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 17399     |\n",
      "|    policy_loss        | 0.299     |\n",
      "|    std                | 0.668     |\n",
      "|    value_loss         | 0.873     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.03e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 443        |\n",
      "|    iterations         | 17500      |\n",
      "|    time_elapsed       | 197        |\n",
      "|    total_timesteps    | 87500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1.02      |\n",
      "|    explained_variance | -43.717556 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 17499      |\n",
      "|    policy_loss        | -127       |\n",
      "|    std                | 0.671      |\n",
      "|    value_loss         | 1.43e+04   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1.01e+03  |\n",
      "| time/                 |            |\n",
      "|    fps                | 443        |\n",
      "|    iterations         | 17600      |\n",
      "|    time_elapsed       | 198        |\n",
      "|    total_timesteps    | 88000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -1         |\n",
      "|    explained_variance | -2.2636847 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 17599      |\n",
      "|    policy_loss        | 0.0274     |\n",
      "|    std                | 0.658      |\n",
      "|    value_loss         | 0.000515   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -996       |\n",
      "| time/                 |            |\n",
      "|    fps                | 443        |\n",
      "|    iterations         | 17700      |\n",
      "|    time_elapsed       | 199        |\n",
      "|    total_timesteps    | 88500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -0.983     |\n",
      "|    explained_variance | -42.091915 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 17699      |\n",
      "|    policy_loss        | 0.0115     |\n",
      "|    std                | 0.647      |\n",
      "|    value_loss         | 0.000759   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -984       |\n",
      "| time/                 |            |\n",
      "|    fps                | 443        |\n",
      "|    iterations         | 17800      |\n",
      "|    time_elapsed       | 200        |\n",
      "|    total_timesteps    | 89000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -0.983     |\n",
      "|    explained_variance | 0.90927863 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 17799      |\n",
      "|    policy_loss        | -1.97      |\n",
      "|    std                | 0.647      |\n",
      "|    value_loss         | 6.55       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -996       |\n",
      "| time/                 |            |\n",
      "|    fps                | 442        |\n",
      "|    iterations         | 17900      |\n",
      "|    time_elapsed       | 202        |\n",
      "|    total_timesteps    | 89500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -0.983     |\n",
      "|    explained_variance | -14.599709 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 17899      |\n",
      "|    policy_loss        | 4.03       |\n",
      "|    std                | 0.646      |\n",
      "|    value_loss         | 39.6       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -1e+03     |\n",
      "| time/                 |            |\n",
      "|    fps                | 442        |\n",
      "|    iterations         | 18000      |\n",
      "|    time_elapsed       | 203        |\n",
      "|    total_timesteps    | 90000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -0.981     |\n",
      "|    explained_variance | 0.50563574 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 17999      |\n",
      "|    policy_loss        | -6.33      |\n",
      "|    std                | 0.646      |\n",
      "|    value_loss         | 77.9       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -976      |\n",
      "| time/                 |           |\n",
      "|    fps                | 442       |\n",
      "|    iterations         | 18100     |\n",
      "|    time_elapsed       | 204       |\n",
      "|    total_timesteps    | 90500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.96     |\n",
      "|    explained_variance | -3.534841 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 18099     |\n",
      "|    policy_loss        | 58.8      |\n",
      "|    std                | 0.632     |\n",
      "|    value_loss         | 3.08e+03  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -982       |\n",
      "| time/                 |            |\n",
      "|    fps                | 442        |\n",
      "|    iterations         | 18200      |\n",
      "|    time_elapsed       | 205        |\n",
      "|    total_timesteps    | 91000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -0.964     |\n",
      "|    explained_variance | -11.868114 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 18199      |\n",
      "|    policy_loss        | -65.1      |\n",
      "|    std                | 0.634      |\n",
      "|    value_loss         | 4.14e+03   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -980       |\n",
      "| time/                 |            |\n",
      "|    fps                | 441        |\n",
      "|    iterations         | 18300      |\n",
      "|    time_elapsed       | 207        |\n",
      "|    total_timesteps    | 91500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -0.952     |\n",
      "|    explained_variance | -20.448204 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 18299      |\n",
      "|    policy_loss        | 0.0495     |\n",
      "|    std                | 0.627      |\n",
      "|    value_loss         | 0.00377    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -970       |\n",
      "| time/                 |            |\n",
      "|    fps                | 441        |\n",
      "|    iterations         | 18400      |\n",
      "|    time_elapsed       | 208        |\n",
      "|    total_timesteps    | 92000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -0.951     |\n",
      "|    explained_variance | 0.36896235 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 18399      |\n",
      "|    policy_loss        | -2.87      |\n",
      "|    std                | 0.626      |\n",
      "|    value_loss         | 27.1       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -948       |\n",
      "| time/                 |            |\n",
      "|    fps                | 441        |\n",
      "|    iterations         | 18500      |\n",
      "|    time_elapsed       | 209        |\n",
      "|    total_timesteps    | 92500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -0.944     |\n",
      "|    explained_variance | -1.4150543 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 18499      |\n",
      "|    policy_loss        | -14.7      |\n",
      "|    std                | 0.622      |\n",
      "|    value_loss         | 200        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -941       |\n",
      "| time/                 |            |\n",
      "|    fps                | 440        |\n",
      "|    iterations         | 18600      |\n",
      "|    time_elapsed       | 210        |\n",
      "|    total_timesteps    | 93000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -0.929     |\n",
      "|    explained_variance | -2.9037309 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 18599      |\n",
      "|    policy_loss        | -8         |\n",
      "|    std                | 0.613      |\n",
      "|    value_loss         | 45.6       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -946       |\n",
      "| time/                 |            |\n",
      "|    fps                | 441        |\n",
      "|    iterations         | 18700      |\n",
      "|    time_elapsed       | 211        |\n",
      "|    total_timesteps    | 93500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -0.931     |\n",
      "|    explained_variance | -0.5419524 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 18699      |\n",
      "|    policy_loss        | 5.8        |\n",
      "|    std                | 0.614      |\n",
      "|    value_loss         | 112        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -947       |\n",
      "| time/                 |            |\n",
      "|    fps                | 440        |\n",
      "|    iterations         | 18800      |\n",
      "|    time_elapsed       | 213        |\n",
      "|    total_timesteps    | 94000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -0.934     |\n",
      "|    explained_variance | 0.70503044 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 18799      |\n",
      "|    policy_loss        | 1.53       |\n",
      "|    std                | 0.616      |\n",
      "|    value_loss         | 2.88       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -930       |\n",
      "| time/                 |            |\n",
      "|    fps                | 441        |\n",
      "|    iterations         | 18900      |\n",
      "|    time_elapsed       | 214        |\n",
      "|    total_timesteps    | 94500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -0.908     |\n",
      "|    explained_variance | -632.47894 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 18899      |\n",
      "|    policy_loss        | 0.0515     |\n",
      "|    std                | 0.601      |\n",
      "|    value_loss         | 0.016      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -919       |\n",
      "| time/                 |            |\n",
      "|    fps                | 440        |\n",
      "|    iterations         | 19000      |\n",
      "|    time_elapsed       | 215        |\n",
      "|    total_timesteps    | 95000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -0.899     |\n",
      "|    explained_variance | -73.553604 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 18999      |\n",
      "|    policy_loss        | -191       |\n",
      "|    std                | 0.595      |\n",
      "|    value_loss         | 2.34e+04   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -928       |\n",
      "| time/                 |            |\n",
      "|    fps                | 440        |\n",
      "|    iterations         | 19100      |\n",
      "|    time_elapsed       | 217        |\n",
      "|    total_timesteps    | 95500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -0.897     |\n",
      "|    explained_variance | -40.015804 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 19099      |\n",
      "|    policy_loss        | 81         |\n",
      "|    std                | 0.594      |\n",
      "|    value_loss         | 7.1e+03    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -921       |\n",
      "| time/                 |            |\n",
      "|    fps                | 439        |\n",
      "|    iterations         | 19200      |\n",
      "|    time_elapsed       | 218        |\n",
      "|    total_timesteps    | 96000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -0.895     |\n",
      "|    explained_variance | -11.058227 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 19199      |\n",
      "|    policy_loss        | -11.1      |\n",
      "|    std                | 0.592      |\n",
      "|    value_loss         | 478        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -921      |\n",
      "| time/                 |           |\n",
      "|    fps                | 439       |\n",
      "|    iterations         | 19300     |\n",
      "|    time_elapsed       | 219       |\n",
      "|    total_timesteps    | 96500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.89     |\n",
      "|    explained_variance | -933.9519 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 19299     |\n",
      "|    policy_loss        | -131      |\n",
      "|    std                | 0.589     |\n",
      "|    value_loss         | 1.69e+04  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -918       |\n",
      "| time/                 |            |\n",
      "|    fps                | 439        |\n",
      "|    iterations         | 19400      |\n",
      "|    time_elapsed       | 220        |\n",
      "|    total_timesteps    | 97000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -0.881     |\n",
      "|    explained_variance | -63.666603 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 19399      |\n",
      "|    policy_loss        | -8.91      |\n",
      "|    std                | 0.583      |\n",
      "|    value_loss         | 33.5       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -908      |\n",
      "| time/                 |           |\n",
      "|    fps                | 438       |\n",
      "|    iterations         | 19500     |\n",
      "|    time_elapsed       | 222       |\n",
      "|    total_timesteps    | 97500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.852    |\n",
      "|    explained_variance | -32.86614 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 19499     |\n",
      "|    policy_loss        | -0.138    |\n",
      "|    std                | 0.567     |\n",
      "|    value_loss         | 0.0416    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -899       |\n",
      "| time/                 |            |\n",
      "|    fps                | 438        |\n",
      "|    iterations         | 19600      |\n",
      "|    time_elapsed       | 223        |\n",
      "|    total_timesteps    | 98000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -0.85      |\n",
      "|    explained_variance | -64.555504 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 19599      |\n",
      "|    policy_loss        | -0.0817    |\n",
      "|    std                | 0.564      |\n",
      "|    value_loss         | 0.0105     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -913       |\n",
      "| time/                 |            |\n",
      "|    fps                | 438        |\n",
      "|    iterations         | 19700      |\n",
      "|    time_elapsed       | 224        |\n",
      "|    total_timesteps    | 98500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -0.848     |\n",
      "|    explained_variance | -85.285515 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 19699      |\n",
      "|    policy_loss        | 57         |\n",
      "|    std                | 0.565      |\n",
      "|    value_loss         | 6.5e+03    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 200        |\n",
      "|    ep_rew_mean        | -914       |\n",
      "| time/                 |            |\n",
      "|    fps                | 438        |\n",
      "|    iterations         | 19800      |\n",
      "|    time_elapsed       | 225        |\n",
      "|    total_timesteps    | 99000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -0.835     |\n",
      "|    explained_variance | -14395.387 |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 19799      |\n",
      "|    policy_loss        | 0.0441     |\n",
      "|    std                | 0.557      |\n",
      "|    value_loss         | 0.274      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 200         |\n",
      "|    ep_rew_mean        | -921        |\n",
      "| time/                 |             |\n",
      "|    fps                | 438         |\n",
      "|    iterations         | 19900       |\n",
      "|    time_elapsed       | 227         |\n",
      "|    total_timesteps    | 99500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -0.835      |\n",
      "|    explained_variance | -0.42865503 |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19899       |\n",
      "|    policy_loss        | 3.01        |\n",
      "|    std                | 0.557       |\n",
      "|    value_loss         | 26.7        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -926      |\n",
      "| time/                 |           |\n",
      "|    fps                | 437       |\n",
      "|    iterations         | 20000     |\n",
      "|    time_elapsed       | 228       |\n",
      "|    total_timesteps    | 100000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.822    |\n",
      "|    explained_variance | -11351.18 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 19999     |\n",
      "|    policy_loss        | 0.225     |\n",
      "|    std                | 0.551     |\n",
      "|    value_loss         | 0.224     |\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import torch as th\n",
    "\n",
    "from stable_baselines3 import A2C\n",
    "\n",
    "# Custom actor (pi) and value function (vf) networks\n",
    "# of two layers of size 32 each with Relu activation function\n",
    "# Note: an extra linear layer will be added on top of the pi and the vf nets, respectively\n",
    "policy_kwargs = dict(activation_fn=th.nn.ReLU,\n",
    "                     net_arch=dict(pi=[64, 64], vf=[64, 64]))\n",
    "# Create the agent\n",
    "model = A2C(\"MlpPolicy\", \"Pendulum-v1\", policy_kwargs=policy_kwargs, verbose=1)\n",
    "# Retrieve the environment\n",
    "env = model.get_env()\n",
    "# Train the agent\n",
    "model.learn(total_timesteps=100_000)\n",
    "# Save the agent\n",
    "model.save(\"ppo_llv2\")\n",
    "\n",
    "del model\n",
    "# the policy_kwargs are automatically loaded\n",
    "model = A2C.load(\"ppo_llv2\", env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.8635671 ,  0.50423384, -0.71662366], dtype=float32), {})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    " action, _states = model.predict(obs, deterministic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "size must be two numbers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m action, _states \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(obs, deterministic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Lakukan aksi di lingkungan\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m obs, reward, done, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Render visualisasi hasilnya\u001b[39;00m\n\u001b[0;32m     20\u001b[0m env\u001b[38;5;241m.\u001b[39mrender()\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\robot_sim\\lib\\site-packages\\gymnasium\\wrappers\\time_limit.py:57\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m     47\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m \n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\robot_sim\\lib\\site-packages\\gymnasium\\wrappers\\order_enforcing.py:56\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\robot_sim\\lib\\site-packages\\gymnasium\\wrappers\\env_checker.py:49\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_step:\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43menv_step_passive_checker\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\robot_sim\\lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:208\u001b[0m, in \u001b[0;36menv_step_passive_checker\u001b[1;34m(env, action)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"A passive check for the environment step, investigating the returning data then returning the data unchanged.\"\"\"\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;66;03m# We don't check the action as for some environments then out-of-bounds values can be given\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    210\u001b[0m     result, \u001b[38;5;28mtuple\u001b[39m\n\u001b[0;32m    211\u001b[0m ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpects step result to be a tuple, actual type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(result)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\robot_sim\\lib\\site-packages\\gymnasium\\envs\\classic_control\\pendulum.py:143\u001b[0m, in \u001b[0;36mPendulumEnv.step\u001b[1;34m(self, u)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([newth, newthdot])\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 143\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_obs(), \u001b[38;5;241m-\u001b[39mcosts, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m, {}\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\robot_sim\\lib\\site-packages\\gymnasium\\envs\\classic_control\\pendulum.py:237\u001b[0m, in \u001b[0;36mPendulumEnv.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    235\u001b[0m img \u001b[38;5;241m=\u001b[39m pygame\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mload(fname)\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_u \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 237\u001b[0m     scale_img \u001b[38;5;241m=\u001b[39m \u001b[43mpygame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msmoothscale\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43mscale\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_u\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_u\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    241\u001b[0m     is_flip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_u \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    242\u001b[0m     scale_img \u001b[38;5;241m=\u001b[39m pygame\u001b[38;5;241m.\u001b[39mtransform\u001b[38;5;241m.\u001b[39mflip(scale_img, is_flip, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: size must be two numbers"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import A2C\n",
    "\n",
    "# Memuat model yang telah dilatih\n",
    "model = A2C.load(\"ppo_llv2\")\n",
    "\n",
    "# Inisialisasi lingkungan\n",
    "env = gym.make(\"Pendulum-v1\", render_mode=\"human\")\n",
    "\n",
    "# Mulai episode inferensi\n",
    "obs, info = env.reset()\n",
    "done = False\n",
    "truncated = False\n",
    "while not done or truncated:\n",
    "    # Pilih tindakan berdasarkan model\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    # Lakukan aksi di lingkungan\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    # Render visualisasi hasilnya\n",
    "    env.render()\n",
    "\n",
    "# Menutup lingkungan setelah selesai\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\User\\anaconda3\\envs\\robot_sim\\lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\User\\anaconda3\\envs\\robot_sim\\lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training A2C...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training PPO...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A2C: Mean reward = -490.11 +/- 318.44\n",
      "PPO: Mean reward = -217.97 +/- 20.94\n",
      "\n",
      "Comparison of results:\n",
      "A2C: Mean Reward = -490.1056629000001, Std Reward = 318.43748785392296\n",
      "PPO: Mean Reward = -217.97396650000002, Std Reward = 20.938320972389807\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import torch as th\n",
    "from stable_baselines3 import DQN, A2C, PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "# Set konfigurasi umum\n",
    "env_id = \"LunarLander-v2\"\n",
    "policy_kwargs = dict(activation_fn=th.nn.ReLU, net_arch=dict(pi=[64, 64, 64], vf=[64, 64]))\n",
    "\n",
    "# Inisialisasi model untuk setiap algoritma\n",
    "algorithms = {\n",
    "    \"A2C\": A2C(\"MlpPolicy\", env_id, policy_kwargs=policy_kwargs, verbose=0),\n",
    "    \"PPO\": PPO(\"MlpPolicy\", env_id, policy_kwargs=policy_kwargs, verbose=0),\n",
    "}\n",
    "\n",
    "# Latih setiap model dan simpan hasilnya\n",
    "trained_models = {}\n",
    "for algo_name, model in algorithms.items():\n",
    "    print(f\"Training {algo_name}...\")\n",
    "    model.learn(total_timesteps=20_000, progress_bar=True)\n",
    "    trained_models[algo_name] = model\n",
    "    model.save(f\"{algo_name}_lunarlander\")\n",
    "\n",
    "# Evaluasi performa setiap model\n",
    "results = {}\n",
    "for algo_name, model in trained_models.items():\n",
    "    # Evaluasi model menggunakan evaluate_policy\n",
    "    mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=10)\n",
    "    results[algo_name] = {\"mean_reward\": mean_reward, \"std_reward\": std_reward}\n",
    "    print(f\"{algo_name}: Mean reward = {mean_reward:.2f} +/- {std_reward:.2f}\")\n",
    "\n",
    "# Print perbandingan hasil\n",
    "print(\"\\nComparison of results:\")\n",
    "for algo_name, result in results.items():\n",
    "    print(f\"{algo_name}: Mean Reward = {result['mean_reward']}, Std Reward = {result['std_reward']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m truncated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done \u001b[38;5;129;01mor\u001b[39;00m truncated:\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# Pilih tindakan berdasarkan model\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m     action, _states \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# Lakukan aksi di lingkungan\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     obs, reward, done, truncated, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\robot_sim\\lib\\site-packages\\stable_baselines3\\common\\base_class.py:556\u001b[0m, in \u001b[0;36mBaseAlgorithm.predict\u001b[1;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[0;32m    537\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    538\u001b[0m     observation: Union[np\u001b[38;5;241m.\u001b[39mndarray, Dict[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray]],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    541\u001b[0m     deterministic: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    542\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[np\u001b[38;5;241m.\u001b[39mndarray, Optional[Tuple[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]]]:\n\u001b[0;32m    543\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    544\u001b[0m \u001b[38;5;124;03m    Get the policy action from an observation (and optional hidden state).\u001b[39;00m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;124;03m    Includes sugar-coating to handle different observations (e.g. normalizing images).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;124;03m        (used in recurrent policies)\u001b[39;00m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\robot_sim\\lib\\site-packages\\stable_baselines3\\common\\policies.py:368\u001b[0m, in \u001b[0;36mBasePolicy.predict\u001b[1;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[0;32m    365\u001b[0m obs_tensor, vectorized_env \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs_to_tensor(observation)\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 368\u001b[0m     actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;66;03m# Convert to numpy, and reshape to the original action shape\u001b[39;00m\n\u001b[0;32m    370\u001b[0m actions \u001b[38;5;241m=\u001b[39m actions\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mshape))  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\robot_sim\\lib\\site-packages\\stable_baselines3\\common\\policies.py:717\u001b[0m, in \u001b[0;36mActorCriticPolicy._predict\u001b[1;34m(self, observation, deterministic)\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, observation: PyTorchObs, deterministic: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m th\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m    710\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    711\u001b[0m \u001b[38;5;124;03m    Get the action according to the policy for a given observation.\u001b[39;00m\n\u001b[0;32m    712\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;124;03m    :return: Taken action according to the policy\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 717\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mget_actions(deterministic\u001b[38;5;241m=\u001b[39mdeterministic)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\robot_sim\\lib\\site-packages\\stable_baselines3\\common\\policies.py:752\u001b[0m, in \u001b[0;36mActorCriticPolicy.get_distribution\u001b[1;34m(self, obs)\u001b[0m\n\u001b[0;32m    750\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mextract_features(obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpi_features_extractor)\n\u001b[0;32m    751\u001b[0m latent_pi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp_extractor\u001b[38;5;241m.\u001b[39mforward_actor(features)\n\u001b[1;32m--> 752\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_action_dist_from_latent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent_pi\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\robot_sim\\lib\\site-packages\\stable_baselines3\\common\\policies.py:697\u001b[0m, in \u001b[0;36mActorCriticPolicy._get_action_dist_from_latent\u001b[1;34m(self, latent_pi)\u001b[0m\n\u001b[0;32m    694\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dist\u001b[38;5;241m.\u001b[39mproba_distribution(mean_actions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_std)\n\u001b[0;32m    695\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dist, CategoricalDistribution):\n\u001b[0;32m    696\u001b[0m     \u001b[38;5;66;03m# Here mean_actions are the logits before the softmax\u001b[39;00m\n\u001b[1;32m--> 697\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_dist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproba_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dist, MultiCategoricalDistribution):\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# Here mean_actions are the flattened logits\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dist\u001b[38;5;241m.\u001b[39mproba_distribution(action_logits\u001b[38;5;241m=\u001b[39mmean_actions)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\robot_sim\\lib\\site-packages\\stable_baselines3\\common\\distributions.py:288\u001b[0m, in \u001b[0;36mCategoricalDistribution.proba_distribution\u001b[1;34m(self, action_logits)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mproba_distribution\u001b[39m(\u001b[38;5;28mself\u001b[39m: SelfCategoricalDistribution, action_logits: th\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfCategoricalDistribution:\n\u001b[1;32m--> 288\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribution \u001b[38;5;241m=\u001b[39m \u001b[43mCategorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction_logits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\robot_sim\\lib\\site-packages\\torch\\distributions\\categorical.py:72\u001b[0m, in \u001b[0;36mCategorical.__init__\u001b[1;34m(self, probs, logits, validate_args)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_events \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     69\u001b[0m batch_shape \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39mndimension() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mSize()\n\u001b[0;32m     71\u001b[0m )\n\u001b[1;32m---> 72\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\robot_sim\\lib\\site-packages\\torch\\distributions\\distribution.py:70\u001b[0m, in \u001b[0;36mDistribution.__init__\u001b[1;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[0;32m     68\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, param)\n\u001b[0;32m     69\u001b[0m         valid \u001b[38;5;241m=\u001b[39m constraint\u001b[38;5;241m.\u001b[39mcheck(value)\n\u001b[1;32m---> 70\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m     71\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     72\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     73\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(value\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     76\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut found invalid values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     77\u001b[0m             )\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import A2C\n",
    "\n",
    "# Memuat model yang telah dilatih\n",
    "model = A2C.load(\"A2C_lunarlander\")\n",
    "\n",
    "# Inisialisasi lingkungan\n",
    "env = gym.make(\"LunarLander-v2\", render_mode=\"human\")\n",
    "\n",
    "# Mulai episode inferensi\n",
    "obs, info = env.reset()\n",
    "done = False\n",
    "truncated = False\n",
    "while not done or truncated:\n",
    "    # Pilih tindakan berdasarkan model\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    # Lakukan aksi di lingkungan\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    # Render visualisasi hasilnya\n",
    "    env.render()\n",
    "\n",
    "# Menutup lingkungan setelah selesai\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "\n",
    "# Create environment\n",
    "env = gym.make(\"LunarLander-v2\", render_mode=\"rgb_array\")\n",
    "\n",
    "# Instantiate the agent\n",
    "model = DQN(\"MlpPolicy\", env, verbose=1)\n",
    "# Train the agent and display a progress bar\n",
    "model.learn(total_timesteps=int(2e5), progress_bar=True)\n",
    "# Save the agent\n",
    "model.save(\"dqn_lunar\")\n",
    "del model  # delete trained model to demonstrate loading\n",
    "\n",
    "# Load the trained agent\n",
    "# NOTE: if you have loading issue, you can pass `print_system_info=True`\n",
    "# to compare the system on which the model was trained vs the current one\n",
    "# model = DQN.load(\"dqn_lunar\", env=env, print_system_info=True)\n",
    "model = DQN.load(\"dqn_lunar\", env=env)\n",
    "\n",
    "# Evaluate the agent\n",
    "# NOTE: If you use wrappers with your environment that modify rewards,\n",
    "#       this will be reflected here. To evaluate with original rewards,\n",
    "#       wrap environment in a \"Monitor\" wrapper before other wrappers.\n",
    "mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=10)\n",
    "\n",
    "# Enjoy trained agent\n",
    "vec_env = model.get_env()\n",
    "obs = vec_env.reset()\n",
    "for i in range(1000):\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, rewards, dones, info = vec_env.step(action)\n",
    "    vec_env.render(\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = vec_env.reset()\n",
    "for i in range(1000):\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, rewards, dones, info = vec_env.step(action)\n",
    "    vec_env.render(\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gymnasium-robotics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gymnasium[mujoco]==0.29.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import torch as th\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "# Konfigurasi kebijakan (policy)\n",
    "policy_kwargs = dict(activation_fn=th.nn.ReLU, net_arch=[64, 64])\n",
    "\n",
    "# Inisialisasi lingkungan MuJoCo 'HalfCheetah-v4'\n",
    "env_id = \"HalfCheetah-v4\"\n",
    "env = gym.make(env_id)\n",
    "\n",
    "# Inisialisasi model PPO\n",
    "model = PPO(\"MlpPolicy\", env, policy_kwargs=policy_kwargs, verbose=1)\n",
    "\n",
    "# Latih agen\n",
    "print(\"Starting training...\")\n",
    "model.learn(total_timesteps=100_000)\n",
    "\n",
    "# Simpan model yang sudah dilatih\n",
    "model.save(\"ppo_halfcheetah\")\n",
    "\n",
    "# Evaluasi model yang telah dilatih\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10)\n",
    "\n",
    "# Hasil evaluasi\n",
    "print(f\"Mean reward: {mean_reward:.2f} +/- {std_reward:.2f}\")\n",
    "\n",
    "# Tutup lingkungan\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training A2C...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training PPO...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SAC...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training TD3...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DDPG...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A2C: Mean reward = -100.46 +/- 0.29\n",
      "PPO: Mean reward = -104.64 +/- 6.40\n",
      "SAC: Mean reward = -123.83 +/- 2.37\n",
      "TD3: Mean reward = -111.88 +/- 14.77\n",
      "DDPG: Mean reward = -130.41 +/- 13.93\n",
      "\n",
      "Comparison of results:\n",
      "A2C: Mean Reward = -100.4582122, Std Reward = 0.2876229910044744\n",
      "PPO: Mean Reward = -104.63782269999999, Std Reward = 6.395481108335009\n",
      "SAC: Mean Reward = -123.82576960000002, Std Reward = 2.374024677732194\n",
      "TD3: Mean Reward = -111.87758670000001, Std Reward = 14.766777505273453\n",
      "DDPG: Mean Reward = -130.41362249999997, Std Reward = 13.92941335745438\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import torch as th\n",
    "from stable_baselines3 import A2C, PPO, SAC, TD3, DDPG\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "# Set environment\n",
    "env_id = \"BipedalWalker-v3\"\n",
    "\n",
    "# Policy configuration for each algorithm\n",
    "policy_configs = {\n",
    "    \"A2C\": dict(activation_fn=th.nn.ReLU, net_arch=[dict(pi=[256, 256], vf=[256, 256])]),\n",
    "    \"PPO\": dict(activation_fn=th.nn.ReLU, net_arch=[dict(pi=[256, 256], vf=[256, 256])]),\n",
    "    \"SAC\": dict(activation_fn=th.nn.ReLU, net_arch=[256, 256]),  # Single net for both pi and vf\n",
    "    \"TD3\": dict(activation_fn=th.nn.ReLU, net_arch=[256, 256]),  # Larger network for TD3\n",
    "    \"DDPG\": dict(activation_fn=th.nn.ReLU, net_arch=[256, 256])  # Deeper network for DDPG\n",
    "}\n",
    "\n",
    "# Initialize models with specific policies\n",
    "algorithms = {\n",
    "    \"A2C\": A2C(\"MlpPolicy\", env_id, policy_kwargs=policy_configs[\"A2C\"], verbose=0),\n",
    "    \"PPO\": PPO(\"MlpPolicy\", env_id, policy_kwargs=policy_configs[\"PPO\"], verbose=0),\n",
    "    \"SAC\": SAC(\"MlpPolicy\", env_id, policy_kwargs=policy_configs[\"SAC\"], verbose=0),\n",
    "    \"TD3\": TD3(\"MlpPolicy\", env_id, policy_kwargs=policy_configs[\"TD3\"], verbose=0),\n",
    "    \"DDPG\": DDPG(\"MlpPolicy\", env_id, policy_kwargs=policy_configs[\"DDPG\"], verbose=0)\n",
    "}\n",
    "\n",
    "# Train each model and save results\n",
    "trained_models = {}\n",
    "for algo_name, model in algorithms.items():\n",
    "    print(f\"Training {algo_name}...\")\n",
    "    model.learn(total_timesteps=20_000, progress_bar=True)\n",
    "    trained_models[algo_name] = model\n",
    "    model.save(f\"{algo_name}_bipedalwalker\")\n",
    "\n",
    "# Evaluate each model\n",
    "results = {}\n",
    "for algo_name, model in trained_models.items():\n",
    "    mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=10)\n",
    "    results[algo_name] = {\"mean_reward\": mean_reward, \"std_reward\": std_reward}\n",
    "    print(f\"{algo_name}: Mean reward = {mean_reward:.2f} +/- {std_reward:.2f}\")\n",
    "\n",
    "# Print comparison of results\n",
    "print(\"\\nComparison of results:\")\n",
    "for algo_name, result in results.items():\n",
    "    print(f\"{algo_name}: Mean Reward = {result['mean_reward']}, Std Reward = {result['std_reward']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\robot_sim\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py:568: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "c:\\Users\\User\\anaconda3\\envs\\robot_sim\\lib\\site-packages\\ray\\tune\\logger\\unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "c:\\Users\\User\\anaconda3\\envs\\robot_sim\\lib\\site-packages\\ray\\tune\\logger\\unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "c:\\Users\\User\\anaconda3\\envs\\robot_sim\\lib\\site-packages\\ray\\tune\\logger\\unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "2024-10-31 12:52:24,239\tINFO worker.py:1807 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "2024-10-31 12:52:29,625\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\n",
      "\u001b[36m(SingleAgentEnvRunner pid=66056)\u001b[0m 2024-10-31 12:52:29,580\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\n",
      "2024-10-31 12:52:30,595\tINFO trainable.py:161 -- Trainable.setup took 10.533 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'date': '2024-10-31_12-52-38',\n",
      " 'done': False,\n",
      " 'env_runners': {'agent_episode_returns_mean': {'default_agent': 21.56},\n",
      "                 'episode_duration_sec_mean': 0.010456471003126354,\n",
      "                 'episode_len_max': 84,\n",
      "                 'episode_len_mean': 21.56,\n",
      "                 'episode_len_min': 9,\n",
      "                 'episode_return_max': 84.0,\n",
      "                 'episode_return_mean': 21.56,\n",
      "                 'episode_return_min': 9.0,\n",
      "                 'module_episode_returns_mean': {'default_policy': 21.56},\n",
      "                 'num_agent_steps_sampled': {'default_agent': 4000},\n",
      "                 'num_agent_steps_sampled_lifetime': {'default_agent': 4000},\n",
      "                 'num_env_steps_sampled': 4000,\n",
      "                 'num_env_steps_sampled_lifetime': 4000,\n",
      "                 'num_episodes': 185,\n",
      "                 'num_module_steps_sampled': {'default_policy': 4000},\n",
      "                 'num_module_steps_sampled_lifetime': {'default_policy': 4000},\n",
      "                 'sample': 2.100227599963546},\n",
      " 'fault_tolerance': {'num_healthy_workers': 1,\n",
      "                     'num_in_flight_async_reqs': 0,\n",
      "                     'num_remote_worker_restarts': 0},\n",
      " 'hostname': 'DESKTOP-7BH3375',\n",
      " 'iterations_since_restore': 1,\n",
      " 'learners': {'__all_modules__': {'learner_connector_timer': 0.560110199963674,\n",
      "                                  'num_env_steps_trained': 4186,\n",
      "                                  'num_module_steps_trained': 4186,\n",
      "                                  'num_non_trainable_parameters': 0,\n",
      "                                  'num_trainable_parameters': 134915},\n",
      "              'default_policy': {'curr_entropy_coeff': 0.0,\n",
      "                                 'curr_kl_coeff': 0.30000001192092896,\n",
      "                                 'default_optimizer_learning_rate': 5e-05,\n",
      "                                 'entropy': 0.6682442426681519,\n",
      "                                 'gradients_default_optimizer_global_norm': 3.695650339126587,\n",
      "                                 'mean_kl_loss': 0.025429140776395798,\n",
      "                                 'module_train_batch_size_mean': 4186,\n",
      "                                 'num_module_steps_trained': 4186,\n",
      "                                 'num_non_trainable_parameters': 0,\n",
      "                                 'num_trainable_parameters': 134915,\n",
      "                                 'policy_loss': -0.015599863603711128,\n",
      "                                 'total_loss': 6.226135730743408,\n",
      "                                 'vf_explained_var': 0.18685322999954224,\n",
      "                                 'vf_loss': 6.236650466918945,\n",
      "                                 'vf_loss_unclipped': 100.06354522705078}},\n",
      " 'node_ip': '127.0.0.1',\n",
      " 'num_agent_steps_sampled_lifetime': {'default_agent': 4000},\n",
      " 'num_env_steps_sampled_lifetime': 4000,\n",
      " 'num_env_steps_trained_lifetime': 4186,\n",
      " 'num_episodes_lifetime': 185,\n",
      " 'perf': {'cpu_util_percent': np.float64(2.8999999999999995),\n",
      "          'gpu_util_percent0': np.float64(0.083),\n",
      "          'ram_util_percent': np.float64(81.99999999999999),\n",
      "          'vram_util_percent0': np.float64(0.07771809895833333)},\n",
      " 'pid': 56656,\n",
      " 'time_since_restore': 7.751610994338989,\n",
      " 'time_this_iter_s': 7.751610994338989,\n",
      " 'time_total_s': 7.751610994338989,\n",
      " 'timers': {'env_runner_sampling_timer': 2.1229085999075323,\n",
      "            'learner_update_timer': 5.620937699917704,\n",
      "            'restore_workers_time_sec': 0.0,\n",
      "            'synch_weights': 0.0030896998941898346,\n",
      "            'training_iteration_time_sec': 7.748611211776733,\n",
      "            'training_step_time_sec': 7.748611211776733},\n",
      " 'timestamp': 1730353958,\n",
      " 'training_iteration': 1,\n",
      " 'trial_id': 'default'}\n",
      "Checkpoint saved in directory C:\\Users\\User\\AppData\\Local\\Temp\\2d73a4eb-2040-47fd-ae7e-3ca6c98e0787\n",
      "{'date': '2024-10-31_12-52-50',\n",
      " 'done': False,\n",
      " 'env_runners': {'agent_episode_returns_mean': {'default_agent': 38.93},\n",
      "                 'episode_duration_sec_mean': 0.01934293099679053,\n",
      "                 'episode_len_max': 131,\n",
      "                 'episode_len_mean': 38.93,\n",
      "                 'episode_len_min': 9,\n",
      "                 'episode_return_max': 131.0,\n",
      "                 'episode_return_mean': 38.93,\n",
      "                 'episode_return_min': 9.0,\n",
      "                 'module_episode_returns_mean': {'default_policy': 38.93},\n",
      "                 'num_agent_steps_sampled': {'default_agent': 4000},\n",
      "                 'num_agent_steps_sampled_lifetime': {'default_agent': 12000},\n",
      "                 'num_env_steps_sampled': 4000,\n",
      "                 'num_env_steps_sampled_lifetime': 12000,\n",
      "                 'num_episodes': 104,\n",
      "                 'num_module_steps_sampled': {'default_policy': 4000},\n",
      "                 'num_module_steps_sampled_lifetime': {'default_policy': 12000},\n",
      "                 'sample': 2.1002270521535538,\n",
      "                 'time_between_sampling': 5.6980691000353545},\n",
      " 'fault_tolerance': {'num_healthy_workers': 1,\n",
      "                     'num_in_flight_async_reqs': 0,\n",
      "                     'num_remote_worker_restarts': 0},\n",
      " 'hostname': 'DESKTOP-7BH3375',\n",
      " 'iterations_since_restore': 2,\n",
      " 'learners': {'__all_modules__': {'learner_connector_timer': 0.5600671242236859,\n",
      "                                  'num_env_steps_trained': 4105,\n",
      "                                  'num_module_steps_trained': 4105,\n",
      "                                  'num_non_trainable_parameters': 0.0,\n",
      "                                  'num_trainable_parameters': 134915.0},\n",
      "              'default_policy': {'curr_entropy_coeff': 0.0,\n",
      "                                 'curr_kl_coeff': 0.30000001192092896,\n",
      "                                 'default_optimizer_learning_rate': 5e-05,\n",
      "                                 'entropy': 0.6179018616676331,\n",
      "                                 'gradients_default_optimizer_global_norm': 2.1073310375213623,\n",
      "                                 'mean_kl_loss': 0.017853058874607086,\n",
      "                                 'module_train_batch_size_mean': 4185.9919,\n",
      "                                 'num_module_steps_trained': 4105,\n",
      "                                 'num_non_trainable_parameters': 0.0,\n",
      "                                 'num_trainable_parameters': 134915.0,\n",
      "                                 'policy_loss': -0.05483749136328697,\n",
      "                                 'total_loss': 7.930174827575684,\n",
      "                                 'vf_explained_var': 0.13991647958755493,\n",
      "                                 'vf_loss': 7.97965669631958,\n",
      "                                 'vf_loss_unclipped': 457.4140319824219}},\n",
      " 'node_ip': '127.0.0.1',\n",
      " 'num_agent_steps_sampled_lifetime': {'default_agent': 8000},\n",
      " 'num_env_steps_sampled_lifetime': 8000,\n",
      " 'num_env_steps_trained_lifetime': 8291,\n",
      " 'num_episodes_lifetime': 289,\n",
      " 'perf': {'cpu_util_percent': np.float64(3.29375),\n",
      "          'gpu_util_percent0': np.float64(0.200625),\n",
      "          'ram_util_percent': np.float64(82.8125),\n",
      "          'vram_util_percent0': np.float64(0.08001200358072916)},\n",
      " 'pid': 56656,\n",
      " 'time_since_restore': 20.122600555419922,\n",
      " 'time_this_iter_s': 12.370989561080933,\n",
      " 'time_total_s': 20.122600555419922,\n",
      " 'timers': {'env_runner_sampling_timer': 2.123797123907134,\n",
      "            'learner_update_timer': 5.666164954919369,\n",
      "            'restore_workers_time_sec': 0.0,\n",
      "            'synch_env_connectors': 0.003184082901570946,\n",
      "            'synch_weights': 0.0031315958942286673,\n",
      "            'training_iteration_time_sec': 10.056800603866577,\n",
      "            'training_step_time_sec': 10.056800603866577},\n",
      " 'timestamp': 1730353970,\n",
      " 'training_iteration': 2,\n",
      " 'trial_id': 'default'}\n",
      "{'date': '2024-10-31_12-53-05',\n",
      " 'done': False,\n",
      " 'env_runners': {'agent_episode_returns_mean': {'default_agent': 55.79},\n",
      "                 'episode_duration_sec_mean': 0.043307621986605226,\n",
      "                 'episode_len_max': 231,\n",
      "                 'episode_len_mean': 55.79,\n",
      "                 'episode_len_min': 10,\n",
      "                 'episode_return_max': 231.0,\n",
      "                 'episode_return_mean': 55.79,\n",
      "                 'episode_return_min': 10.0,\n",
      "                 'module_episode_returns_mean': {'default_policy': 55.79},\n",
      "                 'num_agent_steps_sampled': {'default_agent': 4000},\n",
      "                 'num_agent_steps_sampled_lifetime': {'default_agent': 24000},\n",
      "                 'num_env_steps_sampled': 4000,\n",
      "                 'num_env_steps_sampled_lifetime': 24000,\n",
      "                 'num_episodes': 59,\n",
      "                 'num_module_steps_sampled': {'default_policy': 4000},\n",
      "                 'num_module_steps_sampled_lifetime': {'default_policy': 24000},\n",
      "                 'sample': 2.1003904837297553,\n",
      "                 'time_between_sampling': 5.6985285325753505},\n",
      " 'fault_tolerance': {'num_healthy_workers': 1,\n",
      "                     'num_in_flight_async_reqs': 0,\n",
      "                     'num_remote_worker_restarts': 0},\n",
      " 'hostname': 'DESKTOP-7BH3375',\n",
      " 'iterations_since_restore': 3,\n",
      " 'learners': {'__all_modules__': {'learner_connector_timer': 0.5599894576485014,\n",
      "                                  'num_env_steps_trained': 4060,\n",
      "                                  'num_module_steps_trained': 4060,\n",
      "                                  'num_non_trainable_parameters': 0.0,\n",
      "                                  'num_trainable_parameters': 134915.0},\n",
      "              'default_policy': {'curr_entropy_coeff': 0.0,\n",
      "                                 'curr_kl_coeff': 0.30000001192092896,\n",
      "                                 'default_optimizer_learning_rate': 5e-05,\n",
      "                                 'entropy': 0.5989121794700623,\n",
      "                                 'gradients_default_optimizer_global_norm': 1.1514554023742676,\n",
      "                                 'mean_kl_loss': 0.008546785451471806,\n",
      "                                 'module_train_batch_size_mean': 4185.971361999999,\n",
      "                                 'num_module_steps_trained': 4060,\n",
      "                                 'num_non_trainable_parameters': 0.0,\n",
      "                                 'num_trainable_parameters': 134915.0,\n",
      "                                 'policy_loss': -0.1325346678495407,\n",
      "                                 'total_loss': 8.754110336303711,\n",
      "                                 'vf_explained_var': 0.07437610626220703,\n",
      "                                 'vf_loss': 8.88408088684082,\n",
      "                                 'vf_loss_unclipped': 1037.9168701171875}},\n",
      " 'node_ip': '127.0.0.1',\n",
      " 'num_agent_steps_sampled_lifetime': {'default_agent': 12000},\n",
      " 'num_env_steps_sampled_lifetime': 12000,\n",
      " 'num_env_steps_trained_lifetime': 12351,\n",
      " 'num_episodes_lifetime': 348,\n",
      " 'perf': {'cpu_util_percent': np.float64(2.8666666666666663),\n",
      "          'gpu_util_percent0': np.float64(0.16944444444444445),\n",
      "          'ram_util_percent': np.float64(82.90000000000002),\n",
      "          'vram_util_percent0': np.float64(0.07874439380787036)},\n",
      " 'pid': 56656,\n",
      " 'time_since_restore': 34.48605155944824,\n",
      " 'time_this_iter_s': 14.36345100402832,\n",
      " 'time_total_s': 34.48605155944824,\n",
      " 'timers': {'env_runner_sampling_timer': 2.1401573306682518,\n",
      "            'learner_update_timer': 5.715418350370322,\n",
      "            'restore_workers_time_sec': 0.0,\n",
      "            'synch_env_connectors': 0.0031959530712803827,\n",
      "            'synch_weights': 0.0031408499345416206,\n",
      "            'training_iteration_time_sec': 11.49034841855367,\n",
      "            'training_step_time_sec': 11.49034841855367},\n",
      " 'timestamp': 1730353985,\n",
      " 'training_iteration': 3,\n",
      " 'trial_id': 'default'}\n",
      "{'date': '2024-10-31_12-53-12',\n",
      " 'done': False,\n",
      " 'env_runners': {'agent_episode_returns_mean': {'default_agent': 80.69},\n",
      "                 'episode_duration_sec_mean': 0.060603592991828915,\n",
      "                 'episode_len_max': 248,\n",
      "                 'episode_len_mean': 80.69,\n",
      "                 'episode_len_min': 15,\n",
      "                 'episode_return_max': 248.0,\n",
      "                 'episode_return_mean': 80.69,\n",
      "                 'episode_return_min': 15.0,\n",
      "                 'module_episode_returns_mean': {'default_policy': 80.69},\n",
      "                 'num_agent_steps_sampled': {'default_agent': 4000},\n",
      "                 'num_agent_steps_sampled_lifetime': {'default_agent': 40000},\n",
      "                 'num_env_steps_sampled': 4000,\n",
      "                 'num_env_steps_sampled_lifetime': 40000,\n",
      "                 'num_episodes': 36,\n",
      "                 'num_module_steps_sampled': {'default_policy': 4000},\n",
      "                 'num_module_steps_sampled_lifetime': {'default_policy': 40000},\n",
      "                 'sample': 2.1005897770592066,\n",
      "                 'time_between_sampling': 5.69947278699454},\n",
      " 'fault_tolerance': {'num_healthy_workers': 1,\n",
      "                     'num_in_flight_async_reqs': 0,\n",
      "                     'num_remote_worker_restarts': 0},\n",
      " 'hostname': 'DESKTOP-7BH3375',\n",
      " 'iterations_since_restore': 4,\n",
      " 'learners': {'__all_modules__': {'learner_connector_timer': 0.5598675955224033,\n",
      "                                  'num_env_steps_trained': 4037,\n",
      "                                  'num_module_steps_trained': 4037,\n",
      "                                  'num_non_trainable_parameters': 0.0,\n",
      "                                  'num_trainable_parameters': 134915.0},\n",
      "              'default_policy': {'curr_entropy_coeff': 0.0,\n",
      "                                 'curr_kl_coeff': 0.30000001192092896,\n",
      "                                 'default_optimizer_learning_rate': 5e-05,\n",
      "                                 'entropy': 0.5815988183021545,\n",
      "                                 'gradients_default_optimizer_global_norm': 1.3684109449386597,\n",
      "                                 'mean_kl_loss': 0.00795066449791193,\n",
      "                                 'module_train_batch_size_mean': 4185.93633557,\n",
      "                                 'num_module_steps_trained': 4037,\n",
      "                                 'num_non_trainable_parameters': 0.0,\n",
      "                                 'num_trainable_parameters': 134915.0,\n",
      "                                 'policy_loss': 0.06510500609874725,\n",
      "                                 'total_loss': 9.007192611694336,\n",
      "                                 'vf_explained_var': 0.062399446964263916,\n",
      "                                 'vf_loss': 8.939702987670898,\n",
      "                                 'vf_loss_unclipped': 1643.755615234375}},\n",
      " 'node_ip': '127.0.0.1',\n",
      " 'num_agent_steps_sampled_lifetime': {'default_agent': 16000},\n",
      " 'num_env_steps_sampled_lifetime': 16000,\n",
      " 'num_env_steps_trained_lifetime': 16388,\n",
      " 'num_episodes_lifetime': 384,\n",
      " 'perf': {'cpu_util_percent': np.float64(2.7199999999999998),\n",
      "          'gpu_util_percent0': np.float64(0.074),\n",
      "          'ram_util_percent': np.float64(82.86),\n",
      "          'vram_util_percent0': np.float64(0.08064778645833333)},\n",
      " 'pid': 56656,\n",
      " 'time_since_restore': 42.25436878204346,\n",
      " 'time_this_iter_s': 7.768317222595215,\n",
      " 'time_total_s': 42.25436878204346,\n",
      " 'timers': {'env_runner_sampling_timer': 2.1437781243630805,\n",
      "            'learner_update_timer': 5.710853252867426,\n",
      "            'restore_workers_time_sec': 0.0,\n",
      "            'synch_env_connectors': 0.0031914165409964047,\n",
      "            'synch_weights': 0.003135588435222162,\n",
      "            'training_iteration_time_sec': 10.558957993984222,\n",
      "            'training_step_time_sec': 10.558957993984222},\n",
      " 'timestamp': 1730353992,\n",
      " 'training_iteration': 4,\n",
      " 'trial_id': 'default'}\n",
      "{'date': '2024-10-31_12-53-20',\n",
      " 'done': False,\n",
      " 'env_runners': {'agent_episode_returns_mean': {'default_agent': 102.59},\n",
      "                 'episode_duration_sec_mean': 0.06464348799781874,\n",
      "                 'episode_len_max': 334,\n",
      "                 'episode_len_mean': 102.59,\n",
      "                 'episode_len_min': 15,\n",
      "                 'episode_return_max': 334.0,\n",
      "                 'episode_return_mean': 102.59,\n",
      "                 'episode_return_min': 15.0,\n",
      "                 'module_episode_returns_mean': {'default_policy': 102.59},\n",
      "                 'num_agent_steps_sampled': {'default_agent': 4000},\n",
      "                 'num_agent_steps_sampled_lifetime': {'default_agent': 60000},\n",
      "                 'num_env_steps_sampled': 4000,\n",
      "                 'num_env_steps_sampled_lifetime': 60000,\n",
      "                 'num_episodes': 26,\n",
      "                 'num_module_steps_sampled': {'default_policy': 4000},\n",
      "                 'num_module_steps_sampled_lifetime': {'default_policy': 60000},\n",
      "                 'sample': 2.1007758679736956,\n",
      "                 'time_between_sampling': 5.700356491532102},\n",
      " 'fault_tolerance': {'num_healthy_workers': 1,\n",
      "                     'num_in_flight_async_reqs': 0,\n",
      "                     'num_remote_worker_restarts': 0},\n",
      " 'hostname': 'DESKTOP-7BH3375',\n",
      " 'iterations_since_restore': 5,\n",
      " 'learners': {'__all_modules__': {'learner_connector_timer': 0.5597116686630574,\n",
      "                                  'num_env_steps_trained': 4027,\n",
      "                                  'num_module_steps_trained': 4027,\n",
      "                                  'num_non_trainable_parameters': 0.0,\n",
      "                                  'num_trainable_parameters': 134915.0},\n",
      "              'default_policy': {'curr_entropy_coeff': 0.0,\n",
      "                                 'curr_kl_coeff': 0.30000001192092896,\n",
      "                                 'default_optimizer_learning_rate': 5e-05,\n",
      "                                 'entropy': 0.5520856380462646,\n",
      "                                 'gradients_default_optimizer_global_norm': 0.6267256736755371,\n",
      "                                 'mean_kl_loss': 0.008130116388201714,\n",
      "                                 'module_train_batch_size_mean': 4185.886112532399,\n",
      "                                 'num_module_steps_trained': 4027,\n",
      "                                 'num_non_trainable_parameters': 0.0,\n",
      "                                 'num_trainable_parameters': 134915.0,\n",
      "                                 'policy_loss': 0.12268275022506714,\n",
      "                                 'total_loss': 9.431262016296387,\n",
      "                                 'vf_explained_var': 0.1558048129081726,\n",
      "                                 'vf_loss': 9.306140899658203,\n",
      "                                 'vf_loss_unclipped': 1904.0609130859375}},\n",
      " 'node_ip': '127.0.0.1',\n",
      " 'num_agent_steps_sampled_lifetime': {'default_agent': 20000},\n",
      " 'num_env_steps_sampled_lifetime': 20000,\n",
      " 'num_env_steps_trained_lifetime': 20415,\n",
      " 'num_episodes_lifetime': 410,\n",
      " 'perf': {'cpu_util_percent': np.float64(1.6499999999999997),\n",
      "          'gpu_util_percent0': np.float64(0.067),\n",
      "          'ram_util_percent': np.float64(82.79999999999998),\n",
      "          'vram_util_percent0': np.float64(0.0815673828125)},\n",
      " 'pid': 56656,\n",
      " 'time_since_restore': 49.90920901298523,\n",
      " 'time_this_iter_s': 7.6548402309417725,\n",
      " 'time_total_s': 49.90920901298523,\n",
      " 'timers': {'env_runner_sampling_timer': 2.1425278501188045,\n",
      "            'learner_update_timer': 5.71003083733786,\n",
      "            'restore_workers_time_sec': 0.0,\n",
      "            'synch_env_connectors': 0.0031895193771408104,\n",
      "            'synch_weights': 0.0031318815506913354,\n",
      "            'training_iteration_time_sec': 9.977533435821533,\n",
      "            'training_step_time_sec': 9.977533435821533},\n",
      " 'timestamp': 1730354000,\n",
      " 'training_iteration': 5,\n",
      " 'trial_id': 'default'}\n",
      "{'date': '2024-10-31_12-53-33',\n",
      " 'done': False,\n",
      " 'env_runners': {'agent_episode_returns_mean': {'default_agent': 131.92},\n",
      "                 'episode_duration_sec_mean': 0.07650909899733961,\n",
      "                 'episode_len_max': 370,\n",
      "                 'episode_len_mean': 131.92,\n",
      "                 'episode_len_min': 15,\n",
      "                 'episode_return_max': 370.0,\n",
      "                 'episode_return_mean': 131.92,\n",
      "                 'episode_return_min': 15.0,\n",
      "                 'module_episode_returns_mean': {'default_policy': 131.92},\n",
      "                 'num_agent_steps_sampled': {'default_agent': 4000},\n",
      "                 'num_agent_steps_sampled_lifetime': {'default_agent': 84000},\n",
      "                 'num_env_steps_sampled': 4000,\n",
      "                 'num_env_steps_sampled_lifetime': 84000,\n",
      "                 'num_episodes': 17,\n",
      "                 'num_module_steps_sampled': {'default_policy': 4000},\n",
      "                 'num_module_steps_sampled_lifetime': {'default_policy': 84000},\n",
      "                 'sample': 2.100971302852183,\n",
      "                 'time_between_sampling': 5.701217999020223},\n",
      " 'fault_tolerance': {'num_healthy_workers': 1,\n",
      "                     'num_in_flight_async_reqs': 0,\n",
      "                     'num_remote_worker_restarts': 0},\n",
      " 'hostname': 'DESKTOP-7BH3375',\n",
      " 'iterations_since_restore': 6,\n",
      " 'learners': {'__all_modules__': {'learner_connector_timer': 0.5595217056413657,\n",
      "                                  'num_env_steps_trained': 4018,\n",
      "                                  'num_module_steps_trained': 4018,\n",
      "                                  'num_non_trainable_parameters': 0.0,\n",
      "                                  'num_trainable_parameters': 134915.0},\n",
      "              'default_policy': {'curr_entropy_coeff': 0.0,\n",
      "                                 'curr_kl_coeff': 0.30000001192092896,\n",
      "                                 'default_optimizer_learning_rate': 5e-05,\n",
      "                                 'entropy': 0.571510374546051,\n",
      "                                 'gradients_default_optimizer_global_norm': 0.6955237984657288,\n",
      "                                 'mean_kl_loss': 0.006906348746269941,\n",
      "                                 'module_train_batch_size_mean': 4185.820100321994,\n",
      "                                 'num_module_steps_trained': 4018,\n",
      "                                 'num_non_trainable_parameters': 0.0,\n",
      "                                 'num_trainable_parameters': 134915.0,\n",
      "                                 'policy_loss': -0.17093268036842346,\n",
      "                                 'total_loss': 9.590815544128418,\n",
      "                                 'vf_explained_var': 0.14255142211914062,\n",
      "                                 'vf_loss': 9.759675979614258,\n",
      "                                 'vf_loss_unclipped': 3199.531982421875}},\n",
      " 'node_ip': '127.0.0.1',\n",
      " 'num_agent_steps_sampled_lifetime': {'default_agent': 24000},\n",
      " 'num_env_steps_sampled_lifetime': 24000,\n",
      " 'num_env_steps_trained_lifetime': 24433,\n",
      " 'num_episodes_lifetime': 427,\n",
      " 'perf': {'cpu_util_percent': np.float64(2.4466666666666668),\n",
      "          'gpu_util_percent0': np.float64(0.10800000000000003),\n",
      "          'ram_util_percent': np.float64(82.08),\n",
      "          'vram_util_percent0': np.float64(0.0813693576388889)},\n",
      " 'pid': 56656,\n",
      " 'time_since_restore': 62.3740234375,\n",
      " 'time_this_iter_s': 12.46481442451477,\n",
      " 'time_total_s': 62.3740234375,\n",
      " 'timers': {'env_runner_sampling_timer': 2.1435238306175823,\n",
      "            'learner_update_timer': 5.7550219359650345,\n",
      "            'restore_workers_time_sec': 0.0,\n",
      "            'synch_env_connectors': 0.003213664184005533,\n",
      "            'synch_weights': 0.003144576735052606,\n",
      "            'training_iteration_time_sec': 10.390914996465048,\n",
      "            'training_step_time_sec': 10.390914996465048},\n",
      " 'timestamp': 1730354013,\n",
      " 'training_iteration': 6,\n",
      " 'trial_id': 'default'}\n",
      "Checkpoint saved in directory C:\\Users\\User\\AppData\\Local\\Temp\\9a8758b7-07aa-4153-bcf4-e539c621c982\n",
      "{'date': '2024-10-31_12-53-45',\n",
      " 'done': False,\n",
      " 'env_runners': {'agent_episode_returns_mean': {'default_agent': 163.27},\n",
      "                 'episode_duration_sec_mean': 0.10329558900324627,\n",
      "                 'episode_len_max': 500,\n",
      "                 'episode_len_mean': 163.27,\n",
      "                 'episode_len_min': 15,\n",
      "                 'episode_return_max': 500.0,\n",
      "                 'episode_return_mean': 163.27,\n",
      "                 'episode_return_min': 15.0,\n",
      "                 'module_episode_returns_mean': {'default_policy': 163.27},\n",
      "                 'num_agent_steps_sampled': {'default_agent': 4000},\n",
      "                 'num_agent_steps_sampled_lifetime': {'default_agent': 112000},\n",
      "                 'num_env_steps_sampled': 4000,\n",
      "                 'num_env_steps_sampled_lifetime': 112000,\n",
      "                 'num_episodes': 11,\n",
      "                 'num_module_steps_sampled': {'default_policy': 4000},\n",
      "                 'num_module_steps_sampled_lifetime': {'default_policy': 112000},\n",
      "                 'sample': 2.101305945666294,\n",
      "                 'time_between_sampling': 5.702523342479427},\n",
      " 'fault_tolerance': {'num_healthy_workers': 1,\n",
      "                     'num_in_flight_async_reqs': 0,\n",
      "                     'num_remote_worker_restarts': 0},\n",
      " 'hostname': 'DESKTOP-7BH3375',\n",
      " 'iterations_since_restore': 7,\n",
      " 'learners': {'__all_modules__': {'learner_connector_timer': 0.5593002877432368,\n",
      "                                  'num_env_steps_trained': 4012,\n",
      "                                  'num_module_steps_trained': 4012,\n",
      "                                  'num_non_trainable_parameters': 0.0,\n",
      "                                  'num_trainable_parameters': 134915.0},\n",
      "              'default_policy': {'curr_entropy_coeff': 0.0,\n",
      "                                 'curr_kl_coeff': 0.15000000596046448,\n",
      "                                 'default_optimizer_learning_rate': 5e-05,\n",
      "                                 'entropy': 0.5724213719367981,\n",
      "                                 'gradients_default_optimizer_global_norm': 0.9566294550895691,\n",
      "                                 'mean_kl_loss': 0.004231451544910669,\n",
      "                                 'module_train_batch_size_mean': 4185.738019744544,\n",
      "                                 'num_module_steps_trained': 4012,\n",
      "                                 'num_non_trainable_parameters': 0.0,\n",
      "                                 'num_trainable_parameters': 134915.0,\n",
      "                                 'policy_loss': 0.02156582847237587,\n",
      "                                 'total_loss': 9.713427543640137,\n",
      "                                 'vf_explained_var': 0.04951512813568115,\n",
      "                                 'vf_loss': 9.690591812133789,\n",
      "                                 'vf_loss_unclipped': 4084.45556640625}},\n",
      " 'node_ip': '127.0.0.1',\n",
      " 'num_agent_steps_sampled_lifetime': {'default_agent': 28000},\n",
      " 'num_env_steps_sampled_lifetime': 28000,\n",
      " 'num_env_steps_trained_lifetime': 28445,\n",
      " 'num_episodes_lifetime': 438,\n",
      " 'perf': {'cpu_util_percent': np.float64(3.623529411764706),\n",
      "          'gpu_util_percent0': np.float64(0.08117647058823531),\n",
      "          'ram_util_percent': np.float64(82.13529411764705),\n",
      "          'vram_util_percent0': np.float64(0.08199295343137254)},\n",
      " 'pid': 56656,\n",
      " 'time_since_restore': 75.06713819503784,\n",
      " 'time_this_iter_s': 12.693114757537842,\n",
      " 'time_total_s': 75.06713819503784,\n",
      " 'timers': {'env_runner_sampling_timer': 2.157511753312351,\n",
      "            'learner_update_timer': 5.788910748605874,\n",
      "            'restore_workers_time_sec': 0.0,\n",
      "            'synch_env_connectors': 0.0032087345409495724,\n",
      "            'synch_weights': 0.0031391509679251505,\n",
      "            'training_iteration_time_sec': 10.71922492980957,\n",
      "            'training_step_time_sec': 10.71922492980957},\n",
      " 'timestamp': 1730354025,\n",
      " 'training_iteration': 7,\n",
      " 'trial_id': 'default'}\n",
      "{'date': '2024-10-31_12-53-55',\n",
      " 'done': False,\n",
      " 'env_runners': {'agent_episode_returns_mean': {'default_agent': 200.4},\n",
      "                 'episode_duration_sec_mean': 0.12063785700127483,\n",
      "                 'episode_len_max': 500,\n",
      "                 'episode_len_mean': 200.4,\n",
      "                 'episode_len_min': 16,\n",
      "                 'episode_return_max': 500.0,\n",
      "                 'episode_return_mean': 200.4,\n",
      "                 'episode_return_min': 16.0,\n",
      "                 'module_episode_returns_mean': {'default_policy': 200.4},\n",
      "                 'num_agent_steps_sampled': {'default_agent': 4000},\n",
      "                 'num_agent_steps_sampled_lifetime': {'default_agent': 144000},\n",
      "                 'num_env_steps_sampled': 4000,\n",
      "                 'num_env_steps_sampled_lifetime': 144000,\n",
      "                 'num_episodes': 9,\n",
      "                 'num_module_steps_sampled': {'default_policy': 4000},\n",
      "                 'num_module_steps_sampled_lifetime': {'default_policy': 144000},\n",
      "                 'sample': 2.1016230864938414,\n",
      "                 'time_between_sampling': 5.704149270999552},\n",
      " 'fault_tolerance': {'num_healthy_workers': 1,\n",
      "                     'num_in_flight_async_reqs': 0,\n",
      "                     'num_remote_worker_restarts': 0},\n",
      " 'hostname': 'DESKTOP-7BH3375',\n",
      " 'iterations_since_restore': 8,\n",
      " 'learners': {'__all_modules__': {'learner_connector_timer': 0.5590375578325218,\n",
      "                                  'num_env_steps_trained': 4010,\n",
      "                                  'num_module_steps_trained': 4010,\n",
      "                                  'num_non_trainable_parameters': 0.0,\n",
      "                                  'num_trainable_parameters': 134915.0},\n",
      "              'default_policy': {'curr_entropy_coeff': 0.0,\n",
      "                                 'curr_kl_coeff': 0.07500000298023224,\n",
      "                                 'default_optimizer_learning_rate': 5e-05,\n",
      "                                 'entropy': 0.5520418882369995,\n",
      "                                 'gradients_default_optimizer_global_norm': 0.20317652821540833,\n",
      "                                 'mean_kl_loss': 0.0026198094710707664,\n",
      "                                 'module_train_batch_size_mean': 4185.639998768611,\n",
      "                                 'num_module_steps_trained': 4010,\n",
      "                                 'num_non_trainable_parameters': 0.0,\n",
      "                                 'num_trainable_parameters': 134915.0,\n",
      "                                 'policy_loss': 0.134937584400177,\n",
      "                                 'total_loss': 10.060602188110352,\n",
      "                                 'vf_explained_var': 0.03393584489822388,\n",
      "                                 'vf_loss': 9.925271987915039,\n",
      "                                 'vf_loss_unclipped': 4283.5380859375}},\n",
      " 'node_ip': '127.0.0.1',\n",
      " 'num_agent_steps_sampled_lifetime': {'default_agent': 32000},\n",
      " 'num_env_steps_sampled_lifetime': 32000,\n",
      " 'num_env_steps_trained_lifetime': 32455,\n",
      " 'num_episodes_lifetime': 447,\n",
      " 'perf': {'cpu_util_percent': np.float64(2.4384615384615382),\n",
      "          'gpu_util_percent0': np.float64(0.08153846153846155),\n",
      "          'ram_util_percent': np.float64(82.33076923076922),\n",
      "          'vram_util_percent0': np.float64(0.08165564903846154)},\n",
      " 'pid': 56656,\n",
      " 'time_since_restore': 85.01836252212524,\n",
      " 'time_this_iter_s': 9.951224327087402,\n",
      " 'time_total_s': 85.01836252212524,\n",
      " 'timers': {'env_runner_sampling_timer': 2.1559218757785965,\n",
      "            'learner_update_timer': 5.810436343121774,\n",
      "            'restore_workers_time_sec': 0.0,\n",
      "            'synch_env_connectors': 0.00322017519636423,\n",
      "            'synch_weights': 0.003147308457875814,\n",
      "            'training_iteration_time_sec': 10.622599601745605,\n",
      "            'training_step_time_sec': 10.622599601745605},\n",
      " 'timestamp': 1730354035,\n",
      " 'training_iteration': 8,\n",
      " 'trial_id': 'default'}\n",
      "{'date': '2024-10-31_12-54-03',\n",
      " 'done': False,\n",
      " 'env_runners': {'agent_episode_returns_mean': {'default_agent': 228.24},\n",
      "                 'episode_duration_sec_mean': 0.13867940800264478,\n",
      "                 'episode_len_max': 500,\n",
      "                 'episode_len_mean': 228.24,\n",
      "                 'episode_len_min': 16,\n",
      "                 'episode_return_max': 500.0,\n",
      "                 'episode_return_mean': 228.24,\n",
      "                 'episode_return_min': 16.0,\n",
      "                 'module_episode_returns_mean': {'default_policy': 228.24},\n",
      "                 'num_agent_steps_sampled': {'default_agent': 4000},\n",
      "                 'num_agent_steps_sampled_lifetime': {'default_agent': 180000},\n",
      "                 'num_env_steps_sampled': 4000,\n",
      "                 'num_env_steps_sampled_lifetime': 180000,\n",
      "                 'num_episodes': 8,\n",
      "                 'num_module_steps_sampled': {'default_policy': 4000},\n",
      "                 'num_module_steps_sampled_lifetime': {'default_policy': 180000},\n",
      "                 'sample': 2.1020030809002614,\n",
      "                 'time_between_sampling': 5.7059698232750256},\n",
      " 'fault_tolerance': {'num_healthy_workers': 1,\n",
      "                     'num_in_flight_async_reqs': 0,\n",
      "                     'num_remote_worker_restarts': 0},\n",
      " 'hostname': 'DESKTOP-7BH3375',\n",
      " 'iterations_since_restore': 9,\n",
      " 'learners': {'__all_modules__': {'learner_connector_timer': 0.5587443773512548,\n",
      "                                  'num_env_steps_trained': 4009,\n",
      "                                  'num_module_steps_trained': 4009,\n",
      "                                  'num_non_trainable_parameters': 0.0,\n",
      "                                  'num_trainable_parameters': 134915.0},\n",
      "              'default_policy': {'curr_entropy_coeff': 0.0,\n",
      "                                 'curr_kl_coeff': 0.03750000149011612,\n",
      "                                 'default_optimizer_learning_rate': 5e-05,\n",
      "                                 'entropy': 0.5610451698303223,\n",
      "                                 'gradients_default_optimizer_global_norm': 0.7274785041809082,\n",
      "                                 'mean_kl_loss': 0.0023498719092458487,\n",
      "                                 'module_train_batch_size_mean': 4185.526264410222,\n",
      "                                 'num_module_steps_trained': 4009,\n",
      "                                 'num_non_trainable_parameters': 0.0,\n",
      "                                 'num_trainable_parameters': 134915.0,\n",
      "                                 'policy_loss': -0.16236935555934906,\n",
      "                                 'total_loss': 9.678481101989746,\n",
      "                                 'vf_explained_var': 0.03296220302581787,\n",
      "                                 'vf_loss': 9.840675354003906,\n",
      "                                 'vf_loss_unclipped': 5070.31591796875}},\n",
      " 'node_ip': '127.0.0.1',\n",
      " 'num_agent_steps_sampled_lifetime': {'default_agent': 36000},\n",
      " 'num_env_steps_sampled_lifetime': 36000,\n",
      " 'num_env_steps_trained_lifetime': 36464,\n",
      " 'num_episodes_lifetime': 455,\n",
      " 'perf': {'cpu_util_percent': np.float64(3.21),\n",
      "          'gpu_util_percent0': np.float64(0.06699999999999999),\n",
      "          'ram_util_percent': np.float64(82.31999999999998),\n",
      "          'vram_util_percent0': np.float64(0.0852294921875)},\n",
      " 'pid': 56656,\n",
      " 'time_since_restore': 93.14892292022705,\n",
      " 'time_this_iter_s': 8.130560398101807,\n",
      " 'time_total_s': 93.14892292022705,\n",
      " 'timers': {'env_runner_sampling_timer': 2.162358469021983,\n",
      "            'learner_update_timer': 5.805571959690627,\n",
      "            'restore_workers_time_sec': 0.0,\n",
      "            'synch_env_connectors': 0.003219920444352785,\n",
      "            'synch_weights': 0.003141591373838206,\n",
      "            'training_iteration_time_sec': 10.345372862286037,\n",
      "            'training_step_time_sec': 10.345372862286037},\n",
      " 'timestamp': 1730354043,\n",
      " 'training_iteration': 9,\n",
      " 'trial_id': 'default'}\n",
      "{'date': '2024-10-31_12-54-11',\n",
      " 'done': False,\n",
      " 'env_runners': {'agent_episode_returns_mean': {'default_agent': 261.38},\n",
      "                 'episode_duration_sec_mean': 0.15414874999783934,\n",
      "                 'episode_len_max': 500,\n",
      "                 'episode_len_mean': 261.38,\n",
      "                 'episode_len_min': 16,\n",
      "                 'episode_return_max': 500.0,\n",
      "                 'episode_return_mean': 261.38,\n",
      "                 'episode_return_min': 16.0,\n",
      "                 'module_episode_returns_mean': {'default_policy': 261.38},\n",
      "                 'num_agent_steps_sampled': {'default_agent': 4000},\n",
      "                 'num_agent_steps_sampled_lifetime': {'default_agent': 220000},\n",
      "                 'num_env_steps_sampled': 4000,\n",
      "                 'num_env_steps_sampled_lifetime': 220000,\n",
      "                 'num_episodes': 8,\n",
      "                 'num_module_steps_sampled': {'default_policy': 4000},\n",
      "                 'num_module_steps_sampled_lifetime': {'default_policy': 220000},\n",
      "                 'sample': 2.1023716125999203,\n",
      "                 'time_between_sampling': 5.7077179380778755},\n",
      " 'fault_tolerance': {'num_healthy_workers': 1,\n",
      "                     'num_in_flight_async_reqs': 0,\n",
      "                     'num_remote_worker_restarts': 0},\n",
      " 'hostname': 'DESKTOP-7BH3375',\n",
      " 'iterations_since_restore': 10,\n",
      " 'learners': {'__all_modules__': {'learner_connector_timer': 0.5584116930838254,\n",
      "                                  'num_env_steps_trained': 4009,\n",
      "                                  'num_module_steps_trained': 4009,\n",
      "                                  'num_non_trainable_parameters': 0.0,\n",
      "                                  'num_trainable_parameters': 134915.0},\n",
      "              'default_policy': {'curr_entropy_coeff': 0.0,\n",
      "                                 'curr_kl_coeff': 0.03750000149011612,\n",
      "                                 'default_optimizer_learning_rate': 5e-05,\n",
      "                                 'entropy': 0.5393897294998169,\n",
      "                                 'gradients_default_optimizer_global_norm': 1.1120481491088867,\n",
      "                                 'mean_kl_loss': 0.008013014681637287,\n",
      "                                 'module_train_batch_size_mean': 4185.397140739124,\n",
      "                                 'num_module_steps_trained': 4009,\n",
      "                                 'num_non_trainable_parameters': 0.0,\n",
      "                                 'num_trainable_parameters': 134915.0,\n",
      "                                 'policy_loss': -0.013643991202116013,\n",
      "                                 'total_loss': 9.839436531066895,\n",
      "                                 'vf_explained_var': 0.016536474227905273,\n",
      "                                 'vf_loss': 9.852781295776367,\n",
      "                                 'vf_loss_unclipped': 4842.34521484375}},\n",
      " 'node_ip': '127.0.0.1',\n",
      " 'num_agent_steps_sampled_lifetime': {'default_agent': 40000},\n",
      " 'num_env_steps_sampled_lifetime': 40000,\n",
      " 'num_env_steps_trained_lifetime': 40473,\n",
      " 'num_episodes_lifetime': 463,\n",
      " 'perf': {'cpu_util_percent': np.float64(1.53),\n",
      "          'gpu_util_percent0': np.float64(0.07700000000000001),\n",
      "          'ram_util_percent': np.float64(82.36),\n",
      "          'vram_util_percent0': np.float64(0.0828857421875)},\n",
      " 'pid': 56656,\n",
      " 'time_since_restore': 100.7774817943573,\n",
      " 'time_this_iter_s': 7.628558874130249,\n",
      " 'time_total_s': 100.7774817943573,\n",
      " 'timers': {'env_runner_sampling_timer': 2.1614180093308133,\n",
      "            'learner_update_timer': 5.803032750094173,\n",
      "            'restore_workers_time_sec': 0.0,\n",
      "            'synch_env_connectors': 0.003231590239837493,\n",
      "            'synch_weights': 0.0031401454601321594,\n",
      "            'training_iteration_time_sec': 10.073190712928772,\n",
      "            'training_step_time_sec': 10.073190712928772},\n",
      " 'timestamp': 1730354051,\n",
      " 'training_iteration': 10,\n",
      " 'trial_id': 'default'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "\n",
    "config = (\n",
    "    PPOConfig()\n",
    "    .api_stack(\n",
    "        enable_rl_module_and_learner=True,\n",
    "        enable_env_runner_and_connector_v2=True,\n",
    "    )\n",
    "    .environment(\"CartPole-v1\")\n",
    "    .env_runners(num_env_runners=1)\n",
    ")\n",
    "\n",
    "algo = config.build()\n",
    "\n",
    "for i in range(10):\n",
    "    result = algo.train()\n",
    "    result.pop(\"config\")\n",
    "    pprint(result)\n",
    "\n",
    "    if i % 5 == 0:\n",
    "        checkpoint_dir = algo.save_to_path()\n",
    "        print(f\"Checkpoint saved in directory {checkpoint_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-10-31 12:55:16</td></tr>\n",
       "<tr><td>Running for: </td><td>00:01:04.40        </td></tr>\n",
       "<tr><td>Memory:      </td><td>12.7/15.8 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 3.0/24 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      num_env_steps_sample\n",
       "d_lifetime</th><th style=\"text-align: right;\">    num_episodes_lifetim\n",
       "e</th><th style=\"text-align: right;\">      num_env_steps_traine\n",
       "d_lifetime</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v1_8d5c1_00000</td><td>TERMINATED</td><td>127.0.0.1:66008</td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         46.156 </td><td style=\"text-align: right;\">24000</td><td style=\"text-align: right;\">390</td><td style=\"text-align: right;\">24402</td></tr>\n",
       "<tr><td>PPO_CartPole-v1_8d5c1_00001</td><td>TERMINATED</td><td>127.0.0.1:6504 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         46.0704</td><td style=\"text-align: right;\">24000</td><td style=\"text-align: right;\">346</td><td style=\"text-align: right;\">24357</td></tr>\n",
       "<tr><td>PPO_CartPole-v1_8d5c1_00002</td><td>TERMINATED</td><td>127.0.0.1:44472</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         51.5576</td><td style=\"text-align: right;\">28000</td><td style=\"text-align: right;\">388</td><td style=\"text-align: right;\">28401</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SingleAgentEnvRunner pid=39316)\u001b[0m 2024-10-31 12:54:22,715\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\n",
      "\u001b[36m(PPO pid=6504)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/User/ray_results/PPO_2024-10-31_12-54-11/PPO_CartPole-v1_8d5c1_00001_1_lr=0.0010_2024-10-31_12-54-11/checkpoint_000000)\n",
      "\u001b[36m(PPO pid=6504)\u001b[0m 2024-10-31 12:54:22,785\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\u001b[32m [repeated 8x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(PPO pid=44472)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/User/ray_results/PPO_2024-10-31_12-54-11/PPO_CartPole-v1_8d5c1_00002_2_lr=0.0001_2024-10-31_12-54-11/checkpoint_000000)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=64008)\u001b[0m 2024-10-31 12:55:28,412\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\n",
      "\u001b[36m(PPO pid=5440)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/User/ray_results/PPO_2024-10-31_12-55-16/PPO_CartPole-v1_b41e7_00000_0_lr=0.0100_2024-10-31_12-55-16/checkpoint_000000)\n",
      "\u001b[36m(PPO pid=5440)\u001b[0m 2024-10-31 12:55:28,606\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=30748)\u001b[0m 2024-10-31 15:47:14,114\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-31 12:55:16,074\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to 'C:/Users/User/ray_results/PPO_2024-10-31_12-54-11' in 0.0090s.\n",
      "2024-10-31 12:55:16,611\tINFO tune.py:1041 -- Total run time: 64.94 seconds (64.39 seconds for the tuning loop).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResultGrid<[\n",
       "  Result(\n",
       "    metrics={'timers': {'env_runner_sampling_timer': 1.4698971616560688, 'learner_update_timer': 5.683219029279236, 'synch_weights': 0.004406476745286862, 'synch_env_connectors': 0.005091966095070545, 'training_iteration_time_sec': 7.686489582061768, 'restore_workers_time_sec': 0.00016637643178304037, 'training_step_time_sec': 7.685988545417786}, 'env_runners': {'num_agent_steps_sampled_lifetime': {'default_agent': 84000}, 'episode_len_max': 500, 'episode_return_mean': 160.06, 'module_episode_returns_mean': {'default_policy': 160.06}, 'num_agent_steps_sampled': {'default_agent': 4000}, 'num_env_steps_sampled_lifetime': 144000, 'num_env_steps_sampled': 4000, 'episode_len_min': 12, 'episode_duration_sec_mean': 0.12663740099873394, 'episode_len_mean': 160.06, 'num_module_steps_sampled': {'default_policy': 4000}, 'num_episodes': 13, 'agent_episode_returns_mean': {'default_agent': 160.06}, 'num_module_steps_sampled_lifetime': {'default_policy': 84000}, 'sample': np.float64(1.4197086293827752), 'episode_return_min': 12.0, 'episode_return_max': 500.0, 'time_between_sampling': np.float64(5.722337210279006)}, 'num_agent_steps_sampled_lifetime': {'default_agent': 24000}, 'num_env_steps_sampled_lifetime': 24000, 'num_episodes_lifetime': 390, 'learners': {'default_policy': {'mean_kl_loss': 0.009561997838318348, 'num_module_steps_trained': 4015, 'gradients_default_optimizer_global_norm': 5.398732662200928, 'vf_explained_var': 0.455397367477417, 'num_non_trainable_parameters': 0.0, 'policy_loss': -0.0227071363478899, 'curr_entropy_coeff': 0.0, 'vf_loss_unclipped': 505.5712890625, 'num_trainable_parameters': 134915.0, 'entropy': 0.548815906047821, 'module_train_batch_size_mean': 4203.77794775587, 'default_optimizer_learning_rate': 0.01, 'curr_kl_coeff': 0.45000001788139343, 'total_loss': 7.126581192016602, 'vf_loss': 7.144985198974609}, '__all_modules__': {'num_module_steps_trained': 4015, 'learner_connector_timer': 1.2047462001446316, 'num_non_trainable_parameters': 0.0, 'num_env_steps_trained': 4015, 'num_trainable_parameters': 134915.0}}, 'num_env_steps_trained_lifetime': 24402, 'fault_tolerance': {'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'perf': {'cpu_util_percent': np.float64(12.742857142857144), 'ram_util_percent': np.float64(96.89285714285714), 'gpu_util_percent0': np.float64(0.05071428571428572), 'vram_util_percent0': np.float64(0.09672619047619047)}},\n",
       "    path='C:/Users/User/ray_results/PPO_2024-10-31_12-54-11/PPO_CartPole-v1_8d5c1_00000_0_lr=0.0100_2024-10-31_12-54-11',\n",
       "    filesystem='local',\n",
       "    checkpoint=Checkpoint(filesystem=local, path=C:/Users/User/ray_results/PPO_2024-10-31_12-54-11/PPO_CartPole-v1_8d5c1_00000_0_lr=0.0100_2024-10-31_12-54-11/checkpoint_000000)\n",
       "  ),\n",
       "  Result(\n",
       "    metrics={'timers': {'env_runner_sampling_timer': 1.440570370787379, 'learner_update_timer': 5.692486351313712, 'synch_weights': 0.004349584551248554, 'synch_env_connectors': 0.004929850684445605, 'training_iteration_time_sec': 7.671905239423116, 'restore_workers_time_sec': 0.0, 'training_step_time_sec': 7.671737233797709}, 'env_runners': {'num_episodes': 10, 'module_episode_returns_mean': {'default_policy': 169.87}, 'episode_len_min': 12, 'num_module_steps_sampled_lifetime': {'default_policy': 84000}, 'num_env_steps_sampled': 4000, 'num_env_steps_sampled_lifetime': 144000, 'sample': np.float64(1.4038201406183912), 'agent_episode_returns_mean': {'default_agent': 169.87}, 'num_agent_steps_sampled_lifetime': {'default_agent': 84000}, 'num_module_steps_sampled': {'default_policy': 4000}, 'episode_return_mean': 169.87, 'episode_len_max': 500, 'episode_duration_sec_mean': 0.13426612499635668, 'episode_return_max': 500.0, 'episode_return_min': 12.0, 'episode_len_mean': 169.87, 'num_agent_steps_sampled': {'default_agent': 4000}, 'time_between_sampling': np.float64(5.717794706924098)}, 'num_agent_steps_sampled_lifetime': {'default_agent': 24000}, 'num_env_steps_sampled_lifetime': 24000, 'num_episodes_lifetime': 346, 'learners': {'default_policy': {'num_trainable_parameters': 134915.0, 'vf_explained_var': 0.07845431566238403, 'mean_kl_loss': 0.006730296183377504, 'entropy': 0.5519575476646423, 'vf_loss_unclipped': 3744.341064453125, 'module_train_batch_size_mean': 4192.782368413074, 'total_loss': 9.458913803100586, 'num_non_trainable_parameters': 0.0, 'num_module_steps_trained': 4012, 'gradients_default_optimizer_global_norm': 1.6010912656784058, 'default_optimizer_learning_rate': 0.001, 'curr_kl_coeff': 0.45000001788139343, 'curr_entropy_coeff': 0.0, 'policy_loss': -0.00838947482407093, 'vf_loss': 9.464273452758789}, '__all_modules__': {'learner_connector_timer': 1.2232189387811727, 'num_env_steps_trained': 4012, 'num_non_trainable_parameters': 0.0, 'num_module_steps_trained': 4012, 'num_trainable_parameters': 134915.0}}, 'num_env_steps_trained_lifetime': 24357, 'fault_tolerance': {'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'perf': {'cpu_util_percent': np.float64(12.864285714285714), 'ram_util_percent': np.float64(96.94285714285716), 'gpu_util_percent0': np.float64(0.06642857142857142), 'vram_util_percent0': np.float64(0.0967494419642857)}},\n",
       "    path='C:/Users/User/ray_results/PPO_2024-10-31_12-54-11/PPO_CartPole-v1_8d5c1_00001_1_lr=0.0010_2024-10-31_12-54-11',\n",
       "    filesystem='local',\n",
       "    checkpoint=Checkpoint(filesystem=local, path=C:/Users/User/ray_results/PPO_2024-10-31_12-54-11/PPO_CartPole-v1_8d5c1_00001_1_lr=0.0010_2024-10-31_12-54-11/checkpoint_000000)\n",
       "  ),\n",
       "  Result(\n",
       "    metrics={'timers': {'env_runner_sampling_timer': 1.4629849379329793, 'learner_update_timer': 5.629202295692302, 'synch_weights': 0.004354132770995391, 'synch_env_connectors': 0.005226739717928047, 'training_iteration_time_sec': 7.353872128895351, 'restore_workers_time_sec': 0.0, 'training_step_time_sec': 7.353729282106672}, 'env_runners': {'num_env_steps_sampled': 4000, 'num_agent_steps_sampled': {'default_agent': 4000}, 'num_agent_steps_sampled_lifetime': {'default_agent': 112000}, 'num_env_steps_sampled_lifetime': 196000, 'episode_len_min': 19, 'num_module_steps_sampled': {'default_policy': 4000}, 'agent_episode_returns_mean': {'default_agent': 179.17}, 'module_episode_returns_mean': {'default_policy': 179.17}, 'episode_return_max': 500.0, 'num_module_steps_sampled_lifetime': {'default_policy': 112000}, 'episode_return_mean': 179.17, 'episode_return_min': 19.0, 'num_episodes': 12, 'sample': np.float64(1.4050899836762827), 'episode_len_mean': 179.17, 'episode_duration_sec_mean': 0.13332151799928396, 'episode_len_max': 500, 'time_between_sampling': np.float64(5.690146402466631)}, 'num_agent_steps_sampled_lifetime': {'default_agent': 28000}, 'num_env_steps_sampled_lifetime': 28000, 'num_episodes_lifetime': 388, 'learners': {'default_policy': {'vf_loss_unclipped': 3544.827392578125, 'mean_kl_loss': 0.004818702582269907, 'entropy': 0.5521601438522339, 'module_train_batch_size_mean': 4168.760612016049, 'num_module_steps_trained': 4014, 'gradients_default_optimizer_global_norm': 0.7067933678627014, 'curr_kl_coeff': 0.07500000298023224, 'num_trainable_parameters': 134915.0, 'policy_loss': -0.015540044754743576, 'num_non_trainable_parameters': 0.0, 'curr_entropy_coeff': 0.0, 'total_loss': 9.662315368652344, 'default_optimizer_learning_rate': 0.0001, 'vf_explained_var': 0.052399635314941406, 'vf_loss': 9.677132606506348}, '__all_modules__': {'num_module_steps_trained': 4014, 'num_trainable_parameters': 134915.0, 'num_non_trainable_parameters': 0.0, 'num_env_steps_trained': 4014, 'learner_connector_timer': 1.1985064163520462}}, 'num_env_steps_trained_lifetime': 28401, 'fault_tolerance': {'num_healthy_workers': 2, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'perf': {'cpu_util_percent': np.float64(6.885714285714286), 'ram_util_percent': np.float64(82.97142857142858), 'gpu_util_percent0': np.float64(0.0842857142857143), 'vram_util_percent0': np.float64(0.08515857514880952)}},\n",
       "    path='C:/Users/User/ray_results/PPO_2024-10-31_12-54-11/PPO_CartPole-v1_8d5c1_00002_2_lr=0.0001_2024-10-31_12-54-11',\n",
       "    filesystem='local',\n",
       "    checkpoint=Checkpoint(filesystem=local, path=C:/Users/User/ray_results/PPO_2024-10-31_12-54-11/PPO_CartPole-v1_8d5c1_00002_2_lr=0.0001_2024-10-31_12-54-11/checkpoint_000000)\n",
       "  )\n",
       "]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ray import train, tune\n",
    "\n",
    "config = (\n",
    "    PPOConfig()\n",
    "    .api_stack(\n",
    "        enable_rl_module_and_learner=True,\n",
    "        enable_env_runner_and_connector_v2=True,\n",
    "    )\n",
    "    .environment(\"CartPole-v1\")\n",
    "    .training(\n",
    "        lr=tune.grid_search([0.01, 0.001, 0.0001]),\n",
    "    )\n",
    ")\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    \"PPO\",\n",
    "    param_space=config,\n",
    "    run_config=train.RunConfig(\n",
    "        stop={\"env_runners/episode_return_mean\": 150.0},\n",
    "    ),\n",
    ")\n",
    "\n",
    "tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-10-31 12:56:01</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:45.21        </td></tr>\n",
       "<tr><td>Memory:      </td><td>15.1/15.8 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 9.0/24 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  : ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
       "  \n",
       "  \n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      num_env_steps_sample\n",
       "d_lifetime</th><th style=\"text-align: right;\">    num_episodes_lifetim\n",
       "e</th><th style=\"text-align: right;\">      num_env_steps_traine\n",
       "d_lifetime</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CartPole-v1_b41e7_00000</td><td>TERMINATED</td><td>127.0.0.1:5440 </td><td style=\"text-align: right;\">0.01  </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         31.6614</td><td style=\"text-align: right;\">20000</td><td style=\"text-align: right;\">453</td><td style=\"text-align: right;\">20461</td></tr>\n",
       "<tr><td>PPO_CartPole-v1_b41e7_00001</td><td>TERMINATED</td><td>127.0.0.1:2392 </td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         31.6532</td><td style=\"text-align: right;\">20000</td><td style=\"text-align: right;\">336</td><td style=\"text-align: right;\">20346</td></tr>\n",
       "<tr><td>PPO_CartPole-v1_b41e7_00002</td><td>TERMINATED</td><td>127.0.0.1:11676</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         31.8317</td><td style=\"text-align: right;\">20000</td><td style=\"text-align: right;\">355</td><td style=\"text-align: right;\">20365</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-31 12:56:01,908\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to 'C:/Users/User/ray_results/PPO_2024-10-31_12-55-16' in 0.0170s.\n",
      "2024-10-31 12:56:02,549\tINFO tune.py:1041 -- Total run time: 45.85 seconds (45.19 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "from ray import train, tune\n",
    "\n",
    "# Tuner.fit() allows setting a custom log directory (other than ~/ray-results).\n",
    "tuner = tune.Tuner(\n",
    "    \"PPO\",\n",
    "    param_space=config,\n",
    "    run_config=train.RunConfig(\n",
    "        stop={\"num_env_steps_sampled_lifetime\": 20000},\n",
    "        checkpoint_config=train.CheckpointConfig(checkpoint_at_end=True),\n",
    "    ),\n",
    ")\n",
    "\n",
    "results = tuner.fit()\n",
    "\n",
    "# Get the best result based on a particular metric.\n",
    "best_result = results.get_best_result(\n",
    "    metric=\"env_runners/episode_return_mean\", mode=\"max\"\n",
    ")\n",
    "\n",
    "# Get the best checkpoint corresponding to the best result.\n",
    "best_checkpoint = best_result.checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'checkpoint_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgorithms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgorithm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Algorithm\n\u001b[1;32m----> 2\u001b[0m algo \u001b[38;5;241m=\u001b[39m Algorithm\u001b[38;5;241m.\u001b[39mfrom_checkpoint(\u001b[43mcheckpoint_path\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'checkpoint_path' is not defined"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \n",
    "from ray.rllib.algorithms.algorithm import Algorithm\n",
    "algo = Algorithm.from_checkpoint(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached episode return of 500.0.\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "from ray.rllib.core.rl_module import RLModule\n",
    "\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "# Create only the neural network (RLModule) from our checkpoint.\n",
    "rl_module = RLModule.from_checkpoint(\n",
    "    pathlib.Path(best_checkpoint.path) / \"learner_group\" / \"learner\" / \"rl_module\"\n",
    ")[\"default_policy\"]\n",
    "\n",
    "episode_return = 0\n",
    "terminated = truncated = False\n",
    "\n",
    "obs, info = env.reset()\n",
    "\n",
    "while not terminated and not truncated:\n",
    "    # Compute the next action from a batch (B=1) of observations.\n",
    "    torch_obs_batch = torch.from_numpy(np.array([obs]))\n",
    "    action_logits = rl_module.forward_inference({\"obs\": torch_obs_batch})[\n",
    "        \"action_dist_inputs\"\n",
    "    ]\n",
    "    # The default RLModule used here produces action logits (from which\n",
    "    # we'll have to sample an action or use the max-likelihood one).\n",
    "    action = torch.argmax(action_logits[0]).numpy()\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    episode_return += reward\n",
    "\n",
    "print(f\"Reached episode return of {episode_return}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\robot_sim\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py:568: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "c:\\Users\\User\\anaconda3\\envs\\robot_sim\\lib\\site-packages\\ray\\tune\\logger\\unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "c:\\Users\\User\\anaconda3\\envs\\robot_sim\\lib\\site-packages\\ray\\tune\\logger\\unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "c:\\Users\\User\\anaconda3\\envs\\robot_sim\\lib\\site-packages\\ray\\tune\\logger\\unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "c:\\Users\\User\\anaconda3\\envs\\robot_sim\\lib\\site-packages\\gymnasium\\envs\\registration.py:693: UserWarning: \u001b[33mWARN: Overriding environment rllib-single-agent-env-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('encoder.actor_encoder.net.mlp.0.weight',\n",
       "               array([[ 0.48074734, -0.27554852,  0.3861252 ,  0.04286963],\n",
       "                      [-0.24321026,  0.10605699, -0.31143463,  0.45463032],\n",
       "                      [-0.2310844 ,  0.13257575,  0.40450126,  0.40058738],\n",
       "                      ...,\n",
       "                      [-0.39735532, -0.4630162 , -0.48954093, -0.20519793],\n",
       "                      [-0.01912349,  0.17111182, -0.12658882, -0.05784327],\n",
       "                      [ 0.3242514 ,  0.21938777, -0.07781363,  0.06862128]],\n",
       "                     dtype=float32)),\n",
       "              ('encoder.actor_encoder.net.mlp.0.bias',\n",
       "               array([-0.42349046, -0.09525579,  0.19313997,  0.24745929,  0.48743117,\n",
       "                      -0.44139707, -0.24722278, -0.11840814, -0.07465196, -0.15854478,\n",
       "                      -0.25044543, -0.4148047 , -0.25724047,  0.15085763,  0.44752496,\n",
       "                      -0.3305989 ,  0.00122595,  0.0494591 , -0.45621443,  0.44512528,\n",
       "                      -0.08727521,  0.4556445 , -0.18121558,  0.26333153,  0.49070042,\n",
       "                      -0.11704606,  0.23079914, -0.3037504 , -0.00058883, -0.22521228,\n",
       "                      -0.3618093 , -0.27271616,  0.3458839 , -0.06827897,  0.3111347 ,\n",
       "                      -0.13284886,  0.29187316, -0.3529771 , -0.25299948, -0.04151767,\n",
       "                       0.34041613,  0.3062135 , -0.00503838,  0.47687757,  0.03452969,\n",
       "                       0.38654178,  0.06352353, -0.15762585,  0.15518814, -0.25545675,\n",
       "                       0.39882457, -0.04925185,  0.20924348,  0.21864372, -0.35129815,\n",
       "                       0.19893348,  0.32212925,  0.25336236,  0.08955634,  0.09379625,\n",
       "                       0.26815963,  0.13536948,  0.2600597 ,  0.22009802, -0.48384982,\n",
       "                       0.06317121,  0.4788425 ,  0.3695342 , -0.16281015,  0.4809698 ,\n",
       "                       0.35959852,  0.08468854, -0.43470466, -0.03108668, -0.1767999 ,\n",
       "                       0.26140672, -0.05193913, -0.35291213, -0.3534943 ,  0.05708683,\n",
       "                      -0.42946786, -0.26655805, -0.1463862 , -0.34849405,  0.1520145 ,\n",
       "                      -0.46492732, -0.23699778, -0.38120943,  0.18881488, -0.47822875,\n",
       "                      -0.13067418,  0.42043787, -0.481502  ,  0.3610897 , -0.13513154,\n",
       "                       0.03504515,  0.3005873 , -0.42850834,  0.43186653, -0.44459164,\n",
       "                       0.06889832, -0.37436235, -0.26397288, -0.48741382, -0.35603803,\n",
       "                      -0.0277853 , -0.15849668,  0.46113133,  0.3969807 , -0.4706434 ,\n",
       "                       0.06859666, -0.30697703, -0.33360374,  0.2497344 ,  0.36564487,\n",
       "                       0.40830958,  0.24911523,  0.4905694 ,  0.4989558 ,  0.01195931,\n",
       "                       0.18655133, -0.09299272,  0.12612695,  0.47901607,  0.46042448,\n",
       "                       0.22366095, -0.21398783,  0.15625513, -0.46728235,  0.31943464,\n",
       "                       0.05910146, -0.11065191,  0.15188324,  0.11132276,  0.12232471,\n",
       "                      -0.38283664, -0.32266313, -0.03145319, -0.25123394, -0.45093697,\n",
       "                      -0.20454866,  0.20811397,  0.24444902,  0.10563165, -0.449444  ,\n",
       "                       0.27179945,  0.12521243, -0.36974007,  0.12053192, -0.08887333,\n",
       "                      -0.00237858, -0.46484983,  0.30467528,  0.23171341, -0.48680317,\n",
       "                      -0.34509885, -0.11753583,  0.00120604,  0.32154357, -0.20469075,\n",
       "                       0.18866932,  0.14718646,  0.0734629 ,  0.3212204 , -0.05799854,\n",
       "                       0.00121045,  0.12572324,  0.37709963, -0.28302222,  0.32761496,\n",
       "                       0.34815592, -0.43725258,  0.16602552, -0.42888993, -0.1773951 ,\n",
       "                      -0.07594234,  0.12367356, -0.07739776,  0.0563761 , -0.076617  ,\n",
       "                      -0.29747128,  0.26988065, -0.33076668,  0.08757293,  0.2334866 ,\n",
       "                       0.01382673, -0.2238949 ,  0.04937357, -0.49435169, -0.10457748,\n",
       "                      -0.04843348, -0.22782314,  0.2776119 , -0.4167602 , -0.07826817,\n",
       "                       0.27114475, -0.29941088, -0.4791932 , -0.01752067, -0.36992955,\n",
       "                       0.11926144, -0.3889057 , -0.45995533,  0.36747444, -0.261055  ,\n",
       "                      -0.03951073,  0.0571503 ,  0.36328572, -0.08340716,  0.09900635,\n",
       "                      -0.2431348 ,  0.12079334, -0.4723543 ,  0.34179312,  0.38352585,\n",
       "                       0.19006807, -0.1895814 , -0.44292855,  0.28780967, -0.02999926,\n",
       "                       0.0650602 , -0.2106415 , -0.01179242,  0.23550338,  0.36438674,\n",
       "                       0.32621413, -0.12410241, -0.0442239 ,  0.06463236,  0.23559386,\n",
       "                       0.1964395 ,  0.34015417, -0.07768077, -0.00849748, -0.2581331 ,\n",
       "                       0.1665889 , -0.26239818, -0.33595294, -0.02665967, -0.03963792,\n",
       "                      -0.06419784,  0.46261388, -0.15051544,  0.39061642, -0.09580386,\n",
       "                       0.321258  ,  0.3284443 ,  0.1394993 ,  0.22187614, -0.04445052,\n",
       "                       0.23289758, -0.43271238,  0.10471064, -0.11713976, -0.1672275 ,\n",
       "                       0.14586085], dtype=float32)),\n",
       "              ('encoder.actor_encoder.net.mlp.2.weight',\n",
       "               array([[ 0.0080853 ,  0.0323079 , -0.01465252, ..., -0.06127897,\n",
       "                       -0.00958588, -0.00554363],\n",
       "                      [ 0.01876203,  0.02576252, -0.03728223, ...,  0.05412225,\n",
       "                        0.03903201, -0.01636995],\n",
       "                      [-0.0550908 ,  0.04494536, -0.02781003, ..., -0.00592026,\n",
       "                        0.00825797,  0.01999169],\n",
       "                      ...,\n",
       "                      [-0.05552784,  0.06104954,  0.0268489 , ...,  0.04719555,\n",
       "                       -0.04467792,  0.05105264],\n",
       "                      [ 0.03538422,  0.01028964, -0.03888112, ...,  0.0447339 ,\n",
       "                        0.02617799,  0.05129713],\n",
       "                      [ 0.03616749,  0.03662371,  0.01864403, ..., -0.05116637,\n",
       "                        0.0012651 , -0.02736761]], dtype=float32)),\n",
       "              ('encoder.actor_encoder.net.mlp.2.bias',\n",
       "               array([-0.05483877, -0.01086856, -0.03207282, -0.0552389 ,  0.01882464,\n",
       "                      -0.01450511, -0.01380897,  0.05619115,  0.05519126,  0.04282037,\n",
       "                       0.03509031,  0.03354106, -0.04671952, -0.06044195,  0.01564992,\n",
       "                      -0.04305147,  0.03614965,  0.0415917 , -0.0038927 , -0.004899  ,\n",
       "                      -0.05780224, -0.0533485 ,  0.03472023,  0.00340761, -0.02871916,\n",
       "                      -0.00972235, -0.02855749,  0.00833875,  0.01581182,  0.0402784 ,\n",
       "                      -0.04621128,  0.01321653,  0.00713679,  0.01711406,  0.05675553,\n",
       "                       0.01896555,  0.02573644, -0.02135059,  0.05447394,  0.00154029,\n",
       "                      -0.01055746, -0.05033091, -0.01253972, -0.03773767,  0.05537674,\n",
       "                      -0.01933166,  0.01061918, -0.03585333, -0.05046893,  0.02679718,\n",
       "                      -0.02248682, -0.00390609, -0.04337259, -0.05562791,  0.05375476,\n",
       "                       0.02637898, -0.00141916, -0.04103174,  0.03685857, -0.00492857,\n",
       "                       0.04252353, -0.05218405,  0.05588352,  0.0523124 ,  0.03077457,\n",
       "                       0.00319422, -0.01491351,  0.03097296,  0.02350119,  0.03280596,\n",
       "                      -0.01163071, -0.00149412,  0.00887439, -0.00645337,  0.00935113,\n",
       "                      -0.0297704 , -0.05755456, -0.03402695,  0.01241969, -0.01056965,\n",
       "                      -0.03863885, -0.03198112, -0.04319225,  0.01598708, -0.0573564 ,\n",
       "                      -0.03952409, -0.04335008,  0.03233831, -0.00139181,  0.03103629,\n",
       "                      -0.00994296,  0.00917005,  0.01976459, -0.03961627, -0.00158481,\n",
       "                       0.02140968,  0.01065383,  0.05452738,  0.043435  ,  0.04814623,\n",
       "                       0.06058702,  0.01445234, -0.01643939,  0.02355924, -0.04464138,\n",
       "                       0.02946414, -0.00680022, -0.031203  , -0.0524231 , -0.02359964,\n",
       "                       0.02479652, -0.04862949,  0.00586469,  0.06141276,  0.04868831,\n",
       "                      -0.0549775 , -0.0441525 , -0.03484207,  0.0170425 ,  0.04560956,\n",
       "                      -0.00483965,  0.02991773, -0.04983599, -0.03013872,  0.0200049 ,\n",
       "                      -0.01100041,  0.00302176,  0.06180231,  0.0606821 ,  0.00774136,\n",
       "                      -0.06181286, -0.05106541, -0.03253734,  0.00076006,  0.04528134,\n",
       "                       0.04536685, -0.01956477, -0.05361608, -0.04194389, -0.00057021,\n",
       "                       0.04830877, -0.02192818,  0.04167057,  0.05980831,  0.02535572,\n",
       "                      -0.0182219 ,  0.01780368,  0.01645698, -0.05084711, -0.04098175,\n",
       "                       0.05212468,  0.0359209 , -0.02741921,  0.01846322,  0.03562854,\n",
       "                       0.0060561 ,  0.02918175,  0.01737678, -0.0259941 ,  0.05300344,\n",
       "                       0.04106186,  0.06206771, -0.01854938, -0.03596983,  0.01116497,\n",
       "                      -0.02982195,  0.00608473, -0.04943457,  0.06167192,  0.03046296,\n",
       "                      -0.05509935, -0.0050344 , -0.04343363, -0.0058882 ,  0.0593544 ,\n",
       "                       0.04574297, -0.04399016,  0.02661696,  0.01928407, -0.05388333,\n",
       "                      -0.01688489, -0.00736087, -0.05035202, -0.00361029,  0.02662237,\n",
       "                       0.00073697,  0.00108735, -0.02679612,  0.02167954, -0.00132145,\n",
       "                      -0.00935175, -0.04849719, -0.05376819,  0.00210511, -0.05536161,\n",
       "                       0.06031001, -0.00180104,  0.04166397, -0.04506802, -0.02179777,\n",
       "                      -0.03709916,  0.042459  , -0.00148279,  0.02729861,  0.03835669,\n",
       "                       0.01963177,  0.02144207,  0.03831054, -0.05218957, -0.061122  ,\n",
       "                      -0.02443933, -0.05227674, -0.03654977, -0.0468559 ,  0.05019763,\n",
       "                       0.01030625,  0.03729323, -0.04271524,  0.02058569, -0.04590709,\n",
       "                       0.05823355, -0.03842904, -0.00373325,  0.00221756,  0.05255467,\n",
       "                       0.05940501,  0.01632934, -0.05693398,  0.05085645, -0.05413631,\n",
       "                      -0.04562555, -0.00967639,  0.01083607,  0.00462099,  0.05404604,\n",
       "                      -0.05625762, -0.03727283, -0.01790421,  0.02352455, -0.04932119,\n",
       "                       0.04756055,  0.0075471 ,  0.0459665 , -0.01867156, -0.00710109,\n",
       "                      -0.05484503, -0.05243585,  0.01341348, -0.04779353, -0.06238955,\n",
       "                       0.038638  , -0.02603606,  0.04313762,  0.04631102, -0.03641137,\n",
       "                      -0.01792917], dtype=float32)),\n",
       "              ('pi.log_std_clip_param_const', array([20.], dtype=float32)),\n",
       "              ('pi.net.mlp.0.weight',\n",
       "               array([[-0.01313671, -0.00173075,  0.04167236,  0.00575058,  0.04594432,\n",
       "                       -0.0103353 , -0.00224185,  0.01999455, -0.05939083, -0.03014329,\n",
       "                        0.02038279, -0.03045558,  0.02740541, -0.05398218, -0.0066882 ,\n",
       "                       -0.04798061,  0.01209146,  0.00263563,  0.0266151 ,  0.00823582,\n",
       "                        0.0170964 ,  0.04946152,  0.05078118,  0.04242834,  0.04692595,\n",
       "                       -0.02865938,  0.04562116,  0.06243119, -0.04143283,  0.00983918,\n",
       "                       -0.05308914, -0.01373731,  0.02157784,  0.04832786,  0.02550694,\n",
       "                       -0.04610106,  0.04206516,  0.05700564,  0.04209153, -0.01511254,\n",
       "                        0.0103054 , -0.0468247 ,  0.05531837,  0.00011243,  0.008506  ,\n",
       "                        0.00765128, -0.01526   ,  0.01157278,  0.02141973,  0.02813394,\n",
       "                       -0.02252876,  0.03739684, -0.04128118, -0.02670424, -0.0328301 ,\n",
       "                        0.01437586, -0.01368906, -0.00347359,  0.03529309,  0.04651532,\n",
       "                       -0.0510945 , -0.03307255, -0.01154967, -0.0464215 ,  0.02322236,\n",
       "                        0.02310637,  0.04682424,  0.01760754,  0.02175149,  0.00428822,\n",
       "                       -0.01677097, -0.05158218,  0.04999451, -0.01202732, -0.014318  ,\n",
       "                       -0.00882027,  0.0219216 , -0.03830662, -0.03718287, -0.0099023 ,\n",
       "                        0.01116969,  0.04841509,  0.04649531,  0.05671351, -0.00169657,\n",
       "                        0.05335541,  0.03423308, -0.0426086 ,  0.004724  ,  0.04073806,\n",
       "                       -0.02228359, -0.00732937, -0.01798267, -0.05716844, -0.00562861,\n",
       "                        0.04979683,  0.00465437, -0.04759078,  0.03267837, -0.02506749,\n",
       "                       -0.03884327,  0.04107001, -0.01481468,  0.04354573,  0.02086639,\n",
       "                        0.02365147,  0.02765702, -0.006198  , -0.00747155, -0.05953271,\n",
       "                        0.0595983 ,  0.01615798, -0.01235236, -0.0159465 , -0.02539399,\n",
       "                       -0.03083641,  0.00859643, -0.05217274,  0.01111576, -0.01217937,\n",
       "                       -0.02365668,  0.05117048, -0.06019244, -0.05971586,  0.03666333,\n",
       "                        0.02221389,  0.00842257, -0.02503069, -0.03225253, -0.05196583,\n",
       "                        0.04490815, -0.04820148, -0.04307986,  0.00228114, -0.00178972,\n",
       "                       -0.00287166, -0.05981685, -0.03170202,  0.02397207,  0.02933534,\n",
       "                       -0.04444902,  0.04366769,  0.05520859,  0.00274657,  0.01108017,\n",
       "                       -0.042826  ,  0.04730872,  0.00878555, -0.03733391,  0.00243246,\n",
       "                        0.04727523, -0.04004619, -0.02240922, -0.02858298, -0.03563883,\n",
       "                        0.00263787,  0.04021375,  0.00302777,  0.00305723,  0.02089957,\n",
       "                       -0.06119261, -0.05736507, -0.01306706,  0.00637399,  0.02837564,\n",
       "                        0.04017717,  0.04416613,  0.03681602, -0.04259226,  0.03005847,\n",
       "                        0.01231644, -0.05380039,  0.05157653,  0.01721138,  0.00918559,\n",
       "                       -0.00488909,  0.01849586, -0.03477903, -0.03133502, -0.00646163,\n",
       "                        0.04769563,  0.03764308, -0.02803403,  0.00639565,  0.02501041,\n",
       "                       -0.05828516,  0.01711814, -0.03926115,  0.03584143, -0.01973251,\n",
       "                       -0.02866747, -0.05991889, -0.03124879, -0.01271755, -0.02110961,\n",
       "                       -0.053663  , -0.03612147,  0.04159606,  0.01346264,  0.03979391,\n",
       "                        0.04219094, -0.05944049,  0.05424672, -0.02876265,  0.01464498,\n",
       "                       -0.00155015,  0.04252493,  0.06166948,  0.04501007, -0.03145634,\n",
       "                        0.05738986,  0.0268788 ,  0.01203227, -0.02544892, -0.01781096,\n",
       "                        0.03170944,  0.05819654, -0.03001004,  0.06216743, -0.05042212,\n",
       "                        0.05312058, -0.04738064, -0.0166346 ,  0.06016381, -0.00801235,\n",
       "                       -0.05082443, -0.01290483, -0.00210752, -0.03113911,  0.01442955,\n",
       "                        0.01213247, -0.06193651, -0.06084687,  0.03197943, -0.00660754,\n",
       "                        0.04971921, -0.03238543,  0.02313472, -0.04505336,  0.04033609,\n",
       "                       -0.03816813,  0.03772196,  0.03979667,  0.00439757, -0.02776327,\n",
       "                       -0.02946671, -0.05176897,  0.05782506,  0.01346825, -0.05134817,\n",
       "                        0.0456559 , -0.02067457,  0.04440528, -0.01511118, -0.01230736,\n",
       "                       -0.02351792],\n",
       "                      [ 0.01949818,  0.0398969 , -0.03242809, -0.05052533, -0.03656701,\n",
       "                        0.03732007,  0.02779944, -0.0037123 , -0.05525424, -0.0342093 ,\n",
       "                        0.01767053, -0.04596609, -0.01509397, -0.03473909, -0.0185442 ,\n",
       "                       -0.04429118,  0.03132825,  0.05942085, -0.03178602,  0.00886004,\n",
       "                        0.06199326, -0.05198236,  0.04893436, -0.01360759, -0.0130163 ,\n",
       "                       -0.06216436, -0.05426211, -0.02136708, -0.03460015,  0.03853048,\n",
       "                       -0.05114377, -0.02658971,  0.04226289,  0.02568338, -0.05930212,\n",
       "                        0.05589007,  0.03016873, -0.06103218,  0.02360252, -0.04613745,\n",
       "                        0.01478528,  0.02159323, -0.01338396,  0.00572348,  0.05043457,\n",
       "                       -0.02644963,  0.00660767,  0.04075736, -0.00648788, -0.04134962,\n",
       "                        0.03616478,  0.03211886, -0.03155123,  0.03663921,  0.05897919,\n",
       "                        0.0344949 ,  0.0308792 , -0.02531863,  0.01215278,  0.04409729,\n",
       "                       -0.05928946,  0.01089086, -0.01731156,  0.00403932, -0.04633197,\n",
       "                       -0.03007106,  0.05195288, -0.04597612,  0.0003755 , -0.00247356,\n",
       "                       -0.05027652,  0.05578275, -0.00426263, -0.01710191,  0.00880483,\n",
       "                        0.04121914,  0.05194912, -0.04424093, -0.00276189,  0.03559946,\n",
       "                       -0.05263678,  0.01658513,  0.03650089,  0.04713741, -0.04107349,\n",
       "                       -0.05577666, -0.04382362,  0.02804866,  0.01116478,  0.0425243 ,\n",
       "                        0.04645891,  0.04630507,  0.03079243, -0.04402997, -0.02206876,\n",
       "                        0.01579694, -0.0237233 , -0.01103821,  0.04993603,  0.00521007,\n",
       "                       -0.03059959, -0.04783435, -0.0290435 , -0.05480897, -0.05900099,\n",
       "                       -0.06229038, -0.04005285,  0.0599615 ,  0.01589551, -0.01492995,\n",
       "                        0.0586545 , -0.05070681,  0.06015033, -0.01627359,  0.01404962,\n",
       "                       -0.04692873,  0.00910296,  0.03336567,  0.00766423,  0.02254967,\n",
       "                       -0.02000728, -0.05308246,  0.03376099, -0.0091566 , -0.04433458,\n",
       "                       -0.05111946, -0.04624216,  0.05078097,  0.02339116,  0.00523171,\n",
       "                       -0.05330604,  0.01917763,  0.01429494, -0.06165884, -0.03934342,\n",
       "                       -0.02155685, -0.0053166 ,  0.05595464, -0.00059628,  0.03987124,\n",
       "                        0.02924772,  0.05395145,  0.02677169,  0.00031842,  0.05028171,\n",
       "                        0.06239859,  0.01146857, -0.05917674, -0.04537854,  0.00864206,\n",
       "                       -0.03143852, -0.00038201,  0.01063187,  0.03560904,  0.04076108,\n",
       "                        0.01437438, -0.0053601 , -0.04875275, -0.04126211, -0.00962576,\n",
       "                       -0.03952285,  0.02164524,  0.00428326, -0.01472887, -0.01192643,\n",
       "                       -0.03661261,  0.03702688,  0.01490717, -0.04080921,  0.02416848,\n",
       "                        0.03922965,  0.05206028,  0.00948313,  0.01319379,  0.06097715,\n",
       "                        0.03275237,  0.03182915, -0.03807483, -0.05893101, -0.00905039,\n",
       "                        0.0135575 , -0.0400764 , -0.03752891, -0.01637033,  0.01453601,\n",
       "                       -0.0597759 ,  0.04734781,  0.04411278, -0.03574504,  0.04127835,\n",
       "                       -0.05046581,  0.00377101, -0.01150955,  0.03446755,  0.01713137,\n",
       "                       -0.05522966, -0.04899348,  0.03628014, -0.00310334, -0.0067618 ,\n",
       "                       -0.02642173, -0.02165736,  0.02379757,  0.00998969,  0.0195431 ,\n",
       "                        0.03804238,  0.05275122, -0.01770315, -0.05527505, -0.00929274,\n",
       "                       -0.03526432, -0.0605516 ,  0.0321383 ,  0.05237477,  0.00307608,\n",
       "                       -0.03332259, -0.01933326, -0.01112966,  0.05464538, -0.00873809,\n",
       "                        0.03118315,  0.04765485, -0.0527145 ,  0.0290682 ,  0.00433207,\n",
       "                        0.00722915, -0.02725794,  0.026506  ,  0.02612773,  0.04341318,\n",
       "                        0.03199492, -0.03975249,  0.01735438, -0.01804987, -0.05817404,\n",
       "                        0.04095325, -0.03172841, -0.02755065,  0.03212278,  0.03638732,\n",
       "                       -0.04925679,  0.01047102,  0.02932756, -0.03436913,  0.0430408 ,\n",
       "                        0.04257266,  0.05655405, -0.04755934,  0.04568511,  0.01169502,\n",
       "                       -0.00755979, -0.06015145,  0.02758955,  0.04890035, -0.0212636 ,\n",
       "                       -0.03758594]], dtype=float32)),\n",
       "              ('pi.net.mlp.0.bias',\n",
       "               array([0.0286466 , 0.04479951], dtype=float32)),\n",
       "              ('vf.log_std_clip_param_const', array([20.], dtype=float32)),\n",
       "              ('vf.net.mlp.0.weight',\n",
       "               array([[-4.38579395e-02,  3.84296179e-02,  7.30851293e-03,\n",
       "                        5.89352921e-02,  3.57827023e-02, -3.29493135e-02,\n",
       "                        2.29707882e-02,  3.45619395e-02,  2.60238722e-02,\n",
       "                        3.20152864e-02, -5.41778803e-02,  6.04118407e-03,\n",
       "                       -3.82698253e-02,  3.55751440e-02, -5.92633113e-02,\n",
       "                       -5.15268147e-02, -6.05711043e-02, -4.27605361e-02,\n",
       "                       -5.60979322e-02, -3.04131359e-02, -4.18453813e-02,\n",
       "                       -3.41624990e-02, -8.87387991e-03,  5.24062663e-02,\n",
       "                        2.59869695e-02,  5.23888692e-02, -7.53656775e-03,\n",
       "                        5.66210151e-02,  6.17952123e-02,  3.96024436e-02,\n",
       "                       -4.63220552e-02, -3.48933861e-02,  3.62212360e-02,\n",
       "                       -3.78312171e-02,  4.35796678e-02,  1.81376636e-02,\n",
       "                        5.15282154e-05,  2.97458172e-02, -5.63487783e-02,\n",
       "                       -4.81405035e-02,  2.93824822e-02, -4.56098393e-02,\n",
       "                        4.77089211e-02,  2.19630823e-02, -5.95590472e-03,\n",
       "                        4.80804220e-02, -2.10099667e-02,  3.96736711e-02,\n",
       "                       -4.64252830e-02,  4.35511991e-02, -5.46430200e-02,\n",
       "                       -3.47858667e-03,  2.40646899e-02,  4.12048697e-02,\n",
       "                        5.94633520e-02,  1.30185783e-02, -3.64959687e-02,\n",
       "                       -2.23206580e-02, -1.58635527e-02,  4.09732237e-02,\n",
       "                        6.24267682e-02, -1.32536814e-02, -1.98795572e-02,\n",
       "                       -5.37328869e-02,  5.80734834e-02,  2.04055533e-02,\n",
       "                       -5.77092767e-02, -1.98804513e-02, -5.56113794e-02,\n",
       "                        4.33714166e-02, -4.05940935e-02,  2.75015086e-02,\n",
       "                        1.63422748e-02,  2.71921828e-02,  1.09504908e-02,\n",
       "                        4.46824580e-02, -5.55777773e-02,  4.24000323e-02,\n",
       "                       -5.24023473e-02, -5.66927567e-02, -3.82010192e-02,\n",
       "                       -3.94713208e-02,  6.01036251e-02, -2.71104276e-02,\n",
       "                       -3.77201065e-02,  8.29346478e-04,  3.05007547e-02,\n",
       "                        4.70696762e-02, -3.79600972e-02,  3.37521657e-02,\n",
       "                        2.41796225e-02,  5.01814112e-02, -3.75028849e-02,\n",
       "                        6.05072826e-03, -4.16494757e-02, -1.88145041e-02,\n",
       "                        4.80158255e-02, -9.04949009e-03, -8.42853636e-03,\n",
       "                       -6.05097860e-02,  5.27416766e-02, -2.09270194e-02,\n",
       "                        1.70594826e-02, -1.63819566e-02,  2.25158483e-02,\n",
       "                       -5.94831407e-02, -4.54984456e-02, -4.51187417e-02,\n",
       "                       -3.85496914e-02,  2.94025093e-02, -1.75440013e-02,\n",
       "                       -1.60047337e-02,  1.85239315e-02,  1.63882673e-02,\n",
       "                       -2.96498239e-02,  4.27850559e-02, -2.82991081e-02,\n",
       "                        5.31192645e-02,  1.60814673e-02, -4.93692532e-02,\n",
       "                        2.15410441e-02,  3.24847177e-02,  4.29324806e-03,\n",
       "                       -5.28914779e-02,  7.28002191e-03,  3.56843621e-02,\n",
       "                        4.96090949e-03, -3.63143757e-02, -6.21508509e-02,\n",
       "                       -3.81521136e-02,  2.70427763e-03,  5.87178618e-02,\n",
       "                       -4.65644673e-02,  5.15028238e-02, -5.02767116e-02,\n",
       "                        2.53669173e-03, -4.52635437e-03,  2.99434662e-02,\n",
       "                        2.12851316e-02,  3.34956497e-02, -9.21063870e-03,\n",
       "                       -8.36863369e-03,  1.73839852e-02,  2.72855088e-02,\n",
       "                       -6.02403581e-02,  2.16071978e-02,  3.46179977e-02,\n",
       "                       -4.94465604e-02, -5.60245663e-02,  3.72438803e-02,\n",
       "                        1.34375021e-02,  1.28111616e-02,  4.25518453e-02,\n",
       "                       -1.91465467e-02,  5.99899739e-02,  2.81993300e-03,\n",
       "                        2.49949470e-02,  4.08256054e-03,  4.87532839e-02,\n",
       "                        4.19584736e-02, -1.82164982e-02,  4.76526618e-02,\n",
       "                       -5.35710976e-02,  1.11621916e-02, -1.82331428e-02,\n",
       "                       -5.71545213e-03,  2.10446417e-02, -1.99286565e-02,\n",
       "                        1.58931836e-02, -1.56712979e-02,  3.97454575e-02,\n",
       "                       -2.26154923e-02, -1.40918493e-02,  4.79451045e-02,\n",
       "                       -5.85730970e-02,  6.11231998e-02,  3.48509923e-02,\n",
       "                        1.25770569e-02, -5.69203794e-02,  9.20674205e-03,\n",
       "                        1.00363791e-02,  4.09524143e-02, -5.40560633e-02,\n",
       "                       -5.22027612e-02, -2.39338875e-02, -4.31842804e-02,\n",
       "                       -1.20813474e-02,  3.90742347e-02, -2.58318931e-02,\n",
       "                        5.26126698e-02,  3.90398800e-02,  3.83662432e-02,\n",
       "                        9.14666802e-03,  5.45099303e-02, -5.03492653e-02,\n",
       "                       -2.35545114e-02, -5.99846616e-02,  3.82855311e-02,\n",
       "                        4.75480035e-02, -1.28459558e-02, -3.08090895e-02,\n",
       "                        1.80774033e-02, -5.91847524e-02,  2.52962857e-03,\n",
       "                       -1.77069902e-02, -3.27503234e-02,  3.98357064e-02,\n",
       "                       -4.00983617e-02,  1.14134774e-02,  6.80776685e-03,\n",
       "                        2.23727450e-02,  2.73922458e-02,  3.58364582e-02,\n",
       "                        2.91974321e-02, -4.52228487e-02, -3.81384045e-02,\n",
       "                        5.80490232e-02,  1.15245655e-02,  9.40056145e-03,\n",
       "                        1.51737258e-02, -7.23536313e-03, -1.88372731e-02,\n",
       "                        3.11479717e-02, -1.13700554e-02, -9.31070000e-03,\n",
       "                       -3.71849909e-02, -4.39057425e-02,  1.98085085e-02,\n",
       "                       -2.94934809e-02, -3.54765207e-02, -2.84563750e-03,\n",
       "                        3.33583206e-02,  1.99474245e-02, -5.16449660e-02,\n",
       "                       -5.09012938e-02, -4.52280864e-02,  2.34317929e-02,\n",
       "                        4.67777252e-03, -3.65714580e-02,  3.88582498e-02,\n",
       "                       -6.24651089e-02, -3.43331471e-02, -3.39533240e-02,\n",
       "                        4.12301570e-02,  5.88023663e-02,  4.82607633e-02,\n",
       "                       -5.68071231e-02, -1.03691369e-02, -8.96526873e-03,\n",
       "                        5.54292426e-02, -5.65575063e-02,  3.81417722e-02,\n",
       "                        4.04348224e-03, -1.55888721e-02,  3.28163654e-02,\n",
       "                        7.55415112e-03]], dtype=float32)),\n",
       "              ('vf.net.mlp.0.bias', array([0.00081867], dtype=float32))]),\n",
       " OrderedDict([('encoder.actor_encoder.net.mlp.0.weight',\n",
       "               array([[ 0.48074734, -0.27554852,  0.3861252 ,  0.04286963],\n",
       "                      [-0.24321026,  0.10605699, -0.31143463,  0.45463032],\n",
       "                      [-0.2310844 ,  0.13257575,  0.40450126,  0.40058738],\n",
       "                      ...,\n",
       "                      [-0.39735532, -0.4630162 , -0.48954093, -0.20519793],\n",
       "                      [-0.01912349,  0.17111182, -0.12658882, -0.05784327],\n",
       "                      [ 0.3242514 ,  0.21938777, -0.07781363,  0.06862128]],\n",
       "                     dtype=float32)),\n",
       "              ('encoder.actor_encoder.net.mlp.0.bias',\n",
       "               array([-0.42349046, -0.09525579,  0.19313997,  0.24745929,  0.48743117,\n",
       "                      -0.44139707, -0.24722278, -0.11840814, -0.07465196, -0.15854478,\n",
       "                      -0.25044543, -0.4148047 , -0.25724047,  0.15085763,  0.44752496,\n",
       "                      -0.3305989 ,  0.00122595,  0.0494591 , -0.45621443,  0.44512528,\n",
       "                      -0.08727521,  0.4556445 , -0.18121558,  0.26333153,  0.49070042,\n",
       "                      -0.11704606,  0.23079914, -0.3037504 , -0.00058883, -0.22521228,\n",
       "                      -0.3618093 , -0.27271616,  0.3458839 , -0.06827897,  0.3111347 ,\n",
       "                      -0.13284886,  0.29187316, -0.3529771 , -0.25299948, -0.04151767,\n",
       "                       0.34041613,  0.3062135 , -0.00503838,  0.47687757,  0.03452969,\n",
       "                       0.38654178,  0.06352353, -0.15762585,  0.15518814, -0.25545675,\n",
       "                       0.39882457, -0.04925185,  0.20924348,  0.21864372, -0.35129815,\n",
       "                       0.19893348,  0.32212925,  0.25336236,  0.08955634,  0.09379625,\n",
       "                       0.26815963,  0.13536948,  0.2600597 ,  0.22009802, -0.48384982,\n",
       "                       0.06317121,  0.4788425 ,  0.3695342 , -0.16281015,  0.4809698 ,\n",
       "                       0.35959852,  0.08468854, -0.43470466, -0.03108668, -0.1767999 ,\n",
       "                       0.26140672, -0.05193913, -0.35291213, -0.3534943 ,  0.05708683,\n",
       "                      -0.42946786, -0.26655805, -0.1463862 , -0.34849405,  0.1520145 ,\n",
       "                      -0.46492732, -0.23699778, -0.38120943,  0.18881488, -0.47822875,\n",
       "                      -0.13067418,  0.42043787, -0.481502  ,  0.3610897 , -0.13513154,\n",
       "                       0.03504515,  0.3005873 , -0.42850834,  0.43186653, -0.44459164,\n",
       "                       0.06889832, -0.37436235, -0.26397288, -0.48741382, -0.35603803,\n",
       "                      -0.0277853 , -0.15849668,  0.46113133,  0.3969807 , -0.4706434 ,\n",
       "                       0.06859666, -0.30697703, -0.33360374,  0.2497344 ,  0.36564487,\n",
       "                       0.40830958,  0.24911523,  0.4905694 ,  0.4989558 ,  0.01195931,\n",
       "                       0.18655133, -0.09299272,  0.12612695,  0.47901607,  0.46042448,\n",
       "                       0.22366095, -0.21398783,  0.15625513, -0.46728235,  0.31943464,\n",
       "                       0.05910146, -0.11065191,  0.15188324,  0.11132276,  0.12232471,\n",
       "                      -0.38283664, -0.32266313, -0.03145319, -0.25123394, -0.45093697,\n",
       "                      -0.20454866,  0.20811397,  0.24444902,  0.10563165, -0.449444  ,\n",
       "                       0.27179945,  0.12521243, -0.36974007,  0.12053192, -0.08887333,\n",
       "                      -0.00237858, -0.46484983,  0.30467528,  0.23171341, -0.48680317,\n",
       "                      -0.34509885, -0.11753583,  0.00120604,  0.32154357, -0.20469075,\n",
       "                       0.18866932,  0.14718646,  0.0734629 ,  0.3212204 , -0.05799854,\n",
       "                       0.00121045,  0.12572324,  0.37709963, -0.28302222,  0.32761496,\n",
       "                       0.34815592, -0.43725258,  0.16602552, -0.42888993, -0.1773951 ,\n",
       "                      -0.07594234,  0.12367356, -0.07739776,  0.0563761 , -0.076617  ,\n",
       "                      -0.29747128,  0.26988065, -0.33076668,  0.08757293,  0.2334866 ,\n",
       "                       0.01382673, -0.2238949 ,  0.04937357, -0.49435169, -0.10457748,\n",
       "                      -0.04843348, -0.22782314,  0.2776119 , -0.4167602 , -0.07826817,\n",
       "                       0.27114475, -0.29941088, -0.4791932 , -0.01752067, -0.36992955,\n",
       "                       0.11926144, -0.3889057 , -0.45995533,  0.36747444, -0.261055  ,\n",
       "                      -0.03951073,  0.0571503 ,  0.36328572, -0.08340716,  0.09900635,\n",
       "                      -0.2431348 ,  0.12079334, -0.4723543 ,  0.34179312,  0.38352585,\n",
       "                       0.19006807, -0.1895814 , -0.44292855,  0.28780967, -0.02999926,\n",
       "                       0.0650602 , -0.2106415 , -0.01179242,  0.23550338,  0.36438674,\n",
       "                       0.32621413, -0.12410241, -0.0442239 ,  0.06463236,  0.23559386,\n",
       "                       0.1964395 ,  0.34015417, -0.07768077, -0.00849748, -0.2581331 ,\n",
       "                       0.1665889 , -0.26239818, -0.33595294, -0.02665967, -0.03963792,\n",
       "                      -0.06419784,  0.46261388, -0.15051544,  0.39061642, -0.09580386,\n",
       "                       0.321258  ,  0.3284443 ,  0.1394993 ,  0.22187614, -0.04445052,\n",
       "                       0.23289758, -0.43271238,  0.10471064, -0.11713976, -0.1672275 ,\n",
       "                       0.14586085], dtype=float32)),\n",
       "              ('encoder.actor_encoder.net.mlp.2.weight',\n",
       "               array([[ 0.0080853 ,  0.0323079 , -0.01465252, ..., -0.06127897,\n",
       "                       -0.00958588, -0.00554363],\n",
       "                      [ 0.01876203,  0.02576252, -0.03728223, ...,  0.05412225,\n",
       "                        0.03903201, -0.01636995],\n",
       "                      [-0.0550908 ,  0.04494536, -0.02781003, ..., -0.00592026,\n",
       "                        0.00825797,  0.01999169],\n",
       "                      ...,\n",
       "                      [-0.05552784,  0.06104954,  0.0268489 , ...,  0.04719555,\n",
       "                       -0.04467792,  0.05105264],\n",
       "                      [ 0.03538422,  0.01028964, -0.03888112, ...,  0.0447339 ,\n",
       "                        0.02617799,  0.05129713],\n",
       "                      [ 0.03616749,  0.03662371,  0.01864403, ..., -0.05116637,\n",
       "                        0.0012651 , -0.02736761]], dtype=float32)),\n",
       "              ('encoder.actor_encoder.net.mlp.2.bias',\n",
       "               array([-0.05483877, -0.01086856, -0.03207282, -0.0552389 ,  0.01882464,\n",
       "                      -0.01450511, -0.01380897,  0.05619115,  0.05519126,  0.04282037,\n",
       "                       0.03509031,  0.03354106, -0.04671952, -0.06044195,  0.01564992,\n",
       "                      -0.04305147,  0.03614965,  0.0415917 , -0.0038927 , -0.004899  ,\n",
       "                      -0.05780224, -0.0533485 ,  0.03472023,  0.00340761, -0.02871916,\n",
       "                      -0.00972235, -0.02855749,  0.00833875,  0.01581182,  0.0402784 ,\n",
       "                      -0.04621128,  0.01321653,  0.00713679,  0.01711406,  0.05675553,\n",
       "                       0.01896555,  0.02573644, -0.02135059,  0.05447394,  0.00154029,\n",
       "                      -0.01055746, -0.05033091, -0.01253972, -0.03773767,  0.05537674,\n",
       "                      -0.01933166,  0.01061918, -0.03585333, -0.05046893,  0.02679718,\n",
       "                      -0.02248682, -0.00390609, -0.04337259, -0.05562791,  0.05375476,\n",
       "                       0.02637898, -0.00141916, -0.04103174,  0.03685857, -0.00492857,\n",
       "                       0.04252353, -0.05218405,  0.05588352,  0.0523124 ,  0.03077457,\n",
       "                       0.00319422, -0.01491351,  0.03097296,  0.02350119,  0.03280596,\n",
       "                      -0.01163071, -0.00149412,  0.00887439, -0.00645337,  0.00935113,\n",
       "                      -0.0297704 , -0.05755456, -0.03402695,  0.01241969, -0.01056965,\n",
       "                      -0.03863885, -0.03198112, -0.04319225,  0.01598708, -0.0573564 ,\n",
       "                      -0.03952409, -0.04335008,  0.03233831, -0.00139181,  0.03103629,\n",
       "                      -0.00994296,  0.00917005,  0.01976459, -0.03961627, -0.00158481,\n",
       "                       0.02140968,  0.01065383,  0.05452738,  0.043435  ,  0.04814623,\n",
       "                       0.06058702,  0.01445234, -0.01643939,  0.02355924, -0.04464138,\n",
       "                       0.02946414, -0.00680022, -0.031203  , -0.0524231 , -0.02359964,\n",
       "                       0.02479652, -0.04862949,  0.00586469,  0.06141276,  0.04868831,\n",
       "                      -0.0549775 , -0.0441525 , -0.03484207,  0.0170425 ,  0.04560956,\n",
       "                      -0.00483965,  0.02991773, -0.04983599, -0.03013872,  0.0200049 ,\n",
       "                      -0.01100041,  0.00302176,  0.06180231,  0.0606821 ,  0.00774136,\n",
       "                      -0.06181286, -0.05106541, -0.03253734,  0.00076006,  0.04528134,\n",
       "                       0.04536685, -0.01956477, -0.05361608, -0.04194389, -0.00057021,\n",
       "                       0.04830877, -0.02192818,  0.04167057,  0.05980831,  0.02535572,\n",
       "                      -0.0182219 ,  0.01780368,  0.01645698, -0.05084711, -0.04098175,\n",
       "                       0.05212468,  0.0359209 , -0.02741921,  0.01846322,  0.03562854,\n",
       "                       0.0060561 ,  0.02918175,  0.01737678, -0.0259941 ,  0.05300344,\n",
       "                       0.04106186,  0.06206771, -0.01854938, -0.03596983,  0.01116497,\n",
       "                      -0.02982195,  0.00608473, -0.04943457,  0.06167192,  0.03046296,\n",
       "                      -0.05509935, -0.0050344 , -0.04343363, -0.0058882 ,  0.0593544 ,\n",
       "                       0.04574297, -0.04399016,  0.02661696,  0.01928407, -0.05388333,\n",
       "                      -0.01688489, -0.00736087, -0.05035202, -0.00361029,  0.02662237,\n",
       "                       0.00073697,  0.00108735, -0.02679612,  0.02167954, -0.00132145,\n",
       "                      -0.00935175, -0.04849719, -0.05376819,  0.00210511, -0.05536161,\n",
       "                       0.06031001, -0.00180104,  0.04166397, -0.04506802, -0.02179777,\n",
       "                      -0.03709916,  0.042459  , -0.00148279,  0.02729861,  0.03835669,\n",
       "                       0.01963177,  0.02144207,  0.03831054, -0.05218957, -0.061122  ,\n",
       "                      -0.02443933, -0.05227674, -0.03654977, -0.0468559 ,  0.05019763,\n",
       "                       0.01030625,  0.03729323, -0.04271524,  0.02058569, -0.04590709,\n",
       "                       0.05823355, -0.03842904, -0.00373325,  0.00221756,  0.05255467,\n",
       "                       0.05940501,  0.01632934, -0.05693398,  0.05085645, -0.05413631,\n",
       "                      -0.04562555, -0.00967639,  0.01083607,  0.00462099,  0.05404604,\n",
       "                      -0.05625762, -0.03727283, -0.01790421,  0.02352455, -0.04932119,\n",
       "                       0.04756055,  0.0075471 ,  0.0459665 , -0.01867156, -0.00710109,\n",
       "                      -0.05484503, -0.05243585,  0.01341348, -0.04779353, -0.06238955,\n",
       "                       0.038638  , -0.02603606,  0.04313762,  0.04631102, -0.03641137,\n",
       "                      -0.01792917], dtype=float32)),\n",
       "              ('pi.log_std_clip_param_const', array([20.], dtype=float32)),\n",
       "              ('pi.net.mlp.0.weight',\n",
       "               array([[-0.01313671, -0.00173075,  0.04167236,  0.00575058,  0.04594432,\n",
       "                       -0.0103353 , -0.00224185,  0.01999455, -0.05939083, -0.03014329,\n",
       "                        0.02038279, -0.03045558,  0.02740541, -0.05398218, -0.0066882 ,\n",
       "                       -0.04798061,  0.01209146,  0.00263563,  0.0266151 ,  0.00823582,\n",
       "                        0.0170964 ,  0.04946152,  0.05078118,  0.04242834,  0.04692595,\n",
       "                       -0.02865938,  0.04562116,  0.06243119, -0.04143283,  0.00983918,\n",
       "                       -0.05308914, -0.01373731,  0.02157784,  0.04832786,  0.02550694,\n",
       "                       -0.04610106,  0.04206516,  0.05700564,  0.04209153, -0.01511254,\n",
       "                        0.0103054 , -0.0468247 ,  0.05531837,  0.00011243,  0.008506  ,\n",
       "                        0.00765128, -0.01526   ,  0.01157278,  0.02141973,  0.02813394,\n",
       "                       -0.02252876,  0.03739684, -0.04128118, -0.02670424, -0.0328301 ,\n",
       "                        0.01437586, -0.01368906, -0.00347359,  0.03529309,  0.04651532,\n",
       "                       -0.0510945 , -0.03307255, -0.01154967, -0.0464215 ,  0.02322236,\n",
       "                        0.02310637,  0.04682424,  0.01760754,  0.02175149,  0.00428822,\n",
       "                       -0.01677097, -0.05158218,  0.04999451, -0.01202732, -0.014318  ,\n",
       "                       -0.00882027,  0.0219216 , -0.03830662, -0.03718287, -0.0099023 ,\n",
       "                        0.01116969,  0.04841509,  0.04649531,  0.05671351, -0.00169657,\n",
       "                        0.05335541,  0.03423308, -0.0426086 ,  0.004724  ,  0.04073806,\n",
       "                       -0.02228359, -0.00732937, -0.01798267, -0.05716844, -0.00562861,\n",
       "                        0.04979683,  0.00465437, -0.04759078,  0.03267837, -0.02506749,\n",
       "                       -0.03884327,  0.04107001, -0.01481468,  0.04354573,  0.02086639,\n",
       "                        0.02365147,  0.02765702, -0.006198  , -0.00747155, -0.05953271,\n",
       "                        0.0595983 ,  0.01615798, -0.01235236, -0.0159465 , -0.02539399,\n",
       "                       -0.03083641,  0.00859643, -0.05217274,  0.01111576, -0.01217937,\n",
       "                       -0.02365668,  0.05117048, -0.06019244, -0.05971586,  0.03666333,\n",
       "                        0.02221389,  0.00842257, -0.02503069, -0.03225253, -0.05196583,\n",
       "                        0.04490815, -0.04820148, -0.04307986,  0.00228114, -0.00178972,\n",
       "                       -0.00287166, -0.05981685, -0.03170202,  0.02397207,  0.02933534,\n",
       "                       -0.04444902,  0.04366769,  0.05520859,  0.00274657,  0.01108017,\n",
       "                       -0.042826  ,  0.04730872,  0.00878555, -0.03733391,  0.00243246,\n",
       "                        0.04727523, -0.04004619, -0.02240922, -0.02858298, -0.03563883,\n",
       "                        0.00263787,  0.04021375,  0.00302777,  0.00305723,  0.02089957,\n",
       "                       -0.06119261, -0.05736507, -0.01306706,  0.00637399,  0.02837564,\n",
       "                        0.04017717,  0.04416613,  0.03681602, -0.04259226,  0.03005847,\n",
       "                        0.01231644, -0.05380039,  0.05157653,  0.01721138,  0.00918559,\n",
       "                       -0.00488909,  0.01849586, -0.03477903, -0.03133502, -0.00646163,\n",
       "                        0.04769563,  0.03764308, -0.02803403,  0.00639565,  0.02501041,\n",
       "                       -0.05828516,  0.01711814, -0.03926115,  0.03584143, -0.01973251,\n",
       "                       -0.02866747, -0.05991889, -0.03124879, -0.01271755, -0.02110961,\n",
       "                       -0.053663  , -0.03612147,  0.04159606,  0.01346264,  0.03979391,\n",
       "                        0.04219094, -0.05944049,  0.05424672, -0.02876265,  0.01464498,\n",
       "                       -0.00155015,  0.04252493,  0.06166948,  0.04501007, -0.03145634,\n",
       "                        0.05738986,  0.0268788 ,  0.01203227, -0.02544892, -0.01781096,\n",
       "                        0.03170944,  0.05819654, -0.03001004,  0.06216743, -0.05042212,\n",
       "                        0.05312058, -0.04738064, -0.0166346 ,  0.06016381, -0.00801235,\n",
       "                       -0.05082443, -0.01290483, -0.00210752, -0.03113911,  0.01442955,\n",
       "                        0.01213247, -0.06193651, -0.06084687,  0.03197943, -0.00660754,\n",
       "                        0.04971921, -0.03238543,  0.02313472, -0.04505336,  0.04033609,\n",
       "                       -0.03816813,  0.03772196,  0.03979667,  0.00439757, -0.02776327,\n",
       "                       -0.02946671, -0.05176897,  0.05782506,  0.01346825, -0.05134817,\n",
       "                        0.0456559 , -0.02067457,  0.04440528, -0.01511118, -0.01230736,\n",
       "                       -0.02351792],\n",
       "                      [ 0.01949818,  0.0398969 , -0.03242809, -0.05052533, -0.03656701,\n",
       "                        0.03732007,  0.02779944, -0.0037123 , -0.05525424, -0.0342093 ,\n",
       "                        0.01767053, -0.04596609, -0.01509397, -0.03473909, -0.0185442 ,\n",
       "                       -0.04429118,  0.03132825,  0.05942085, -0.03178602,  0.00886004,\n",
       "                        0.06199326, -0.05198236,  0.04893436, -0.01360759, -0.0130163 ,\n",
       "                       -0.06216436, -0.05426211, -0.02136708, -0.03460015,  0.03853048,\n",
       "                       -0.05114377, -0.02658971,  0.04226289,  0.02568338, -0.05930212,\n",
       "                        0.05589007,  0.03016873, -0.06103218,  0.02360252, -0.04613745,\n",
       "                        0.01478528,  0.02159323, -0.01338396,  0.00572348,  0.05043457,\n",
       "                       -0.02644963,  0.00660767,  0.04075736, -0.00648788, -0.04134962,\n",
       "                        0.03616478,  0.03211886, -0.03155123,  0.03663921,  0.05897919,\n",
       "                        0.0344949 ,  0.0308792 , -0.02531863,  0.01215278,  0.04409729,\n",
       "                       -0.05928946,  0.01089086, -0.01731156,  0.00403932, -0.04633197,\n",
       "                       -0.03007106,  0.05195288, -0.04597612,  0.0003755 , -0.00247356,\n",
       "                       -0.05027652,  0.05578275, -0.00426263, -0.01710191,  0.00880483,\n",
       "                        0.04121914,  0.05194912, -0.04424093, -0.00276189,  0.03559946,\n",
       "                       -0.05263678,  0.01658513,  0.03650089,  0.04713741, -0.04107349,\n",
       "                       -0.05577666, -0.04382362,  0.02804866,  0.01116478,  0.0425243 ,\n",
       "                        0.04645891,  0.04630507,  0.03079243, -0.04402997, -0.02206876,\n",
       "                        0.01579694, -0.0237233 , -0.01103821,  0.04993603,  0.00521007,\n",
       "                       -0.03059959, -0.04783435, -0.0290435 , -0.05480897, -0.05900099,\n",
       "                       -0.06229038, -0.04005285,  0.0599615 ,  0.01589551, -0.01492995,\n",
       "                        0.0586545 , -0.05070681,  0.06015033, -0.01627359,  0.01404962,\n",
       "                       -0.04692873,  0.00910296,  0.03336567,  0.00766423,  0.02254967,\n",
       "                       -0.02000728, -0.05308246,  0.03376099, -0.0091566 , -0.04433458,\n",
       "                       -0.05111946, -0.04624216,  0.05078097,  0.02339116,  0.00523171,\n",
       "                       -0.05330604,  0.01917763,  0.01429494, -0.06165884, -0.03934342,\n",
       "                       -0.02155685, -0.0053166 ,  0.05595464, -0.00059628,  0.03987124,\n",
       "                        0.02924772,  0.05395145,  0.02677169,  0.00031842,  0.05028171,\n",
       "                        0.06239859,  0.01146857, -0.05917674, -0.04537854,  0.00864206,\n",
       "                       -0.03143852, -0.00038201,  0.01063187,  0.03560904,  0.04076108,\n",
       "                        0.01437438, -0.0053601 , -0.04875275, -0.04126211, -0.00962576,\n",
       "                       -0.03952285,  0.02164524,  0.00428326, -0.01472887, -0.01192643,\n",
       "                       -0.03661261,  0.03702688,  0.01490717, -0.04080921,  0.02416848,\n",
       "                        0.03922965,  0.05206028,  0.00948313,  0.01319379,  0.06097715,\n",
       "                        0.03275237,  0.03182915, -0.03807483, -0.05893101, -0.00905039,\n",
       "                        0.0135575 , -0.0400764 , -0.03752891, -0.01637033,  0.01453601,\n",
       "                       -0.0597759 ,  0.04734781,  0.04411278, -0.03574504,  0.04127835,\n",
       "                       -0.05046581,  0.00377101, -0.01150955,  0.03446755,  0.01713137,\n",
       "                       -0.05522966, -0.04899348,  0.03628014, -0.00310334, -0.0067618 ,\n",
       "                       -0.02642173, -0.02165736,  0.02379757,  0.00998969,  0.0195431 ,\n",
       "                        0.03804238,  0.05275122, -0.01770315, -0.05527505, -0.00929274,\n",
       "                       -0.03526432, -0.0605516 ,  0.0321383 ,  0.05237477,  0.00307608,\n",
       "                       -0.03332259, -0.01933326, -0.01112966,  0.05464538, -0.00873809,\n",
       "                        0.03118315,  0.04765485, -0.0527145 ,  0.0290682 ,  0.00433207,\n",
       "                        0.00722915, -0.02725794,  0.026506  ,  0.02612773,  0.04341318,\n",
       "                        0.03199492, -0.03975249,  0.01735438, -0.01804987, -0.05817404,\n",
       "                        0.04095325, -0.03172841, -0.02755065,  0.03212278,  0.03638732,\n",
       "                       -0.04925679,  0.01047102,  0.02932756, -0.03436913,  0.0430408 ,\n",
       "                        0.04257266,  0.05655405, -0.04755934,  0.04568511,  0.01169502,\n",
       "                       -0.00755979, -0.06015145,  0.02758955,  0.04890035, -0.0212636 ,\n",
       "                       -0.03758594]], dtype=float32)),\n",
       "              ('pi.net.mlp.0.bias',\n",
       "               array([0.0286466 , 0.04479951], dtype=float32)),\n",
       "              ('vf.log_std_clip_param_const', array([20.], dtype=float32)),\n",
       "              ('vf.net.mlp.0.weight',\n",
       "               array([[-0.05734554,  0.039763  , -0.02609766,  0.03290825, -0.02943325,\n",
       "                        0.00525767,  0.03586349, -0.05233687, -0.05162664, -0.04950567,\n",
       "                       -0.03524912,  0.01559496,  0.06167836, -0.01203049, -0.05874869,\n",
       "                        0.05721776, -0.01276902, -0.02897685,  0.02496023,  0.00356279,\n",
       "                        0.01177818, -0.0292305 , -0.00296313,  0.02827802,  0.00225517,\n",
       "                       -0.02973831,  0.05255034, -0.01428294, -0.0130914 , -0.02564789,\n",
       "                        0.04105298,  0.04238445, -0.03222838,  0.00903114, -0.02300785,\n",
       "                       -0.01691474, -0.05224957,  0.02130514,  0.01027128,  0.01175401,\n",
       "                        0.01002912, -0.0514333 ,  0.02242158,  0.0338067 ,  0.05638821,\n",
       "                        0.01975119, -0.05721954, -0.04029767, -0.04985628, -0.04555862,\n",
       "                       -0.02486588, -0.05088713, -0.00915529, -0.03416287,  0.03160309,\n",
       "                       -0.02704623, -0.05835471, -0.00883695,  0.02407525,  0.03483889,\n",
       "                        0.02680975, -0.04486547,  0.05148072,  0.04036103,  0.03044851,\n",
       "                       -0.01804172, -0.02033062, -0.04544982,  0.04107455, -0.01793619,\n",
       "                       -0.05692551, -0.06123634,  0.05383865,  0.0149643 ,  0.03749064,\n",
       "                       -0.00649278,  0.02470005, -0.02011434, -0.01705045,  0.02188642,\n",
       "                        0.02252723,  0.04564063, -0.00375132, -0.03082296,  0.00035947,\n",
       "                       -0.05754294, -0.04185542, -0.04403578,  0.0138597 , -0.01810636,\n",
       "                        0.03881984,  0.05083408,  0.03148013,  0.01294105,  0.03276066,\n",
       "                       -0.00059133, -0.00572962,  0.01904986, -0.01222689, -0.02248952,\n",
       "                        0.01507754, -0.02139331,  0.00123425, -0.04079128,  0.01804969,\n",
       "                       -0.06008362, -0.03975254, -0.0295576 ,  0.03302825,  0.0067986 ,\n",
       "                       -0.00132464,  0.03434535,  0.02143077,  0.05419314,  0.03024659,\n",
       "                       -0.01544922, -0.00695625, -0.0094828 , -0.00389918,  0.02298341,\n",
       "                        0.05970425, -0.01181474, -0.02418526, -0.02418872, -0.05229013,\n",
       "                        0.04080833, -0.01625654, -0.00958513, -0.05104338,  0.04300158,\n",
       "                       -0.04599597, -0.03521051, -0.05579017, -0.02149758, -0.05253784,\n",
       "                        0.00485785, -0.05161431,  0.00273647, -0.03724583,  0.02788797,\n",
       "                       -0.02994092,  0.05823266,  0.01235566,  0.00625806,  0.0587334 ,\n",
       "                       -0.01141969,  0.00625995,  0.0353191 , -0.02616085, -0.05209679,\n",
       "                        0.02712348,  0.00388511,  0.0581753 ,  0.05884127, -0.01504923,\n",
       "                       -0.00069584, -0.05181163, -0.04465256, -0.02448689, -0.01890087,\n",
       "                       -0.00614996, -0.01869512, -0.005314  , -0.01576173, -0.00187094,\n",
       "                        0.02804864,  0.01958539,  0.04355184, -0.0396023 , -0.02678093,\n",
       "                       -0.04120348,  0.00720385, -0.05981238,  0.01842639, -0.05297507,\n",
       "                       -0.02633324, -0.03918999,  0.00204991,  0.0425854 ,  0.01800918,\n",
       "                        0.00557593, -0.04763126, -0.02955464,  0.03417265, -0.04536851,\n",
       "                        0.04798348, -0.00506595,  0.01341461,  0.02900749, -0.04305829,\n",
       "                       -0.03360166,  0.05654901,  0.03964067,  0.03946629, -0.02923225,\n",
       "                        0.01216384, -0.00661533, -0.04639766, -0.03127697, -0.02724061,\n",
       "                        0.01897417, -0.05274494, -0.02949508,  0.02160902,  0.0309856 ,\n",
       "                        0.04881833, -0.04179701,  0.05134843,  0.03434717, -0.0432926 ,\n",
       "                        0.04990337,  0.03454584,  0.01375949, -0.0562267 ,  0.02343552,\n",
       "                        0.04500997, -0.00679623,  0.04720082,  0.00799509,  0.00955548,\n",
       "                       -0.05461737, -0.03377372,  0.04876229, -0.05029328,  0.00395588,\n",
       "                       -0.060197  , -0.02397896,  0.00724392,  0.04721482, -0.04733811,\n",
       "                        0.01201128, -0.03468361,  0.04837886, -0.02216166, -0.00090055,\n",
       "                        0.01432346,  0.00991163, -0.01485561,  0.0204974 , -0.02133087,\n",
       "                        0.05061889, -0.04266048,  0.03542779,  0.00300261, -0.0407915 ,\n",
       "                       -0.01570041, -0.00229996,  0.05339552,  0.05396073, -0.00643305,\n",
       "                       -0.03947031, -0.02444985, -0.06105637, -0.00139159,  0.01998796,\n",
       "                        0.04847846]], dtype=float32)),\n",
       "              ('vf.net.mlp.0.bias', array([-0.0319372], dtype=float32))]),\n",
       " OrderedDict([('encoder.actor_encoder.net.mlp.0.weight',\n",
       "               array([[ 0.48074734, -0.27554852,  0.3861252 ,  0.04286963],\n",
       "                      [-0.24321026,  0.10605699, -0.31143463,  0.45463032],\n",
       "                      [-0.2310844 ,  0.13257575,  0.40450126,  0.40058738],\n",
       "                      ...,\n",
       "                      [-0.39735532, -0.4630162 , -0.48954093, -0.20519793],\n",
       "                      [-0.01912349,  0.17111182, -0.12658882, -0.05784327],\n",
       "                      [ 0.3242514 ,  0.21938777, -0.07781363,  0.06862128]],\n",
       "                     dtype=float32)),\n",
       "              ('encoder.actor_encoder.net.mlp.0.bias',\n",
       "               array([-0.42349046, -0.09525579,  0.19313997,  0.24745929,  0.48743117,\n",
       "                      -0.44139707, -0.24722278, -0.11840814, -0.07465196, -0.15854478,\n",
       "                      -0.25044543, -0.4148047 , -0.25724047,  0.15085763,  0.44752496,\n",
       "                      -0.3305989 ,  0.00122595,  0.0494591 , -0.45621443,  0.44512528,\n",
       "                      -0.08727521,  0.4556445 , -0.18121558,  0.26333153,  0.49070042,\n",
       "                      -0.11704606,  0.23079914, -0.3037504 , -0.00058883, -0.22521228,\n",
       "                      -0.3618093 , -0.27271616,  0.3458839 , -0.06827897,  0.3111347 ,\n",
       "                      -0.13284886,  0.29187316, -0.3529771 , -0.25299948, -0.04151767,\n",
       "                       0.34041613,  0.3062135 , -0.00503838,  0.47687757,  0.03452969,\n",
       "                       0.38654178,  0.06352353, -0.15762585,  0.15518814, -0.25545675,\n",
       "                       0.39882457, -0.04925185,  0.20924348,  0.21864372, -0.35129815,\n",
       "                       0.19893348,  0.32212925,  0.25336236,  0.08955634,  0.09379625,\n",
       "                       0.26815963,  0.13536948,  0.2600597 ,  0.22009802, -0.48384982,\n",
       "                       0.06317121,  0.4788425 ,  0.3695342 , -0.16281015,  0.4809698 ,\n",
       "                       0.35959852,  0.08468854, -0.43470466, -0.03108668, -0.1767999 ,\n",
       "                       0.26140672, -0.05193913, -0.35291213, -0.3534943 ,  0.05708683,\n",
       "                      -0.42946786, -0.26655805, -0.1463862 , -0.34849405,  0.1520145 ,\n",
       "                      -0.46492732, -0.23699778, -0.38120943,  0.18881488, -0.47822875,\n",
       "                      -0.13067418,  0.42043787, -0.481502  ,  0.3610897 , -0.13513154,\n",
       "                       0.03504515,  0.3005873 , -0.42850834,  0.43186653, -0.44459164,\n",
       "                       0.06889832, -0.37436235, -0.26397288, -0.48741382, -0.35603803,\n",
       "                      -0.0277853 , -0.15849668,  0.46113133,  0.3969807 , -0.4706434 ,\n",
       "                       0.06859666, -0.30697703, -0.33360374,  0.2497344 ,  0.36564487,\n",
       "                       0.40830958,  0.24911523,  0.4905694 ,  0.4989558 ,  0.01195931,\n",
       "                       0.18655133, -0.09299272,  0.12612695,  0.47901607,  0.46042448,\n",
       "                       0.22366095, -0.21398783,  0.15625513, -0.46728235,  0.31943464,\n",
       "                       0.05910146, -0.11065191,  0.15188324,  0.11132276,  0.12232471,\n",
       "                      -0.38283664, -0.32266313, -0.03145319, -0.25123394, -0.45093697,\n",
       "                      -0.20454866,  0.20811397,  0.24444902,  0.10563165, -0.449444  ,\n",
       "                       0.27179945,  0.12521243, -0.36974007,  0.12053192, -0.08887333,\n",
       "                      -0.00237858, -0.46484983,  0.30467528,  0.23171341, -0.48680317,\n",
       "                      -0.34509885, -0.11753583,  0.00120604,  0.32154357, -0.20469075,\n",
       "                       0.18866932,  0.14718646,  0.0734629 ,  0.3212204 , -0.05799854,\n",
       "                       0.00121045,  0.12572324,  0.37709963, -0.28302222,  0.32761496,\n",
       "                       0.34815592, -0.43725258,  0.16602552, -0.42888993, -0.1773951 ,\n",
       "                      -0.07594234,  0.12367356, -0.07739776,  0.0563761 , -0.076617  ,\n",
       "                      -0.29747128,  0.26988065, -0.33076668,  0.08757293,  0.2334866 ,\n",
       "                       0.01382673, -0.2238949 ,  0.04937357, -0.49435169, -0.10457748,\n",
       "                      -0.04843348, -0.22782314,  0.2776119 , -0.4167602 , -0.07826817,\n",
       "                       0.27114475, -0.29941088, -0.4791932 , -0.01752067, -0.36992955,\n",
       "                       0.11926144, -0.3889057 , -0.45995533,  0.36747444, -0.261055  ,\n",
       "                      -0.03951073,  0.0571503 ,  0.36328572, -0.08340716,  0.09900635,\n",
       "                      -0.2431348 ,  0.12079334, -0.4723543 ,  0.34179312,  0.38352585,\n",
       "                       0.19006807, -0.1895814 , -0.44292855,  0.28780967, -0.02999926,\n",
       "                       0.0650602 , -0.2106415 , -0.01179242,  0.23550338,  0.36438674,\n",
       "                       0.32621413, -0.12410241, -0.0442239 ,  0.06463236,  0.23559386,\n",
       "                       0.1964395 ,  0.34015417, -0.07768077, -0.00849748, -0.2581331 ,\n",
       "                       0.1665889 , -0.26239818, -0.33595294, -0.02665967, -0.03963792,\n",
       "                      -0.06419784,  0.46261388, -0.15051544,  0.39061642, -0.09580386,\n",
       "                       0.321258  ,  0.3284443 ,  0.1394993 ,  0.22187614, -0.04445052,\n",
       "                       0.23289758, -0.43271238,  0.10471064, -0.11713976, -0.1672275 ,\n",
       "                       0.14586085], dtype=float32)),\n",
       "              ('encoder.actor_encoder.net.mlp.2.weight',\n",
       "               array([[ 0.0080853 ,  0.0323079 , -0.01465252, ..., -0.06127897,\n",
       "                       -0.00958588, -0.00554363],\n",
       "                      [ 0.01876203,  0.02576252, -0.03728223, ...,  0.05412225,\n",
       "                        0.03903201, -0.01636995],\n",
       "                      [-0.0550908 ,  0.04494536, -0.02781003, ..., -0.00592026,\n",
       "                        0.00825797,  0.01999169],\n",
       "                      ...,\n",
       "                      [-0.05552784,  0.06104954,  0.0268489 , ...,  0.04719555,\n",
       "                       -0.04467792,  0.05105264],\n",
       "                      [ 0.03538422,  0.01028964, -0.03888112, ...,  0.0447339 ,\n",
       "                        0.02617799,  0.05129713],\n",
       "                      [ 0.03616749,  0.03662371,  0.01864403, ..., -0.05116637,\n",
       "                        0.0012651 , -0.02736761]], dtype=float32)),\n",
       "              ('encoder.actor_encoder.net.mlp.2.bias',\n",
       "               array([-0.05483877, -0.01086856, -0.03207282, -0.0552389 ,  0.01882464,\n",
       "                      -0.01450511, -0.01380897,  0.05619115,  0.05519126,  0.04282037,\n",
       "                       0.03509031,  0.03354106, -0.04671952, -0.06044195,  0.01564992,\n",
       "                      -0.04305147,  0.03614965,  0.0415917 , -0.0038927 , -0.004899  ,\n",
       "                      -0.05780224, -0.0533485 ,  0.03472023,  0.00340761, -0.02871916,\n",
       "                      -0.00972235, -0.02855749,  0.00833875,  0.01581182,  0.0402784 ,\n",
       "                      -0.04621128,  0.01321653,  0.00713679,  0.01711406,  0.05675553,\n",
       "                       0.01896555,  0.02573644, -0.02135059,  0.05447394,  0.00154029,\n",
       "                      -0.01055746, -0.05033091, -0.01253972, -0.03773767,  0.05537674,\n",
       "                      -0.01933166,  0.01061918, -0.03585333, -0.05046893,  0.02679718,\n",
       "                      -0.02248682, -0.00390609, -0.04337259, -0.05562791,  0.05375476,\n",
       "                       0.02637898, -0.00141916, -0.04103174,  0.03685857, -0.00492857,\n",
       "                       0.04252353, -0.05218405,  0.05588352,  0.0523124 ,  0.03077457,\n",
       "                       0.00319422, -0.01491351,  0.03097296,  0.02350119,  0.03280596,\n",
       "                      -0.01163071, -0.00149412,  0.00887439, -0.00645337,  0.00935113,\n",
       "                      -0.0297704 , -0.05755456, -0.03402695,  0.01241969, -0.01056965,\n",
       "                      -0.03863885, -0.03198112, -0.04319225,  0.01598708, -0.0573564 ,\n",
       "                      -0.03952409, -0.04335008,  0.03233831, -0.00139181,  0.03103629,\n",
       "                      -0.00994296,  0.00917005,  0.01976459, -0.03961627, -0.00158481,\n",
       "                       0.02140968,  0.01065383,  0.05452738,  0.043435  ,  0.04814623,\n",
       "                       0.06058702,  0.01445234, -0.01643939,  0.02355924, -0.04464138,\n",
       "                       0.02946414, -0.00680022, -0.031203  , -0.0524231 , -0.02359964,\n",
       "                       0.02479652, -0.04862949,  0.00586469,  0.06141276,  0.04868831,\n",
       "                      -0.0549775 , -0.0441525 , -0.03484207,  0.0170425 ,  0.04560956,\n",
       "                      -0.00483965,  0.02991773, -0.04983599, -0.03013872,  0.0200049 ,\n",
       "                      -0.01100041,  0.00302176,  0.06180231,  0.0606821 ,  0.00774136,\n",
       "                      -0.06181286, -0.05106541, -0.03253734,  0.00076006,  0.04528134,\n",
       "                       0.04536685, -0.01956477, -0.05361608, -0.04194389, -0.00057021,\n",
       "                       0.04830877, -0.02192818,  0.04167057,  0.05980831,  0.02535572,\n",
       "                      -0.0182219 ,  0.01780368,  0.01645698, -0.05084711, -0.04098175,\n",
       "                       0.05212468,  0.0359209 , -0.02741921,  0.01846322,  0.03562854,\n",
       "                       0.0060561 ,  0.02918175,  0.01737678, -0.0259941 ,  0.05300344,\n",
       "                       0.04106186,  0.06206771, -0.01854938, -0.03596983,  0.01116497,\n",
       "                      -0.02982195,  0.00608473, -0.04943457,  0.06167192,  0.03046296,\n",
       "                      -0.05509935, -0.0050344 , -0.04343363, -0.0058882 ,  0.0593544 ,\n",
       "                       0.04574297, -0.04399016,  0.02661696,  0.01928407, -0.05388333,\n",
       "                      -0.01688489, -0.00736087, -0.05035202, -0.00361029,  0.02662237,\n",
       "                       0.00073697,  0.00108735, -0.02679612,  0.02167954, -0.00132145,\n",
       "                      -0.00935175, -0.04849719, -0.05376819,  0.00210511, -0.05536161,\n",
       "                       0.06031001, -0.00180104,  0.04166397, -0.04506802, -0.02179777,\n",
       "                      -0.03709916,  0.042459  , -0.00148279,  0.02729861,  0.03835669,\n",
       "                       0.01963177,  0.02144207,  0.03831054, -0.05218957, -0.061122  ,\n",
       "                      -0.02443933, -0.05227674, -0.03654977, -0.0468559 ,  0.05019763,\n",
       "                       0.01030625,  0.03729323, -0.04271524,  0.02058569, -0.04590709,\n",
       "                       0.05823355, -0.03842904, -0.00373325,  0.00221756,  0.05255467,\n",
       "                       0.05940501,  0.01632934, -0.05693398,  0.05085645, -0.05413631,\n",
       "                      -0.04562555, -0.00967639,  0.01083607,  0.00462099,  0.05404604,\n",
       "                      -0.05625762, -0.03727283, -0.01790421,  0.02352455, -0.04932119,\n",
       "                       0.04756055,  0.0075471 ,  0.0459665 , -0.01867156, -0.00710109,\n",
       "                      -0.05484503, -0.05243585,  0.01341348, -0.04779353, -0.06238955,\n",
       "                       0.038638  , -0.02603606,  0.04313762,  0.04631102, -0.03641137,\n",
       "                      -0.01792917], dtype=float32)),\n",
       "              ('pi.log_std_clip_param_const', array([20.], dtype=float32)),\n",
       "              ('pi.net.mlp.0.weight',\n",
       "               array([[-0.01313671, -0.00173075,  0.04167236,  0.00575058,  0.04594432,\n",
       "                       -0.0103353 , -0.00224185,  0.01999455, -0.05939083, -0.03014329,\n",
       "                        0.02038279, -0.03045558,  0.02740541, -0.05398218, -0.0066882 ,\n",
       "                       -0.04798061,  0.01209146,  0.00263563,  0.0266151 ,  0.00823582,\n",
       "                        0.0170964 ,  0.04946152,  0.05078118,  0.04242834,  0.04692595,\n",
       "                       -0.02865938,  0.04562116,  0.06243119, -0.04143283,  0.00983918,\n",
       "                       -0.05308914, -0.01373731,  0.02157784,  0.04832786,  0.02550694,\n",
       "                       -0.04610106,  0.04206516,  0.05700564,  0.04209153, -0.01511254,\n",
       "                        0.0103054 , -0.0468247 ,  0.05531837,  0.00011243,  0.008506  ,\n",
       "                        0.00765128, -0.01526   ,  0.01157278,  0.02141973,  0.02813394,\n",
       "                       -0.02252876,  0.03739684, -0.04128118, -0.02670424, -0.0328301 ,\n",
       "                        0.01437586, -0.01368906, -0.00347359,  0.03529309,  0.04651532,\n",
       "                       -0.0510945 , -0.03307255, -0.01154967, -0.0464215 ,  0.02322236,\n",
       "                        0.02310637,  0.04682424,  0.01760754,  0.02175149,  0.00428822,\n",
       "                       -0.01677097, -0.05158218,  0.04999451, -0.01202732, -0.014318  ,\n",
       "                       -0.00882027,  0.0219216 , -0.03830662, -0.03718287, -0.0099023 ,\n",
       "                        0.01116969,  0.04841509,  0.04649531,  0.05671351, -0.00169657,\n",
       "                        0.05335541,  0.03423308, -0.0426086 ,  0.004724  ,  0.04073806,\n",
       "                       -0.02228359, -0.00732937, -0.01798267, -0.05716844, -0.00562861,\n",
       "                        0.04979683,  0.00465437, -0.04759078,  0.03267837, -0.02506749,\n",
       "                       -0.03884327,  0.04107001, -0.01481468,  0.04354573,  0.02086639,\n",
       "                        0.02365147,  0.02765702, -0.006198  , -0.00747155, -0.05953271,\n",
       "                        0.0595983 ,  0.01615798, -0.01235236, -0.0159465 , -0.02539399,\n",
       "                       -0.03083641,  0.00859643, -0.05217274,  0.01111576, -0.01217937,\n",
       "                       -0.02365668,  0.05117048, -0.06019244, -0.05971586,  0.03666333,\n",
       "                        0.02221389,  0.00842257, -0.02503069, -0.03225253, -0.05196583,\n",
       "                        0.04490815, -0.04820148, -0.04307986,  0.00228114, -0.00178972,\n",
       "                       -0.00287166, -0.05981685, -0.03170202,  0.02397207,  0.02933534,\n",
       "                       -0.04444902,  0.04366769,  0.05520859,  0.00274657,  0.01108017,\n",
       "                       -0.042826  ,  0.04730872,  0.00878555, -0.03733391,  0.00243246,\n",
       "                        0.04727523, -0.04004619, -0.02240922, -0.02858298, -0.03563883,\n",
       "                        0.00263787,  0.04021375,  0.00302777,  0.00305723,  0.02089957,\n",
       "                       -0.06119261, -0.05736507, -0.01306706,  0.00637399,  0.02837564,\n",
       "                        0.04017717,  0.04416613,  0.03681602, -0.04259226,  0.03005847,\n",
       "                        0.01231644, -0.05380039,  0.05157653,  0.01721138,  0.00918559,\n",
       "                       -0.00488909,  0.01849586, -0.03477903, -0.03133502, -0.00646163,\n",
       "                        0.04769563,  0.03764308, -0.02803403,  0.00639565,  0.02501041,\n",
       "                       -0.05828516,  0.01711814, -0.03926115,  0.03584143, -0.01973251,\n",
       "                       -0.02866747, -0.05991889, -0.03124879, -0.01271755, -0.02110961,\n",
       "                       -0.053663  , -0.03612147,  0.04159606,  0.01346264,  0.03979391,\n",
       "                        0.04219094, -0.05944049,  0.05424672, -0.02876265,  0.01464498,\n",
       "                       -0.00155015,  0.04252493,  0.06166948,  0.04501007, -0.03145634,\n",
       "                        0.05738986,  0.0268788 ,  0.01203227, -0.02544892, -0.01781096,\n",
       "                        0.03170944,  0.05819654, -0.03001004,  0.06216743, -0.05042212,\n",
       "                        0.05312058, -0.04738064, -0.0166346 ,  0.06016381, -0.00801235,\n",
       "                       -0.05082443, -0.01290483, -0.00210752, -0.03113911,  0.01442955,\n",
       "                        0.01213247, -0.06193651, -0.06084687,  0.03197943, -0.00660754,\n",
       "                        0.04971921, -0.03238543,  0.02313472, -0.04505336,  0.04033609,\n",
       "                       -0.03816813,  0.03772196,  0.03979667,  0.00439757, -0.02776327,\n",
       "                       -0.02946671, -0.05176897,  0.05782506,  0.01346825, -0.05134817,\n",
       "                        0.0456559 , -0.02067457,  0.04440528, -0.01511118, -0.01230736,\n",
       "                       -0.02351792],\n",
       "                      [ 0.01949818,  0.0398969 , -0.03242809, -0.05052533, -0.03656701,\n",
       "                        0.03732007,  0.02779944, -0.0037123 , -0.05525424, -0.0342093 ,\n",
       "                        0.01767053, -0.04596609, -0.01509397, -0.03473909, -0.0185442 ,\n",
       "                       -0.04429118,  0.03132825,  0.05942085, -0.03178602,  0.00886004,\n",
       "                        0.06199326, -0.05198236,  0.04893436, -0.01360759, -0.0130163 ,\n",
       "                       -0.06216436, -0.05426211, -0.02136708, -0.03460015,  0.03853048,\n",
       "                       -0.05114377, -0.02658971,  0.04226289,  0.02568338, -0.05930212,\n",
       "                        0.05589007,  0.03016873, -0.06103218,  0.02360252, -0.04613745,\n",
       "                        0.01478528,  0.02159323, -0.01338396,  0.00572348,  0.05043457,\n",
       "                       -0.02644963,  0.00660767,  0.04075736, -0.00648788, -0.04134962,\n",
       "                        0.03616478,  0.03211886, -0.03155123,  0.03663921,  0.05897919,\n",
       "                        0.0344949 ,  0.0308792 , -0.02531863,  0.01215278,  0.04409729,\n",
       "                       -0.05928946,  0.01089086, -0.01731156,  0.00403932, -0.04633197,\n",
       "                       -0.03007106,  0.05195288, -0.04597612,  0.0003755 , -0.00247356,\n",
       "                       -0.05027652,  0.05578275, -0.00426263, -0.01710191,  0.00880483,\n",
       "                        0.04121914,  0.05194912, -0.04424093, -0.00276189,  0.03559946,\n",
       "                       -0.05263678,  0.01658513,  0.03650089,  0.04713741, -0.04107349,\n",
       "                       -0.05577666, -0.04382362,  0.02804866,  0.01116478,  0.0425243 ,\n",
       "                        0.04645891,  0.04630507,  0.03079243, -0.04402997, -0.02206876,\n",
       "                        0.01579694, -0.0237233 , -0.01103821,  0.04993603,  0.00521007,\n",
       "                       -0.03059959, -0.04783435, -0.0290435 , -0.05480897, -0.05900099,\n",
       "                       -0.06229038, -0.04005285,  0.0599615 ,  0.01589551, -0.01492995,\n",
       "                        0.0586545 , -0.05070681,  0.06015033, -0.01627359,  0.01404962,\n",
       "                       -0.04692873,  0.00910296,  0.03336567,  0.00766423,  0.02254967,\n",
       "                       -0.02000728, -0.05308246,  0.03376099, -0.0091566 , -0.04433458,\n",
       "                       -0.05111946, -0.04624216,  0.05078097,  0.02339116,  0.00523171,\n",
       "                       -0.05330604,  0.01917763,  0.01429494, -0.06165884, -0.03934342,\n",
       "                       -0.02155685, -0.0053166 ,  0.05595464, -0.00059628,  0.03987124,\n",
       "                        0.02924772,  0.05395145,  0.02677169,  0.00031842,  0.05028171,\n",
       "                        0.06239859,  0.01146857, -0.05917674, -0.04537854,  0.00864206,\n",
       "                       -0.03143852, -0.00038201,  0.01063187,  0.03560904,  0.04076108,\n",
       "                        0.01437438, -0.0053601 , -0.04875275, -0.04126211, -0.00962576,\n",
       "                       -0.03952285,  0.02164524,  0.00428326, -0.01472887, -0.01192643,\n",
       "                       -0.03661261,  0.03702688,  0.01490717, -0.04080921,  0.02416848,\n",
       "                        0.03922965,  0.05206028,  0.00948313,  0.01319379,  0.06097715,\n",
       "                        0.03275237,  0.03182915, -0.03807483, -0.05893101, -0.00905039,\n",
       "                        0.0135575 , -0.0400764 , -0.03752891, -0.01637033,  0.01453601,\n",
       "                       -0.0597759 ,  0.04734781,  0.04411278, -0.03574504,  0.04127835,\n",
       "                       -0.05046581,  0.00377101, -0.01150955,  0.03446755,  0.01713137,\n",
       "                       -0.05522966, -0.04899348,  0.03628014, -0.00310334, -0.0067618 ,\n",
       "                       -0.02642173, -0.02165736,  0.02379757,  0.00998969,  0.0195431 ,\n",
       "                        0.03804238,  0.05275122, -0.01770315, -0.05527505, -0.00929274,\n",
       "                       -0.03526432, -0.0605516 ,  0.0321383 ,  0.05237477,  0.00307608,\n",
       "                       -0.03332259, -0.01933326, -0.01112966,  0.05464538, -0.00873809,\n",
       "                        0.03118315,  0.04765485, -0.0527145 ,  0.0290682 ,  0.00433207,\n",
       "                        0.00722915, -0.02725794,  0.026506  ,  0.02612773,  0.04341318,\n",
       "                        0.03199492, -0.03975249,  0.01735438, -0.01804987, -0.05817404,\n",
       "                        0.04095325, -0.03172841, -0.02755065,  0.03212278,  0.03638732,\n",
       "                       -0.04925679,  0.01047102,  0.02932756, -0.03436913,  0.0430408 ,\n",
       "                        0.04257266,  0.05655405, -0.04755934,  0.04568511,  0.01169502,\n",
       "                       -0.00755979, -0.06015145,  0.02758955,  0.04890035, -0.0212636 ,\n",
       "                       -0.03758594]], dtype=float32)),\n",
       "              ('pi.net.mlp.0.bias',\n",
       "               array([0.0286466 , 0.04479951], dtype=float32)),\n",
       "              ('vf.log_std_clip_param_const', array([20.], dtype=float32)),\n",
       "              ('vf.net.mlp.0.weight',\n",
       "               array([[ 0.05482611, -0.02716839,  0.04668076,  0.0507466 , -0.00855439,\n",
       "                        0.00813504, -0.05272486,  0.03913631,  0.05942501, -0.00942905,\n",
       "                       -0.0025904 ,  0.02266674,  0.01558235, -0.01692604, -0.05997509,\n",
       "                        0.00493037, -0.03867844,  0.01291763, -0.04203555, -0.05905393,\n",
       "                       -0.00414252,  0.01661867, -0.03943454,  0.02111991,  0.05763805,\n",
       "                        0.03782928, -0.0407385 , -0.03990423, -0.01913146, -0.00724626,\n",
       "                        0.01756674,  0.00093557,  0.0551703 ,  0.03202841,  0.02822755,\n",
       "                        0.02014317,  0.05107334,  0.02748944, -0.02998625, -0.00349211,\n",
       "                        0.04542273,  0.02399912,  0.06121321, -0.02189145, -0.00050215,\n",
       "                        0.03544434, -0.01364163, -0.02946878, -0.00255047,  0.0262314 ,\n",
       "                        0.02888826,  0.02207608,  0.03731976,  0.05066174,  0.01662443,\n",
       "                        0.00444975, -0.02807875,  0.0373459 , -0.01723808,  0.02878306,\n",
       "                        0.03186984, -0.04328866, -0.05078854,  0.03646812, -0.01811854,\n",
       "                        0.04145514,  0.04679494, -0.05448556,  0.0616877 ,  0.03992084,\n",
       "                       -0.05922727, -0.00881708,  0.0303159 ,  0.02225133,  0.03775775,\n",
       "                        0.0045844 , -0.00724689, -0.02117112,  0.04455843,  0.05225845,\n",
       "                        0.04117621, -0.01466899, -0.00616471,  0.03625538,  0.05633903,\n",
       "                        0.05799158,  0.06225333,  0.05740358, -0.0042693 , -0.02237243,\n",
       "                        0.00616427,  0.014112  ,  0.01720186,  0.04164089,  0.06107403,\n",
       "                        0.03274174, -0.02294691,  0.05983238,  0.01004599,  0.00218342,\n",
       "                       -0.05011001,  0.01954465, -0.02615193, -0.05609542,  0.01091237,\n",
       "                        0.04115733, -0.04308222, -0.03750529, -0.02724351, -0.0488221 ,\n",
       "                        0.04630736,  0.02407085, -0.01204073, -0.02395203, -0.03303841,\n",
       "                       -0.01696888,  0.0090199 , -0.02479658,  0.04268169,  0.0394087 ,\n",
       "                        0.03735483,  0.03800999,  0.03980745,  0.04022178, -0.0240919 ,\n",
       "                        0.05922779,  0.01622833,  0.05093199, -0.05046915, -0.05833174,\n",
       "                        0.01854364,  0.01410013, -0.02446486, -0.00950895,  0.04300228,\n",
       "                       -0.03419082, -0.00623232, -0.00572461,  0.05211541, -0.025968  ,\n",
       "                        0.05753168,  0.02057841, -0.01961306, -0.00820055, -0.00902686,\n",
       "                        0.04694337, -0.06073076, -0.05111662, -0.01751152,  0.01591969,\n",
       "                       -0.05350368,  0.04820054,  0.02181776, -0.04921087,  0.05071202,\n",
       "                       -0.0350472 , -0.03470615, -0.04730701,  0.04658438,  0.02571056,\n",
       "                        0.00339361, -0.01057946,  0.05308007, -0.03590564,  0.02335221,\n",
       "                       -0.05799508,  0.04114173,  0.01513518,  0.04177323, -0.03230783,\n",
       "                        0.01981752,  0.04653262,  0.02587225,  0.01035848,  0.00475638,\n",
       "                        0.0486625 ,  0.00275557, -0.01913002, -0.05825098, -0.01003042,\n",
       "                       -0.0442822 ,  0.01577801, -0.00448647, -0.04921477, -0.05349732,\n",
       "                        0.05502612,  0.02461021, -0.04135197,  0.01452606, -0.04221614,\n",
       "                        0.00800152, -0.00409921,  0.01935896,  0.02503801,  0.02369662,\n",
       "                       -0.00089265, -0.01540468,  0.01326202, -0.00102081, -0.00833505,\n",
       "                        0.00360924, -0.05389922, -0.0603268 , -0.04418148, -0.03366061,\n",
       "                        0.0412185 ,  0.03338889, -0.01148604,  0.01105595,  0.01366607,\n",
       "                       -0.0199357 ,  0.03053477, -0.02771512, -0.03450099, -0.05033631,\n",
       "                        0.05132785, -0.05886879, -0.05396559, -0.0621212 , -0.05847473,\n",
       "                        0.0562831 , -0.05071069,  0.05550948, -0.03701916,  0.02410289,\n",
       "                        0.02221806,  0.05263752,  0.02103355,  0.0002796 ,  0.0186088 ,\n",
       "                       -0.00243752,  0.00899974, -0.01434304,  0.0011893 ,  0.04101352,\n",
       "                        0.02962507, -0.03257634, -0.0614339 ,  0.04998325, -0.00496625,\n",
       "                        0.05018326,  0.00228309,  0.04020574, -0.04290803,  0.00362322,\n",
       "                       -0.02096552,  0.03703496, -0.03379003, -0.01222767,  0.05543646,\n",
       "                       -0.04809371,  0.04777338,  0.00831006,  0.01117385,  0.05140447,\n",
       "                       -0.01225355]], dtype=float32)),\n",
       "              ('vf.net.mlp.0.bias', array([0.01628944], dtype=float32))])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "\n",
    "algo = (\n",
    "    PPOConfig()\n",
    "    .api_stack(\n",
    "        enable_rl_module_and_learner=True,\n",
    "        enable_env_runner_and_connector_v2=True,\n",
    "    )\n",
    "    .environment(\"CartPole-v1\")\n",
    "    .env_runners(num_env_runners=2)\n",
    ").build()\n",
    "\n",
    "# Get weights of the algo's RLModule.\n",
    "algo.get_module().get_state()\n",
    "\n",
    "# Same as above\n",
    "algo.env_runner.module.get_state()\n",
    "\n",
    "# Get list of weights of each EnvRunner, including remote replicas.\n",
    "algo.env_runner_group.foreach_worker(lambda env_runner: env_runner.module.get_state())\n",
    "\n",
    "# Same as above, but with index.\n",
    "algo.env_runner_group.foreach_worker_with_id(\n",
    "    lambda _id, env_runner: env_runner.module.get_state()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 84, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    import gymnasium as gym\n",
    "\n",
    "    env = gym.make(\"ALE/Pong-v5\")\n",
    "    obs, infos = env.reset()\n",
    "except Exception:\n",
    "    import gym\n",
    "\n",
    "    env = gym.make(\"PongNoFrameskip-v4\")\n",
    "    obs = env.reset()\n",
    "\n",
    "# RLlib uses preprocessors to implement transforms such as one-hot encoding\n",
    "# and flattening of tuple and dict observations.\n",
    "from ray.rllib.models.preprocessors import get_preprocessor\n",
    "\n",
    "prep = get_preprocessor(env.observation_space)(env.observation_space)\n",
    "# <ray.rllib.models.preprocessors.GenericPixelPreprocessor object at 0x7fc4d049de80>\n",
    "\n",
    "# Observations should be preprocessed prior to feeding into a model\n",
    "obs.shape\n",
    "# (210, 160, 3)\n",
    "prep.transform(obs).shape\n",
    "# (84, 84, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FullyConnectedNetwork_as_DQNTorchModel(\n",
      "  (_hidden_layers): Sequential(\n",
      "    (0): SlimFC(\n",
      "      (_model): Sequential(\n",
      "        (0): Linear(in_features=4, out_features=256, bias=True)\n",
      "        (1): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (1): SlimFC(\n",
      "      (_model): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (1): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (_value_branch): SlimFC(\n",
      "    (_model): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (advantage_module): Sequential(\n",
      "    (dueling_A_0): SlimFC(\n",
      "      (_model): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (1): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (A): SlimFC(\n",
      "      (_model): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=2, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (value_module): Sequential(\n",
      "    (dueling_V_0): SlimFC(\n",
      "      (_model): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (1): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (V): SlimFC(\n",
      "      (_model): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\robot_sim\\lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py:568: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "c:\\Users\\User\\anaconda3\\envs\\robot_sim\\lib\\site-packages\\ray\\tune\\logger\\unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "c:\\Users\\User\\anaconda3\\envs\\robot_sim\\lib\\site-packages\\ray\\tune\\logger\\unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "c:\\Users\\User\\anaconda3\\envs\\robot_sim\\lib\\site-packages\\ray\\tune\\logger\\unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nModel: \"model\"\\n_____________________________________________________________________\\nLayer (type)               Output Shape  Param #  Connected to\\n=====================================================================\\nobservations (InputLayer)  [(None, 4)]   0\\n_____________________________________________________________________\\nfc_1 (Dense)               (None, 256)   1280     observations[0][0]\\n_____________________________________________________________________\\nfc_value_1 (Dense)         (None, 256)   1280     observations[0][0]\\n_____________________________________________________________________\\nfc_2 (Dense)               (None, 256)   65792    fc_1[0][0]\\n_____________________________________________________________________\\nfc_value_2 (Dense)         (None, 256)   65792    fc_value_1[0][0]\\n_____________________________________________________________________\\nfc_out (Dense)             (None, 2)     514      fc_2[0][0]\\n_____________________________________________________________________\\nvalue_out (Dense)          (None, 1)     257      fc_value_2[0][0]\\n=====================================================================\\nTotal params: 134,915\\nTrainable params: 134,915\\nNon-trainable params: 0\\n_____________________________________________________________________\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a reference to the policy\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from ray.rllib.algorithms.dqn import DQNConfig\n",
    "\n",
    "algo = (\n",
    "    DQNConfig()\n",
    "    .api_stack(\n",
    "        enable_rl_module_and_learner=False, enable_env_runner_and_connector_v2=False\n",
    "    )\n",
    "    .framework(\"torch\")\n",
    "    .environment(\"CartPole-v1\")\n",
    "    .env_runners(num_env_runners=0)\n",
    "    .training(\n",
    "        replay_buffer_config={\n",
    "            \"type\": \"MultiAgentPrioritizedReplayBuffer\",\n",
    "        }\n",
    "    )\n",
    ").build()\n",
    "# <ray.rllib.algorithms.ppo.PPO object at 0x7fd020186384>\n",
    "\n",
    "policy = algo.get_policy()\n",
    "# <ray.rllib.policy.eager_tf_policy.PPOTFPolicy_eager object at 0x7fd020165470>\n",
    "\n",
    "# Run a forward pass to get model output logits. Note that complex observations\n",
    "# must be preprocessed as in the above code block.\n",
    "logits, _ = policy.model({\"obs\": torch.from_numpy(np.array([[0.1, 0.2, 0.3, 0.4]]))})\n",
    "# (<tf.Tensor: id=1274, shape=(1, 2), dtype=float32, numpy=...>, [])\n",
    "\n",
    "# Compute action distribution given logits\n",
    "policy.dist_class\n",
    "# <class_object 'ray.rllib.models.tf.tf_action_dist.Categorical'>\n",
    "dist = policy.dist_class(logits, policy.model)\n",
    "# <ray.rllib.models.tf.tf_action_dist.Categorical object at 0x7fd02301d710>\n",
    "\n",
    "# Query the distribution for samples, sample logps\n",
    "dist.sample()\n",
    "# <tf.Tensor: id=661, shape=(1,), dtype=int64, numpy=..>\n",
    "dist.logp(torch.tensor([1]))\n",
    "# <tf.Tensor: id=1298, shape=(1,), dtype=float32, numpy=...>\n",
    "\n",
    "# Get the estimated values for the most recent forward pass\n",
    "policy.model.value_function()\n",
    "# <tf.Tensor: id=670, shape=(1,), dtype=float32, numpy=...>\n",
    "\n",
    "print(policy.model)\n",
    "\"\"\"\n",
    "Model: \"model\"\n",
    "_____________________________________________________________________\n",
    "Layer (type)               Output Shape  Param #  Connected to\n",
    "=====================================================================\n",
    "observations (InputLayer)  [(None, 4)]   0\n",
    "_____________________________________________________________________\n",
    "fc_1 (Dense)               (None, 256)   1280     observations[0][0]\n",
    "_____________________________________________________________________\n",
    "fc_value_1 (Dense)         (None, 256)   1280     observations[0][0]\n",
    "_____________________________________________________________________\n",
    "fc_2 (Dense)               (None, 256)   65792    fc_1[0][0]\n",
    "_____________________________________________________________________\n",
    "fc_value_2 (Dense)         (None, 256)   65792    fc_value_1[0][0]\n",
    "_____________________________________________________________________\n",
    "fc_out (Dense)             (None, 2)     514      fc_2[0][0]\n",
    "_____________________________________________________________________\n",
    "value_out (Dense)          (None, 1)     257      fc_value_2[0][0]\n",
    "=====================================================================\n",
    "Total params: 134,915\n",
    "Trainable params: 134,915\n",
    "Non-trainable params: 0\n",
    "_____________________________________________________________________\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robot_sim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
